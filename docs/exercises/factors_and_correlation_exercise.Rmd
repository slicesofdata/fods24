---
title: "Exercise: Factors and Correlations"
author: "yourname"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  #word_document:
  #  toc: yes
  #  number_sections: yes
  html_document:
    toc: no
    number_sections: yes
    code_folding: show #hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
eval_answers <- TRUE
include_answers <- FALSE
```

```{r, include=FALSE}
R.utils::sourceDirectory(here::here("r", "functions"))
```

# **Class Practice**






# **Loading Libraries**

```{r, eval=eval_answers, include=include_answers}
library(easystats)
library(tidyverse)
library(ggplot2)
library(gt)
library(gtsummary)
```

# **Reading Data**

1. Read some of your project task data that has been cleaned as well as the demographic data that has been created by your teammate. 

2. Verify that the files contain a unique identifier for joining the data frames.

```{r, eval=eval_answers, include=include_answers}
SPAN_cleaned <- readRDS(here::here("data", "symmspan", "sspan_long_clean.Rds")) |>
  select(id_subject, id_school, wave, totalerrors, 
         totalcorrectsquares, totalrecalledsets, sspan)

DEMOG <- readRDS(here::here("data", "demog", "demog_subset_wide.rds")) |>
  mutate(wave = id_wave,
         age = as.numeric(age),
         ethnicity = ifelse(self_eth == "N/A" | is.na(self_eth), 
                            "NA", self_eth
                            ),
         #sex = ifelse(sex == "N/A" | is.na(sex), "Not Answered", sex)
         ) |>
  relocate(c(id_subject, id_school, wave, age, ethnicity, sex), .before = 1)
```

```{r, eval=eval_answers, include=include_answers}
DEMOG |> view_html()

SPAN_cleaned |> view_html()
```

# **Creating Factor Variables**

If there are character type variables that would be factor predictors of a model, you will want to convert them into factor variables. When you convert them into factors inside the data frame, they will also look better in visualizations compared with converting them into factors inside of **{ggplot}** functions.   

1. Identify variables that represent categorical groups and convert them into factors.

2. 


# **Joining Data Frames**
 
1. Join the two data frames into a single data frame.

```{r}
JOINED_LONG <- 
  dplyr::left_join(x = DEMOG,
                   y = SPAN_cleaned, 
                   by = "id_subject",
                   suffix = c("", ""),
                   relationship = "many-to-many"
                   ) 

JOINED_LONG |> view_html()
```

2. Review your joined data frame to see that it looks like you expect it to look. 

3. Examine your data frame for column variables with a `.x` or `.y`. Review such variable for errors. If you have them, consider adding `suffix = c("", ""))` to your join function. This will ensure that no *suffixes* should be added to the variable names in the returned data frame.

4. If you have multiple rows in one data frame (e.g., long format) but not the other data frame, you may receive a warning message like:

```
 Detected an unexpected many-to-many relationship between `x` and `y`.
ℹ Row 10 of `x` matches multiple rows in `y`.
ℹ Row 1 of `y` matches multiple rows in `x`.
ℹ If a many-to-many relationship is expected, set `relationship = "many-to-many"` to silence this warning.
```

If, and only if, your data frame looks appropriate for your goal, silence the warning by adding the recommended (in the warning message) parameter and argument to your join function. You won't want to see this message when you build your files. 

5. Once you are certain that your new data frame represents a combined data frame, assign it to an object name like `JOINED` or something else meaningful. If you are matching data with a long format (in any data frame),  consider modifying the name to `JOINED_LONG` so you can understand the file contents by the file name.


6. Options and Team Choices. 

*Script files*. There will be several tasks that involve using combined data frames (e.g., data summaries, models, visualizations) so your team should consider how best to address related issues. One recommendation is to create something like a `"join_data.R"` or `"merge_data.R"` script file performs  all of your data frame joining operations needed for your project after the sub-components of the project are cleaned appropriately. Because certain project tasks like summarizing data, modeling data, and visualizing data will utilize the joined data, you could source this new script in the summarizing, modeling, and visualizing scripts before performing other operations. Moreover, depending on your goals, you may need to pivot data after joining or join data that have been pivoted to either long or wide. For example, in order to correlate data, the variables that you wish to correlate would need to be represented as **columns** (e.g., a single task data from different waves will need to be in separate columns). In such an instance, you could pivot your sub-task data by `wave` so that all participants are on one row and then join that data frame with others. Similarly, a regression model that uses data at time 1 to predict time 2 data will require a similar *wide* file structure. Visualizing data, however, will best be structured in a *long* format.   

*Data files*. Similarly, to facilitate access to the joined data, you may also wish to save the joined data file(s). In such instances, you might wish to save the joined data in a sub-directory of your `/data` directory, for example, `/data/joined` or `/data/merged`. If you decide to do this, you should also read in the joined data files after sourcing the code that produced them. In some instances you might want to create different joined files but the main goal would likely be to combine data across components of the project. 

Your team should decide how best to handle joined data so that everyone knows whether there are data files and if so, where they would be located. You would also want to make decisions that would be clear to the project liaison.  


# **(Optional): Pivoting to Wide based on Wave**

1. In order to correlate measures, you will need to have all variables you wish to correlate represented as columns. Use `pivot_wider()` to pivot your data frame by wave.

```{r}
SPAN_cleaned_wide <- 
  SPAN_cleaned |>
  tidyr::pivot_wider(
    id_cols = id_subject,
    names_from  = wave,
    values_from = c(sspan, totalcorrectsquares)
  ) 

SPAN_cleaned_wide |> view_html()

JOINED_WIDE <- full_join(
  x = DEMOG,
  y = SPAN_cleaned_wide,
  by = "id_subject"
)

JOINED_WIDE |> view_html()

JOINED_WIDE <-
  JOINED_WIDE |> 
  mutate(across(.cols = contains("_yn"),
                .fns = ~as.numeric(ifelse(.x == "N/A", NA, .x))
                ))

JOINED_WIDE |> view_html()

# may need if alternating NAs %>% group_by(., ) %>% dplyr::summarise_all(purrr::discard, is.na) %>% distinct()
```

2. Join this *wide* version of your file with a team members data frame.



# **Summarize a Variable (or Variables) by Group**

1. Using wave 1 data, create a data summary using `summarize()` to present the means, standard errors, upper and lower limit 95% confidence-interval thresholds, and sample size associate with a measurement/outcome variable of your choice. To assist with the standard error, confidence intervals, *n*, use the list provided below. Include a grouping variable in your summary. 

```
summarize_across_list <- list(
  mean = ~mean(na.omit(.x)),
  se   = ~sd(na.omit(.x)) / sqrt(length(na.omit(.x))),
  ci.95l = ~ifelse(length(na.omit(.x)) > 1, t.test(.x, conf.level = .95)$conf.int[1], NA),
  ci.95u = ~ifelse(length(na.omit(.x)), t.test(.x, conf.level = .95)$conf.int[2], NA),
  n    = ~length(na.omit(.x))
  )
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
summarize_across_list <- list(
  mean = ~mean(na.omit(.x)),
  se   = ~sd(na.omit(.x)) / sqrt(length(na.omit(.x))),
  ci.95l = ~ifelse(length(na.omit(.x)) > 1, t.test(na.omit(.x), 
                                                   conf.level = .95)$conf.int[1], NA),
  ci.95u = ~ifelse(length(na.omit(.x)), t.test(na.omit(.x), conf.level = .95)$conf.int[2], NA),
  n    = ~length(na.omit(.x))
  )

JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  group_by(ethnicity, wave) |>
  filter(wave == 1) |>
  summarize(across(.cols = c(contains("sspan")),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |> 
  arrange(wave, desc(sspan_mean)) |>
  rename_with(~tolower(gsub("sspan_", "", .x, fixed = T))) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute Span Score by Ethnicity")

JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  filter(wave == 1 | wave == "1") |>
  group_by(ethnicity) |>
  summarize(across(.cols = c(contains("sspan")),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |> 
  arrange(ethnicity, desc(sspan_mean)) |>
  rename_with(~tolower(gsub("sspan_", "", .x, fixed = T))) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute Span Score by Ethnicity")

JOINED_LONG |>
  mutate(wave = as.factor(wave)) |>
  group_by(ethnicity) |>
  filter(wave == 1) |>
  summarize(across(.cols = contains("totalcorrectsquares"),
                   .fns = summarize_across_list,
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |>
  arrange(ethnicity, desc(totalcorrectsquares_mean)) |>
  mutate(across(where(is.numeric), round, digits = 2)) |>
  rename_with(~tolower(gsub("totalcorrectsquares_", "", .x, fixed = T))) |>
  gt() |>
  tab_header(title = "Wave 1: Partial Span Score by Ethnicity")
```

2. After you are sure that your summary table looks correct, pipe the data frame to `gt()` from the **{gt}** library  (used in modules) to present the summary in a simple table. 

3. To add a title to the table, pipe your data frame to `tab_header()` from the **{gt}** library.

Example: `tab_header(title = "My Clear Title")`

4. In preparation for your liaison meeting, you can repeat the process for another variable that you would want to present. 



# **Correlate Variables**

1. Create a Pearson's *r* correlation table of numeric variables that are also grouped by some grouping variable. Use the `gt()` function from module to present the correlations in a simple table. 

2. Extend the correlation table by adding a grouping variable that is relevant to the liaison's proposal. Use the `gt()` function from module to present the correlations in a simple table.

```{r}
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  #select(where(fn = is.numeric)) |>
  select(c(self_eth, contains("span_1"), contains("squares_1"), age)) |>
  group_by(self_eth) |>
  correlation() |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  #cor(use = "pairwise.complete.obs") |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute and Partial Span Score Correlations by Ethnicity")


JOINED_WIDE |>
  filter(sex != "N/A") |>
  filter(wave == 1 |  wave == "1") |>
  #select(where(fn = is.numeric)) |>
  select(c(sex, self_eth, contains("span_1"), contains("squares_1"), age)) |>
  group_by(sex) |>
  correlation() |>
  #cor(use = "pairwise.complete.obs") |>
  mutate(across(where(is.numeric), round, digits = 3)) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Absolute and Partial Span Score Correlations by Sex")
```


```{r}
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  select(ethnicity) |>
  table() |>  
  as.data.frame() |>
  pivot_wider(
      names_from = ethnicity,
      values_from = Freq
    ) |>
  relocate("NA", .after = last_col()) |>
  gt::gt() |>
  tab_header(title = "Wave 1: Ethnicity (n)")
  
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  select(sex, ethnicity) |>
  table() |> 
  as.data.frame() |>
  pivot_wider(
      names_from = ethnicity,
      values_from = Freq
    ) |> 
  relocate("NA", .after = last_col()) |>
  gt() |>
  tab_header(title = "Wave 1: Sex and Ethnicity (n)")
```



# **Explore Variables**

1. Create a generalized pairs plot to explore the data and bivariate relationships among a set of numeric variables. Consider variable relationships that would be relevant for your liaison's proposal. 

```{r}
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(!is.na(sspan_1)) |>
  select(c(contains("span_1"), contains("squares_1"), age)) |>
  #view_html()
  GGally::ggpairs()
```

2. Extend the generalized pairs plot by adding a grouping variable that is relevant to the liaison's proposal. 

```{r}
suppressWarnings(
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(sex != "N/A") |>
  filter(ethnicity %in% c("White", "Black", "Other", "NA")) |>
  filter(!is.na(sspan_1)) |>
  select(c(self_eth, contains("span_1"), contains("squares_1"), age)) |>
  #view_html()
  GGally::ggpairs()
)
```

```{r}
suppressWarnings(
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(sex != "N/A") |>
  filter(ethnicity %in% c("White", "Black", "Other", "NA")) |>
  filter(!is.na(sspan_1)) |>
  select(c(ethnicity, contains("span_1"), contains("squares_1"), age)) |>
  GGally::ggpairs(mapping = aes(col = ethnicity, alpha = .3),
                  lower = list(continuous = wrap("smooth", se = FALSE))
                  )
)

new_colors <- c("cornflowerblue", "firebrick") 

suppressWarnings(
JOINED_WIDE |>
  filter(wave == 1 | wave == "1") |>
  filter(sex != "N/A") |>
  filter(ethnicity %in% c("White", "Black", "Other", "NA")) |>
  filter(!is.na(sspan_1)) |>
  select(c(sex, contains("span_1"), contains("squares_1"), age)) |>
  #view_html()
  GGally::ggpairs(mapping = aes(col = sex, alpha = .3),
                  lower = list(continuous = wrap("smooth", se = FALSE))
                  ) +
  scale_color_manual(values = new_colors) +
  scale_fill_manual(values = new_colors)
)

WIDE |> 
  select(group, var1_1:var1_3) |>

  GGally::ggpairs(mapping = aes(col = group, 
                                alpha = .3
                                ),
                  lower = list(continuous = wrap("smooth", se = FALSE))
                  ) +
  scale_color_manual(values = new_colors) +
  scale_fill_manual(values = new_colors)
```


# **Model**


```{r}
library(easystats)
library(gtsummary)
#library(performance)
#library(see)

lm_mod <- lm(sspan_1 ~ totalcorrectsquares_1, data = JOINED_WIDE)
lm_mod2 <- lm(sspan_1 ~ age, data = JOINED_WIDE)

tbl_lm_mod <- lm_mod |> gtsummary::tbl_regression()

tbl_lm_mod2 <- lm_mod2 |>  tbl_regression()

gtsummary::tbl_merge(
    tbls = list(tbl_lm_mod, tbl_lm_mod2), 
    tab_spanner = c("**y ~ X**", "**y ~ x1 + x2**") 
  )


GGally::ggnostic(lm_mod)
GGally::ggnostic(lm_mod2)

lm_mod |> performance::check_collinearity()

# Comprehensive visualization of model checks:
lm_mod |> performance::check_model()

# performance::check_collinearity() check_normality() or check_heteroscedasticity() 
# Summarizing Model Performance

lm_mod |> performance::check_normality()
lm_mod |> performance::check_heteroscedasticity()

lm_mod |> performance::check_collinearity()

lm_mod |> performance::model_performance()

  

# Comparing Models
performance::compare_performance(lm_mod, lm_mod2, rank = TRUE)
plot(performance::compare_performance(lm_mod, lm_mod2, rank = TRUE))
# Fit a linear model

# Summary of the model
summary(lm_mod) 

lm_mod |>  tbl_regression() 

GGally::ggnostic(lm_mod)
plot(fit.models::fit.models(lm_mod, lm_mod2))

 



library(fit.models)
data(stackloss)
stack.lm <- lm(stack.loss ~ ., data = stackloss)
stack.clean <- lm(stack.loss ~ ., data = stackloss, subset = 5:20)
fm <- fit.models(stack.clean, stack.lm)
plot(fm)

fit.models(stack.clean, stack.lm)
plot(fm)

# Diagnostic plots
diagnose(lm_mod2)

JOIN_WIDE |>
  tbl_summary(include = c(age, sspan))

  tbl_summary(
    trial,
    include = c(age, grade, response),
    by = trt, # split table by group
    missing = "no" # don't list missing data separately
  ) %>%
  add_n() %>% # add column with total number of non-missing observations
  add_p() %>% # test for a difference between groups
  modify_header(label = "**Variable**") %>% # update the column header
  bold_labels()
  
  JOIN_WIDE |> view_html()
```

**Save the Table as an image**

```{r}
tbl |>
  gtsummary::as_gt() %>%
  gt::gtsave(filename = ".") 

trial
JOIN_WIDE |>
  select(age, sspan_1, totalcorrectsquares_1) |>
  
    tbl_summary(
    trial,
    include = c(age, grade, response),
    by = trt, # split table by group
    missing = "no" # don't list missing data separately
  ) %>%
  add_n() %>% # add column with total number of non-missing observations
  add_p() %>% # test for a difference between groups
  modify_header(label = "**Variable**") %>% # update the column header
  bold_labels()
  tbl_summary()

```



# **Aggregate the Data**



# **Summarizing Data**

```{r, eval=eval_answers, include=include_answers}
# functions
std_error <- function(x) { sd(na.omit(x)) / sqrt(length(na.omit(x))) }

# Custom function to calculate minimum with NA handling
# 
min_with_NA_check <- function(x) {
  if (any(!is.na(x))) {
    return(min(x, na.rm = TRUE))
  } else {
    return(NA)  # Return NA if all values are NA
  }
}

# Custom function to calculate maximum with NA handling
max_with_NA_check <- function(x) {
  if (any(!is.na(x))) {
    return(max(x, na.rm = TRUE))
  } else {
    return(NA)  # Return NA if all values are NA
  }
}

summarize_across <- list(
    mean   = ~mean(na.omit(.x)),
    median = ~median(na.omit(.x)),
    min    = ~max_with_NA_check(.x),
    max    = ~max_with_NA_check(.x),
    sd     = ~sd(na.omit(.x)),
    n      = ~length(na.omit(.x)),
    sem    = ~std_error(.x)
    )
```


## **Choose One**

### **Visualizing a Bar Graph**

From your `"sspan_long_cleaned.Rds"` file

1. Select: `id_subject`, `wave`, `target`, `accuracy`, and `rt`
2. Aggregate the data so that you can obtain `rt` and `accuracy` data for both `Go` and `No-Go` trials for each each individual at each wave.
3. Generate a summarized data frame containing the mean, median, and standard deviation across `accuracy` and `rt` so that you have the summary statistics for each participant, at each wave, and for both go and no-go trials. In the end, remove the grouping structure so that if you assign it to an object or write the data frame, it is not grouped.

```{r, eval=eval_answers, include=include_answers}
the_vars <- c("accuracy", "rt") 
# GNG_CLEAN |> view_html()

GNG_agg_by_id <-
  GNG_CLEAN |>
  select(c(id_subject, wave, target, accuracy, rt)) |>
  group_by(id_subject, wave, target) |>
  summarize(across(.cols = the_vars,  
                   .fns = summarize_across[c(1, 2, 5)],
                   .names = "{.col}_{.fn}"
                   ),
            .groups = "drop"
            ) |>
  ungroup() 

GNG_agg_by_id |> head() |> view_html() 
```

### **Visualizing a Point Plot: Scatterplot**

Using `geom_point()` to plot the relationship between response time and accuracy. You will need all individuals in the data set so that each point represents an individuals average response time and accuracy 

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = accuracy_mean, 
                       y = rt_mean
                       )
         ) +
  geom_point() #+ facet_wrap(facets = vars(wave), ncol = 1)
```

Inspect the scatterplot. Using your knowledge from your statistics courses to understand your data and notes. 



### **Visualizing a Point Plot**

Using `geom_point()` to plot the relationship between response time and accuracy.

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  filter(wave == 1) |>
  ggplot(mapping = aes(x = target, 
                       y = rt_mean
                       )
         ) +
  geom_point() 
```



### **Addressing Overplotting: Jittering Points**

Although you can see the range of data, you cannot see the individual points in the plot. To address **overplotting**, adjust the point position by modifying the `position` parameter of `geom_point()` (e.g.,  `position = position_jitter()`). If you are adventurous, you can also change the `size` and `alpha` aesthetics of the points if the jittering does not solve the problem. 

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = target, 
                       y = rt_mean
                       )
         ) +
  geom_point(position = position_jitter(),
             size = 1, 
             alpha = .3
             ) #+ facet_wrap(facets = vars(wave), ncol = 1)
```

You can see the distribution of the data. 




### **Visualizing a Bar Graph**
4. Filter the summarized data frame to include only wave 1.
5. Use `geom_col()` to create two bar/column plots:

a. for the response time variable as a function for target type; remember that when you add layers to ggplot object, you need to literally add, `+`, not pipe. 
b.

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  filter(!is.na(rt_mean)) |>
  filter(wave == 1) |>
  slice(1:30) |>
  ggplot(mapping = aes(x = target, 
                       y = rt_mean
                       )
         ) +
  geom_col() + facet_wrap(facets = vars(id_subject))

GNG_agg_by_id$rt_mean
GNG_agg_by_id |>
  group_by(wave) |>
  summarize(across(
    .cols = c(accuracy_mean, rt_mean),
    .fns = ~mean(.x, na.rm = T)
    ))
SSPAN |>
  group_by(wave) |>
  summarize(across(
    .cols = c(sspan, totalcorrectsquares),
    .fns = ~mean(.x, na.rm = T)
    ))
```


### **Visualizing a Bar Graph**

# scatter plot

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  filter(wave == 1) |>
  slice(1:30) |>
  ggplot(mapping = aes(x = accuracy_mean, 
                       y = rt_mean
                       )
         ) +
  geom_point() 
```

### **Visualizing a Histogram**

Create a `geom_histogram()` for the response times. Remember that `geom_histogram()` needs only an . By default, the bin number or width of the bins is chosen by ggplot. You can modify your plot in different ways:

- If you want to change the number of bins for the data, modify the `bins` parameter or to change the range of values for the bins, modify `binwidth`;
- If you want to modify the fill color of the bars, modify `fill`;
- If you want to modify the ouline color of the bars, modify `col`;
- If any of the parameters are confusing, read the docs, `?geom_histogram`.

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean)) +
  geom_histogram(
    #mapping = aes(fill = wave),
    #binwidth = 10,
    bins = 100,
    fill = "skyblue",
    col = "black"
    ) +
  theme_minimal()
```

Inspect your distribution and make notes. 


### **Visualizing a Histogram by Target Type**

You don't see the distribution for the Go and No-Go trials. They are all included. In order to see both distributions and be able to compare them, vertically, use `facet_wrap()` to create separate plots for each target type. 

For some guidance, you will need to pass arguments for the facets and the number of columns.

- `facets = vars(the variable associated with the subplot)`
- `ncol = 1`

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean)) +
  geom_histogram(
    alpha = 0.4,
    binwidth = 10,
    color = "black"
    ) +
  facet_wrap(facets = vars(target),
             ncol = 1
  ) +
  theme_minimal()
```

Inspect the distributions. Make note of their characteristics. 





```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean)) +
  geom_density(
#    alpha = 0.4,
    #binwidth = 10,
#    color = "black"
    ) +
  facet_wrap(facets = vars(target),
             ncol = 1
  ) +
  theme_minimal()
```





```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_id |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean,
                       fill = as.factor(wave)
                       )
         ) +
  geom_histogram(
  #  mapping = aes(),
    position = "identity",
    alpha = 0.4,
    #bins = 100,
    binwidth = 10,
    color = "black"
    ) +
  facet_wrap(facets = vars(wave),
             ncol = 1
  ) +
  scale_fill_manual(values = c("black", "red", "blue")) +
  theme_minimal()

MERGE |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean,
                       fill = as.factor(wave)
  )
  ) +
  geom_density(alpha = 0.5) +
  facet_wrap(facets = vars(wave),
             ncol = 1
  ) +
  scale_fill_manual(values = c("black", "red", "blue"))

MERGE |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean,
                       fill = as.factor(wave)
  )
  ) +
  geom_density(alpha = 0.5) +
  facet_grid(wave ~ target) +
  scale_fill_manual(values = c("black", "red", "blue")) +
  theme_minimal()


MERGE |>
  #filter(wave == 1) |>
  ggplot(mapping = aes(x = accuracy_mean,
                       fill = as.factor(wave)
  )
  ) +
  geom_density(alpha = 0.5) +
  facet_grid(wave ~ target) +
  scale_fill_manual(values = c("black", "red", "blue")) +
  theme_minimal()

MERGE |>
  filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean,
                       fill = as.factor(wave)
  )
  ) +
  geom_density(alpha = 0.5) +
  facet_wrap(facets = vars(target), ncol = 1) +
  scale_fill_manual(values = c("black", "red", "blue")) +
  theme_minimal()



MERGE |>
  filter(wave == 1) |>
  ggplot(mapping = aes(x = rt_mean,
                       fill = as.factor(wave)
  )
  ) +
  geom_density(alpha = 0.5) +
  facet_wrap(facets = vars(target),
             ncol = 1
  ) +
  scale_fill_manual(values = c("black", "red", "blue"))
```  


### **Visualizing a Bar Plot**

```{r, eval=eval_answers, include=include_answers}
GNG_agg_by_trial |>
  #filter(wave == 1) |>
  group_by(target, wave) |>
  summarize(accuracy_mean = mean(na.omit(accuracy_mean)),
            accuracy_mean_med = mean(na.omit(accuracy_median)),
            rt_mean = mean(na.omit(rt_mean)),
            #rt_med = mean(na.omit(rt_mean))
            rt_mean_med = mean(na.omit(rt_median)),
            ) |>
  ggplot(mapping = aes(x = target,
                       y = rt_mean
                       )
         ) +
  geom_col(mapping = aes(fill = target))
```






Where is group performance? 

```{r}
# create the subgroup for the plot below
data2 <- GNG_AGG_by_group |>
  filter(wave == 1) |>
  mutate(rt = rt_mean_mean) |>
  mutate(wave = as.factor(wave))

# rt
GNG_AGG_by_id |>
  filter(wave == 1) |>
  mutate(rt = rt_mean) |>
  mutate(wave = as.factor(wave)) |>
  ggplot(mapping = aes(
    x = target,
    y = rt
  )) +
  geom_point(position = position_jitter(),
             alpha = .5
             ) +
  geom_point(data = data2,
             mapping =  aes(y = rt,
                            x = target
                            ),
             col = "red",
             size = 4,
             alpha = .5
  )
```




### **Visualizing a Histogram**

```{r, eval=eval_answers, include=include_answers}

```


### **Visualizing a Point Plot**

```{r, eval=eval_answers, include=include_answers}

```

### **Visualizing a Point Plot with Group Means**

```{r, eval=eval_answers, include=include_answers}

```



```{r, eval=eval_answers, include=include_answers}
#2. Using the same data, now that your data are aggregated at the participant level, aggregate across all participants for overall group data by wave and trial type (e.g, go vs. no-go trials) to generate a summary data frame containing the mean, median, and standard deviation across `accuracy` and `rt` so that you have the group-level summary statistics (over all participants), at each wave, and for both go and no-go trial. 

GNG_CLEAN |>
  select(c(id_subject, wave, w1age, target, accuracy, rt)) |>
  group_by(id_subject, wave, target) |>
  summarise(across(.cols = c("rt", "accuracy"),  
                   .fns = summarize_across[c(1, 2, 5)],
                   .names = "{.col}_{.fn}"
                   )
            ) |>
  group_by(wave, target) |>
  summarise(across(.cols = c("rt_mean", "accuracy_mean"),  
                   .fns = summarize_across[c(1, 2, 5)],
                   .names = "{.col}_{.fn}"
                   )
            ) |>
  ungroup() |>
  view_html()
```








3b. Using the `sspan_long_cleaned.Rds` data, generate a summary data frame containing the mean, median, and standard deviation across `sspan` and `totalcorrectsquares` by wave. 

```{r, eval=eval_answers, include=include_answers}
the_vars <- c("sspan", "totalcorrectsquares") 
#SSPAN_CLEAN |> view_html()

SSPAN_CLEAN |>
  filter(!is.na(correct)) |>
  select(c(id_subject, wave, the_vars)) |>
  group_by(wave) |>
  summarise(across(.cols = the_vars,  
                   .fns = summarize_across[c(1, 2, 5)],
                   .names = "{.col}_{.fn}"
                   ), 
            .groups = "drop"
            ) |>
  ungroup() |>
  view_html()
```


4. Summarize your data set in a different way.

```{r, eval=eval_answers, include=include_answers}

```
