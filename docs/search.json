[
  {
    "objectID": "syllabus/syllabus.html",
    "href": "syllabus/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Semester\nSpring 2024\n\n\nSection\nPSYC 166, Sect-01\n\n\nDay Time\nThursday 2:45 - 05:30PM (Pacific)\n\n\nLocation\nLocation: Roberts North, 105\n\n\nOffice Hours\nT: 1-2pm\n\n\nInstructor\nGabriel I. Cook\n\n\nContact\nDiscord (preferred) or Email: gcook@CMC.edu (please put ’PSYC 166 in subject line)\n\n\nCredit\n3 hours; 1 credits"
  },
  {
    "objectID": "syllabus/syllabus.html#course-description",
    "href": "syllabus/syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course introduces students to R, a programming language for statistical computing and graphics. Students will learn how to clean, manipulate, transform, join, and tidy data sets to prepare for statistical modeling. Supervised (e.g., regression) and unsupervised (e.g., clustering) approaches will be applied to understand simple and complex relationships between cognitive and non-cognitive variables (e.g., biology, aging, education, socioeconomic, health, etc.). Students will apply their skills to wrangle, explore, and model relevant data sets for a hands-on project for local scholars, offices, organizations, or industry participants. Data sets and relevant readings will change depending on semester.\nPrerequisite: PSYC109 CM or equivalent; recommended a course in Cognitive Psychology or Cognitive Science; or permission of instructor; not open to students who have completed CSCI 36 or any other introductory course in foundation of data science.\n\nCourse Specific Learning Goals\n\nUnderstand various forms of cognitive functioning, how they are measured, and how those abilities relate with other variables\nLearn how to use R and RStudio to answer real‐word questions with data\nUse the {dplyr} and {tidyr} libraries to clean data prior to statistical analysis\nLearn how to import, clean, manipulate, tidy, and summarize data\nExamine relationships among cognitive and non-cognitive variables by applying statistical methods and models to data\nPractice using statistical probability and inference\nLearn how to examine relationships among variables and apply statistical methods and models to data (e.g., supervised or unsupervised machine‐learning methods)\nVisualize data and/or model parameters\nLearn how to manage local and remote projects and collaborate with others\nPractice scientific writing integrating data with theory\nCreate dynamic and reproducible reports with R Markdown\n\nThe following departmental learning goals will also be met: 1. Knowledge of major concepts in cognitive psychology; 2. Understanding of research methods in psychology, including research design, data analysis and interpretation; 3. Development of critical-thinking skills and use of the scientific approach to solve problems related to behavior and mental processes; 4. Oral and written communication skills."
  },
  {
    "objectID": "syllabus/syllabus.html#courses-at-cmc",
    "href": "syllabus/syllabus.html#courses-at-cmc",
    "title": "Syllabus",
    "section": "Courses at CMC",
    "text": "Courses at CMC\n\nFaculty Handbook 5.4.2 Work Load in Classes\n“Courses should involve approximately equal workloads. Generally, students should expect to spend from 6 to 8 hours per week, over and above the time spent in classroom, on each course.” – CMC Faculty Handbook\nIf you do the math, including class time of 2½ hours, you should expect to allocate 8 ½ to 10 ½ hours per week for courses at CMC. “Per week” is a key phrase; courses are not designed for nondistributed cramming."
  },
  {
    "objectID": "syllabus/syllabus.html#course-materials-and-textbook",
    "href": "syllabus/syllabus.html#course-materials-and-textbook",
    "title": "Syllabus",
    "section": "Course Materials and Textbook",
    "text": "Course Materials and Textbook\nAll of the course materials will be available on this course website .\nLink to the course website: https://gabrielcook.xyz/fods24/\n\nRequired Equipment:\nComputer: current Mac (macOS) or PC (Windows or Linux) with high-speed internet connection, capable of running R and RStudio\n\n\nRequired Software:\nR and RStudio: Students will be required to use R and RStudio software. Note: Install Version will be provided. Before installing RStudio, you must also download and install the base R software at https://www.r-project.org/ that is appropriate for your computer’s operating system. RStudio can be downloaded for free at https://www.rstudio.com. You are expected to install R and RStudio on your personal computer by downloading the software from the links above. You will also have to install appropriate libraries throughout the course. Further instructions will be provided.\n\n\nReading Materials/Textbook(s)\nReadings will be taken from different sources and will appear in each topic module.\n\n[R4DS] Grolemund and Wickham (2016): R for Data Science. Electronic version.\n[FODS] Huber (2020): Foundations of Data Science.\nNordmann, E. & DeBruine, L. (2023). Applied Data Skills: Processing & Presenting Data (2023) . https://psyteachr.github.io/ads-v2\n[DSRR] Data Skills for Reproducible Research: Electronic version.\n[Data Skills](https://psyteachr.github.io/data-skills-v2/\nCognition readings for project topics will be available on Canvas/Sakai\n\nThese textbooks are free and open-source."
  },
  {
    "objectID": "syllabus/syllabus.html#overview",
    "href": "syllabus/syllabus.html#overview",
    "title": "Syllabus",
    "section": "Overview",
    "text": "Overview\nStudents will read materials covering data-set relevant cognitive functions or abilities and tasks or tools used to measure those abilities. They will also will learn about coding in R, data validation and wrangling, and support their current knowledge of statistical probability and inference.\nCoding for Data Science: Students will be introduced to functional programming using R, application of models, and use of popular data-science libraries, (e.g., dplyr, ggplot, stringr, etc.). Students would learn elements of programming (e.g., assignment, functions, function arguments, operators, objects, passing objects, control flow, etc.).\nData Validation and Wrangling: Students will learn how to wrangle raw data, clean, and manipulate data. The course would involve both data wrangling and data cleaning. Students would learn main concepts of data sanitation of messy data, for example, how to clean, recode, de-dup, fix structural errors and typos, standardize data, etc. in service of applying machine-learning models.\nStatistical Probability & Inference: Students may not have much experience with formal statistics so they would learn about probability, error, confidence intervals, and frequentist inference in order to interpret data. They would also have to specify models for machine learning, for example, multiple regression.\nMachine Learning: The goal is to introduce students to supervised and unsupervised machine learning applications in order to understand relationships among variables and for classifying and segmenting. For example, supervised learning (e.g., correlation, regression, multiple regression, and if time support-vector machines for nonlinear classification) would be used for understanding relationships among cognitive variables, non-cognitive variables, and to identify groups. Unsupervised learning (e.g., hierarchical clustering, dimension reduction) would be used to understand to data segmentation.\nProject Management: Projects for academics and industry involve collaboration as well as organization of code and materials. Students will learn about and maintain a project with an organized directory structure both locally and remotely with collaborators using Git and GitHub.\nAcademic Integrity. Although you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated.\nMany students are unclear of the definition of plagiarism and for that reason I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\nCourse Modules. This course will be split into modules, allocating various weeks depending on the scope of the module."
  },
  {
    "objectID": "syllabus/syllabus.html#course-structure",
    "href": "syllabus/syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nThe assumption is that students possess varying levels of skills related to programming. Nevertheless, students are expected to attend class prepared to engage with and practice concepts related to readings and lectures. Prior to class, students should have completed readings (e.g., modules or readings referenced therein) and watched any associated lectures on the material. Class time will involve answering questions raised by students, a mining lecture, and coding activities that will inform the final project (note, concepts build). Homework assignments will also involved engagement with the project data. Class time will be spent engaging in a variety of tasks and activities, including lectures, group-work, applied coding activities, presentations, and discussions."
  },
  {
    "objectID": "syllabus/syllabus.html#course-schedule",
    "href": "syllabus/syllabus.html#course-schedule",
    "title": "Syllabus",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\n\n\n\n\n\n\n\n\n\nDate\nWeek\nModule\nTopic\n\n\n\n\n01-18\n1\n1\nIntroduction to R, RStudio, and R Markdown\n\n\n01-25\n2\n2\nData Mise en Place (Project Management), Git & GitHub\n\n\n02-01\n3\n3\nFunctions, Parameters, Arguments, and Scripts\n\n\n\n3\n4\nVectors and Data Frame Basics\n\n\n02-08\n4\n5\nImporting and Exporting Data / Vectors and Data Frame Basics\n\n\n\n4\n6\nVariables and Measures of Cognition\n\n\n02-15\n5\n7\nManipulating Data Frames (Selecting, Filtering, & Mutating)\n\n\n\n5\n8\nWorking with Cognitive Task Data\n\n\n02-22\n6\n9\nGrouping and Summarizing Data\n\n\n\n6\n10\nSummarizing Cognitive Task Data\n\n\n03-01\n7\n11\nTransforming Data Frames (Pivoting)\n\n\n\n7\n12\nVisualizing Data\n\n\n03-07\n8\n13\nJoining Relational Data\n\n\n03-14\n9\n-\nSpring Break (no class)\n\n\n03-21\n10\n-\nMid-Term Presentation\n\n\n03-28\n11\n14\nExamining Relationships in Variables of Cognition\n\n\n\n11\n15\nStrings and Factors\n\n\n04-04\n12\n16\nDiscuss Appropriate Models Related to Cognition Readings\n\n\n\n12\n16\nCont.\n\n\n04-11\n13\n17\nLinear Model Testing\n\n\n04-18\n14\n18\nExploratory Data Analysis\n\n\n\n14\n18\nCont.\n\n\n04-25\n-\n-\nProject Week\n\n\n05-02\n-\n-\nPresentation (Last day of Instruction)"
  },
  {
    "objectID": "syllabus/syllabus.html#assignments-and-grading",
    "href": "syllabus/syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThis is an engagement and skills-acquisition based course. At the beginning of the course and throughout, students will be given instruction on building and maintaining a website using quarto and github pages. Each week students will contribute blog posts and other content to their websites in response to module assignments. Students will be expected to submit URL links to their blogs using Blackboard. Students are expected to attend and participate in each class. The final project includes conducting, communicating, and preserving a reproducible data analysis project.\n\nEvaluation and Grading\n\n\n\n\n\nItem\nTotal Points (%)\n\n\n\n\nKnowledge Assessments\n10%\n\n\nWeekly Conceptual and Programming\n30%\n\n\nMidterm Presentation\n20%\n\n\nFinal Project (Pres and Report)\n40%\n\n\n\n\n\nPercentage grades are converted to letter grades according to the following rubric.\n\n\n\n\n\nLetter\nPoint Range\n\n\n\n\nA\n94 - 100\n\n\nA-\n90 - 93.99\n\n\nB+\n87 - 89.99\n\n\nB\n84 - 86.99\n\n\nB-\n80 - 83.99\n\n\nC+\n77 - 79.99\n\n\nC\n74 - 76.99\n\n\nC-\n70 - 73.99\n\n\nD+\n67 - 69.99\n\n\nD\n64 - 66.99\n\n\nD-\n60 - 63.99\n\n\nF\n0 - 59.99"
  },
  {
    "objectID": "syllabus/syllabus.html#attendance",
    "href": "syllabus/syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\nStudents are expected to attend and participate in each class."
  },
  {
    "objectID": "syllabus/syllabus.html#course-policies",
    "href": "syllabus/syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nDue dates\nDue dates are suggestions for completing coursework on a weekly basis. You may be able to work ahead, but you are not encouraged to fall behind.\nYou should email me if you have an exceptional circumstance preventing you from taking an assessment during an assessment week.\n\n\nChanges to the syllabus\nThe syllabus may be updated for clarity or to make adjustments for pedagogical purposes. The most current version of the syllabus is always available from the course website.\n\n\nAccessibility\nIn order to receive disability-related academic accommodations students must first be registered with the Center for Student Disability Services. Students who have a documented disability or suspect they may have a disability are invited to set up an appointment with the Director of the Center for Student Disability Services, at 718-951-5538. If you have already registered with the Center for Student Disability Services, please provide your professor with the course accommodation form and discuss your specific accommodation with him/her.\n\n\n\nEmail Correspondence\nI will regularly use e-mail but you should contact me on the Discord channel, which is where I will post announcements, changes in the syllabus, reminders, etc. You are responsible for monitoring Discord and e-mail regularly.\nIf you have questions, please message me on Discord. If you need to e-mail me:\n\nAlways add ’PSYC 166” to the subject line\nemail me at: gcook@cmc.edu"
  },
  {
    "objectID": "syllabus/syllabus.html#universitys-policy-on-academic-integrity",
    "href": "syllabus/syllabus.html#universitys-policy-on-academic-integrity",
    "title": "Syllabus",
    "section": "University’s policy on Academic Integrity",
    "text": "University’s policy on Academic Integrity\nThe faculty and administration of Claremont McKenna College support an environment free from cheating and plagiarism. Each student is responsible for being aware of what constitutes cheating and plagiarism and for avoiding both.\n\nViolations of Academic integrity\nEach student is responsible for understanding and acting in accordance with the College’s policy on Academic Integrity, described below.\n\n\nAcademic Integrity\nAlthough you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty, even those raised by concerned peers, will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated. Many students are unclear of the definition of plagiarism so I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course and would be a violation of integrity. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\n\nStatement of Reasonable Accommodations\nYour experience in this class is important to me. If you have already established accommodations with Disability & Accessibility Services at CMC, please communicate your approved accommodations to me during the first week of the semester so we can discuss your needs in this course ASAP. You can start this conversation by forwarding me your accommodation letter. If you have not yet established accommodations through Accessibility Services but have a temporary health condition or permanent disability (conditions include but are not limited to: mental health, attention-related, learning, vision, hearing, physical or health), you are encouraged to contact Assistant Dean for Disability Services & Academic Success, Kari Rood, at AccessibilityServices@cmc.edu to ask questions and/or begin the process. General information and accommodations request information be found at the CMC DOS Accessibility Service’s website. Please note that arrangements must be made with advance notice in order to access the reasonable accommodations. You are able to request accommodations from CMC Accessibility Services at any point in the semester. Be mindful that this process may take some time to complete and accommodations are not retroactive. I would err on the side of caution and make sure your accommodations are sent to me even if you do not believe you need them as some students only learn they may need time after completing assessment. The Americans With Disabilities Act (ADA) and Section 504 of the Rehabilitation Act do not make accommodations retroactive. If you are approved for extra testing time for example, you must do so before an electronic assessment is posted in order for it to be integrated into the assessment. Claremont McKenna College values creating inclusive and accessible learning environments consistent with federal and state law. If you are not a CMC student, please connect with the Disability & Accessibility Services Coordinator on your campus regarding a similar process.\n\n\n\nFYI on cheating etc.\nRemember, you are responsible for not cheating or violating CMC’s Academic Integrity Policy. You are responsible for understanding that policy, and for conducting yourself in a manner such that you do not violate the policy.\nThe above link lists many examples of cheating and plagiarism that are not allowed. There are many more specific acts that you should NOT do. Here is an additional list of activities that will be sufficient cause for immediate failure in the course.\n\nDo not take pictures of exam or quiz questions and share them with other students\nDo not give other students answers during an exam or quiz, or any other assignment that is an individual assignment\nDo not copy work from another source and submit it as your own\nDo not copy and paste text from the internet and submit it as your own words\nDo not copy and paste text and slightly alter wording to pass the work off as your own\nDo not hire someone else to do the coursework for you\nDo not copy and paste text into a paraphrasing app, and then submit the output of the paraphrasing app as your own work\nDo not copy random words from the internet that have nothing to do with the assignment and submit them as your own work.\nDo not work on individual assignments with other students, share answers or other material, and then all hand in versions of the same thing that are slightly different.\nDo not plagiarize yourself by submitting work that you have previously completed in another class.\n\n\n\nMandate to report violations\nIf a faculty member suspects a violation of academic integrity and, upon investigation, confirms that violation, or if the student admits the violation, the faculty member MUST report the violation. Students should be aware that faculty may use plagiarism detection software.\nThere is no excuse for cheating. Students who are caught cheating may receive a failing grade for the entire course. All students found to have violated the academic integrity will be sanctioned by the Academic Standards Committee."
  },
  {
    "objectID": "syllabus/syllabus.html#faq",
    "href": "syllabus/syllabus.html#faq",
    "title": "Syllabus",
    "section": "FAQ",
    "text": "FAQ\nIf you have questions about the syllabus, let’s talk about it in class, and/or please create a thread to discuss the question on Discord."
  },
  {
    "objectID": "slides/sample.html#step-1",
    "href": "slides/sample.html#step-1",
    "title": "Sample Presentation",
    "section": "Step 1",
    "text": "Step 1\n\nSplit slides up with level 2 headers: ## Heading 2\nAdd some markdown + text and/or some R/Python code"
  },
  {
    "objectID": "slides/sample.html#some-r-code",
    "href": "slides/sample.html#some-r-code",
    "title": "Sample Presentation",
    "section": "Some R Code",
    "text": "Some R Code\n\n2 + 2\n\n[1] 4\n\n# comment"
  },
  {
    "objectID": "slides/sample.html#slide-title",
    "href": "slides/sample.html#slide-title",
    "title": "Sample Presentation",
    "section": "Slide Title",
    "text": "Slide Title\n\none\ntwo"
  },
  {
    "objectID": "slides/sample.html#make-this-slide-red",
    "href": "slides/sample.html#make-this-slide-red",
    "title": "Sample Presentation",
    "section": "Make this slide Red",
    "text": "Make this slide Red"
  },
  {
    "objectID": "slides/sample.html#making-a-slide-incremental",
    "href": "slides/sample.html#making-a-slide-incremental",
    "title": "Sample Presentation",
    "section": "Making a Slide Incremental",
    "text": "Making a Slide Incremental\nSay you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.\n\nThen add some content…\n\n\nThen some more content"
  },
  {
    "objectID": "slides/sample.html#omit-this-slide-visibility-hidden",
    "href": "slides/sample.html#omit-this-slide-visibility-hidden",
    "title": "Sample Presentation",
    "section": "Omit This Slide {visibility = “hidden”}",
    "text": "Omit This Slide {visibility = “hidden”}"
  },
  {
    "objectID": "slides/sample.html#add-links",
    "href": "slides/sample.html#add-links",
    "title": "Sample Presentation",
    "section": "Add links",
    "text": "Add links\n\ncmc\n\n\n\nFirst item\nSecond item"
  },
  {
    "objectID": "slides/sample.html#fragments",
    "href": "slides/sample.html#fragments",
    "title": "Sample Presentation",
    "section": "Fragments",
    "text": "Fragments\n\nFade in\n\n\nFade out\n\n\nHighlight red\n\n\nFade in, then out"
  },
  {
    "objectID": "slides/sample.html#fragments-nesting",
    "href": "slides/sample.html#fragments-nesting",
    "title": "Sample Presentation",
    "section": "Fragments, nesting",
    "text": "Fragments, nesting\n\n\n\nFade in &gt; Turn red &gt; Semi fade out"
  },
  {
    "objectID": "slides/sample.html#fragments-spans",
    "href": "slides/sample.html#fragments-spans",
    "title": "Sample Presentation",
    "section": "Fragments, spans",
    "text": "Fragments, spans\nThis is an important sentence!\nMind the gap when riding the rail!"
  },
  {
    "objectID": "slides/sample.html#column-layout",
    "href": "slides/sample.html#column-layout",
    "title": "Sample Presentation",
    "section": "Column layout",
    "text": "Column layout\n\n\ncontents…s\n\ncontents…"
  },
  {
    "objectID": "slides/sample.html#output-location",
    "href": "slides/sample.html#output-location",
    "title": "Sample Presentation",
    "section": "Output Location",
    "text": "Output Location\n\n\nlibrary(ggplot2)\n\nmtcars |&gt; \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\")"
  },
  {
    "objectID": "slides/02_git_slides.html#what-is-version-control-for",
    "href": "slides/02_git_slides.html#what-is-version-control-for",
    "title": "Git and GitHub",
    "section": "What is version control for?",
    "text": "What is version control for?\n\n\nProject backup\nGit monitors/controls file versions (empty directories).\nSee specific changes inside files\nUndo changes (time machine)\nVersion Control Summary Video"
  },
  {
    "objectID": "slides/02_git_slides.html#version-control-git-workflow-basics",
    "href": "slides/02_git_slides.html#version-control-git-workflow-basics",
    "title": "Git and GitHub",
    "section": "Version Control: Git Workflow Basics",
    "text": "Version Control: Git Workflow Basics\nThere are 4 main parts to Git Workflow:\n\n\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)\nPush for sending commits to remote repo (on GitHub)\n\n\nOther: Merge for merging branches (i.e., to incorporate your edits into main)\nVideo of Version Control Workflow Basics\n\n\n\n## **Git: Image Version**\n\n@[understanding git through images](https://dev.to/nopenoshishi/understanding-git-through-images-4an1)"
  },
  {
    "objectID": "slides/02_git_slides.html#connecting-git-to-github-the-rstudio-terminal",
    "href": "slides/02_git_slides.html#connecting-git-to-github-the-rstudio-terminal",
    "title": "Git and GitHub",
    "section": "Connecting Git to GitHub: The RStudio Terminal",
    "text": "Connecting Git to GitHub: The RStudio Terminal\n\n\nConfigure Git and GitHub in RStudio Terminal\nCreate token\nSet token\nCan use the RStudio Gui (clunky though)"
  },
  {
    "objectID": "slides/02_git_slides.html#configuring-git-and-github-with-usethis",
    "href": "slides/02_git_slides.html#configuring-git-and-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Configuring Git and GitHub with {usethis}",
    "text": "Configuring Git and GitHub with {usethis}\n\nusethis::use_git_config(user.name = \"janegit\", \n                        user.email = \"jane_git@gitrdone.com\"\n                        )"
  },
  {
    "objectID": "slides/02_git_slides.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "href": "slides/02_git_slides.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Creating a Personal Access Token (PAT) for GitHub with {usethis}",
    "text": "Creating a Personal Access Token (PAT) for GitHub with {usethis}\n\n\nusethis::create_github_token()\nCreate token and copy to your clipboard"
  },
  {
    "objectID": "slides/02_git_slides.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "href": "slides/02_git_slides.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "title": "Git and GitHub",
    "section": "Setting your Git Credentials (using PAT) with {gitcreds}",
    "text": "Setting your Git Credentials (using PAT) with {gitcreds}\n\n\ngitcreds::gitcreds_set()\nChoose option to either set or replace\nAt ? Enter new password or token, paste PAT to set\ngh::gh_whoami() to check if set"
  },
  {
    "objectID": "slides/02_git_slides.html#some-basic-commands",
    "href": "slides/02_git_slides.html#some-basic-commands",
    "title": "Git and GitHub",
    "section": "Some Basic Commands",
    "text": "Some Basic Commands\n\nFork: to make a copy of a repo in your own GitHub account\nClone: make a copy of the your GitHub repo on your local computer. * copies a remote repo to create a local repo with a remote called origin automatically set up."
  },
  {
    "objectID": "slides/02_git_slides.html#some-basic-commands-cont.",
    "href": "slides/02_git_slides.html#some-basic-commands-cont.",
    "title": "Git and GitHub",
    "section": "Some Basic Commands (Cont.)",
    "text": "Some Basic Commands (Cont.)\n\nPull: incorporates changes into your repo from remote\nAdd: adds snapshots of your changes to the “Staging” area.\nCommit: takes the files as they are in your staging area and stores a snap shot of your files (changes) permanently in your Git directory\nPush: uploads your files (changes) to the remote repo\nStatus: checks the status of a repo changes, etc."
  },
  {
    "objectID": "slides/02_git_slides.html#some-basic-commands-cont.-1",
    "href": "slides/02_git_slides.html#some-basic-commands-cont.-1",
    "title": "Git and GitHub",
    "section": "Some Basic Commands (Cont.)",
    "text": "Some Basic Commands (Cont.)\n\nMerge: incorporates changes into the branch you are on.\nPull Request: By “issuing a pull request” to the owner of the upstream repo, you are requesting that your changes be pulled into their repo (accept your changes/work)."
  },
  {
    "objectID": "slides/02_git_slides.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "slides/02_git_slides.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Git and GitHub",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\n\nMake a change to a file, save to local computer\nCheck status of project for changes\nAdd/Stage change\nCommit change(s)\nPush changes\nPull pulls changes down from repo (downloads and merges changes)"
  },
  {
    "objectID": "slides/02_git_slides.html#checking-the-status-of-local-file-changes",
    "href": "slides/02_git_slides.html#checking-the-status-of-local-file-changes",
    "title": "Git and GitHub",
    "section": "Checking the Status of Local File Changes",
    "text": "Checking the Status of Local File Changes\nAt the Terminal in RStudio\n\n$ git status"
  },
  {
    "objectID": "slides/02_git_slides.html#shared-repository-workflow",
    "href": "slides/02_git_slides.html#shared-repository-workflow",
    "title": "Git and GitHub",
    "section": "Shared Repository Workflow",
    "text": "Shared Repository Workflow\n\n\nPull recent changes from main: git pull\nMake changes to files\nStage your changes: git add\nCommit changes locally: git commit -m \"description of changes\"\nUpload your new the changes to GitHub: git push"
  },
  {
    "objectID": "slides/02_git_slides.html#staging-changes-adding-changes",
    "href": "slides/02_git_slides.html#staging-changes-adding-changes",
    "title": "Git and GitHub",
    "section": "Staging Changes (Adding Changes)",
    "text": "Staging Changes (Adding Changes)\n\n\nStaging and Committing\n\nUntracked vs. tracked files\nTo have tracked by Git, you need to add"
  },
  {
    "objectID": "slides/02_git_slides.html#staging-a-specific-change",
    "href": "slides/02_git_slides.html#staging-a-specific-change",
    "title": "Git and GitHub",
    "section": "Staging a Specific Change",
    "text": "Staging a Specific Change\n\n\n$ git add &lt;file&gt;... such that &lt;file&gt; refers to the file name\nfile might be in a directory, e.g., r/\n$ git add r/yourname.R\nTab to auto-complete, e.g., git add r/you{TAB}"
  },
  {
    "objectID": "slides/02_git_slides.html#staging-all-changes",
    "href": "slides/02_git_slides.html#staging-all-changes",
    "title": "Git and GitHub",
    "section": "Staging All Changes",
    "text": "Staging All Changes\n\n$ git add ."
  },
  {
    "objectID": "slides/02_git_slides.html#committing-the-changes",
    "href": "slides/02_git_slides.html#committing-the-changes",
    "title": "Git and GitHub",
    "section": "Committing the Change(s)",
    "text": "Committing the Change(s)\n\n\ngit commit is used to commit the changes\nadd -m to tell git you want a message (e.g., \"my message here\")\n\n$ git commit -m \"added my first .R file\""
  },
  {
    "objectID": "slides/02_git_slides.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "href": "slides/02_git_slides.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Push (publish) the change(s) from your branch to the remote repository",
    "text": "Push (publish) the change(s) from your branch to the remote repository\n\n\n$ git push\nPushing changes"
  },
  {
    "objectID": "slides/02_git_slides.html#pulls-changes-from-the-remote-repository",
    "href": "slides/02_git_slides.html#pulls-changes-from-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Pulls change(s) from the remote repository",
    "text": "Pulls change(s) from the remote repository\n\n\n$ git pull\nIf you make changes that other will need, let them know to pull"
  },
  {
    "objectID": "slides/02_git_slides.html#git-client-video-tutorials",
    "href": "slides/02_git_slides.html#git-client-video-tutorials",
    "title": "Git and GitHub",
    "section": "Git Client Video Tutorials",
    "text": "Git Client Video Tutorials\n\n\nGitKraken Git Client examples\nfor more, see: this video"
  },
  {
    "objectID": "slides/02_git_slides.html#videos-of-many-things-you-can-do",
    "href": "slides/02_git_slides.html#videos-of-many-things-you-can-do",
    "title": "Git and GitHub",
    "section": "Videos of many things you can do",
    "text": "Videos of many things you can do\nIf interested, see gittower YouTube"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#r-is-an-interpreted-language",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#r-is-an-interpreted-language",
    "title": "R, RStudio, & Rmarkdown",
    "section": "R is an Interpreted Language",
    "text": "R is an Interpreted Language\n\n\ncode or programs you write execute in real time\nby he R interpreter that translates your code\ncode does not need to be compiled prior to being executed"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#r-involves-functional-programming",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#r-involves-functional-programming",
    "title": "R, RStudio, & Rmarkdown",
    "section": "R involves functional programming",
    "text": "R involves functional programming\n\n\nhttps://en.wikipedia.org/wiki/Functional_programming\nprograms are constructed by applying and composing functions\nfunctions:\n\nmean()\ndplyr::summarize()"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Some basics",
    "text": "Some basics\n\n\nnumeric objects (e.g., 2024, 21.2)\nstrings/character objects:\n\ncomposed of letters\nenclosed by quotes (e.g., \"Sam\", \"Male\", \"21\")\n\nvector objects:\n\ncollections of objects (e.g., c(\"18\", \"23\", \"20\"))\n\ndata frames:\n\ncollections of vectors"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Some basics (cont.)",
    "text": "Some basics (cont.)\n\n\nwe assign objects to names/names to objects\n\nages &lt;- c(\"18\", \"23\", \"20\")\n\nwe perform functions on objects:\n\nas.numeric(ages)\noften by assigning or reassigning:\n\nages &lt;- as.numeric(ages)"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.-1",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#some-basics-cont.-1",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Some basics (cont.)",
    "text": "Some basics (cont.)\n\n\nwe inspect object contents\n\nages\nand get something returned: [1] 18 23 20\n\nwe perform more functions on objects:\n\nmean(ageas.numeric(ages))\n[1] 20.33333\n\nwe model data frames"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#open-rstudio",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#open-rstudio",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Open RStudio",
    "text": "Open RStudio\n\n\nfind the Console\nfind the Terminal\nfind ‘environment’ in pane\nfind ‘history’ in pane\nfind ‘help’ in pane\nfind ‘files’ in pane\nfind ‘plots’ in pane"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-code-in-the-r-console",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-code-in-the-r-console",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Write some code in the R console",
    "text": "Write some code in the R console\n\n\n\nyear &lt;- 2024\n\n\n\n\ncode\nyear &lt;- 2024\n\n\n\nassign objects to names using &lt;-, not ="
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#write-more-code-in-the-r-console",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#write-more-code-in-the-r-console",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Write more code in the R console",
    "text": "Write more code in the R console\n\n\n\nages &lt;- c(18, 22, 24)\n\n\n\n\ncode\nages &lt;- c(18, 22, 24)\n\n\n\n[1] 18 22 24"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#rstudio",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#rstudio",
    "title": "R, RStudio, & Rmarkdown",
    "section": "RStudio",
    "text": "RStudio\n\nIDE for using R\nmake for a better coding experience\nlots of extras\n\nbetter UI, markdown, Terminal, Git, code snippets"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#r-markdown",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#r-markdown",
    "title": "R, RStudio, & Rmarkdown",
    "section": "R Markdown",
    "text": "R Markdown\n\n\nMarkdown is a lightweight markup language used for adding formatting elements to plain text text\nR Markdown is a markdown language create for R and RStudio\nAllows you to dress up text, embed and render code, reference hyperlinks, etc. within a written document\nLibraries like {rmarkdown} and {knitr} help you build HTML, pdf, and Word documents that update automatically with new data"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#create-an-r-markdown-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#create-an-r-markdown-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Create an R Markdown File",
    "text": "Create an R Markdown File\n\n\nCreate directory/folder named: fods24\nFile &gt; New File &gt; R Markdown\nName it: my_first_markdown.Rmd\nSave in: /fods24\nNOTE: Directories will be addressed for next week!"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-text-in-the-r-markdown-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#write-some-text-in-the-r-markdown-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Write some text in the R Markdown File",
    "text": "Write some text in the R Markdown File\n\nMy name is X and the year I start learning R is Y."
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#dressing-up-text",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#dressing-up-text",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Dressing up Text",
    "text": "Dressing up Text\n\n\nItalics: wrap text in *\n\n*italics*\n\nBold: wrap text in **\n\n**bold**\n\nBold Italics: wrap text in ***\n\n***bold italics***"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-and-embed-code-block",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-and-embed-code-block",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Insert and Embed Code Block",
    "text": "Insert and Embed Code Block\n\n\n```{r}\n\n```\n\n\n\n\nWindows: CLTR+ALT+I\nMac: COMMAND+ALT+I"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#create-code-in-block-assign-value-to-year",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#create-code-in-block-assign-value-to-year",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Create Code in Block: Assign value to year ",
    "text": "Create Code in Block: Assign value to year \n\n\n```{r}\nyear &lt;- 2024\n```\n\n\n\n\ncode\nyear &lt;- 2024"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#code-block-settings",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#code-block-settings",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Code block settings",
    "text": "Code block settings"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#create-a-code-block-write-some-code",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#create-a-code-block-write-some-code",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Create a code block + write some code",
    "text": "Create a code block + write some code\n\n\n```{r}\nband &lt;- \"your favorite band\"\nstate &lt;- \"the state in which you grew up\"\nname &lt;- \"your name\"\n```"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Embed code in-line (inside text)",
    "text": "Embed code in-line (inside text)\n\n\nIf you have an object in R\nYou can render the object in text\nAnd dress up the text"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-1",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-1",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Embed code in-line (inside text)",
    "text": "Embed code in-line (inside text)\n\nIf you have an object in R\nYou can render the object in text\nAnd dress up the text\n\n\n\nThe year is `r year`!"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-2",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#embed-code-in-line-inside-text-2",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Embed code in-line (inside text)",
    "text": "Embed code in-line (inside text)\n\nIf you have an object in R\nYou can render the object in text\nAnd dress up the text\n\n\n\nThe year is `r year`!\n\n\nThe year is 2024!"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#modify-your-text-in-the-r-markdown-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#modify-your-text-in-the-r-markdown-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Modify your text in the R Markdown File",
    "text": "Modify your text in the R Markdown File\n\n\nmake the year change by using inline code\nmake sure your inline code is after you assign the object"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#add-header-sections-and-subsections-using",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#add-header-sections-and-subsections-using",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Add header sections and subsections using #",
    "text": "Add header sections and subsections using #\n# About me\n## My favorite band\n### My favorite band from the 1990s"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-hyperlinks",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#insert-hyperlinks",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Insert hyperlinks",
    "text": "Insert hyperlinks\n\n\n[message](url)\n[cheatsheet](https://gabrielcook.xyz/fods24/cheatsheets/rmarkdown-2.0.pdf)\ncheatsheet"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#knitting-r-markdown-files",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#knitting-r-markdown-files",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Knitting R Markdown Files",
    "text": "Knitting R Markdown Files\n\n\nAs HTML\nAs pdf\nAs Word"
  },
  {
    "objectID": "slides/01_intro_rstudio_rmarkdown_slides.html#locate-the-html-file",
    "href": "slides/01_intro_rstudio_rmarkdown_slides.html#locate-the-html-file",
    "title": "R, RStudio, & Rmarkdown",
    "section": "Locate the HTML file ",
    "text": "Locate the HTML file \n\nmy_first_markdown.html"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Project",
    "section": "",
    "text": "For the project, your team will write code in order to prepare, model, and visualize data in order to communicate a story that would address the question(s) proposed by the participating body (viz., liaison) about cognitive functioning. Given the constraints of data to inform this specific question, the project may involve data exploration to tell a story about relationships between variables.\nAny exploratory component allows for a healthy dose of flexibility in team creativity. This open element will also allow teams to develop ideas independently, thereby producing stories that will likely diverge wildly from each other, making the project an exciting foray into data storytelling for many students."
  },
  {
    "objectID": "project/index.html#project-description",
    "href": "project/index.html#project-description",
    "title": "Project",
    "section": "",
    "text": "For the project, your team will write code in order to prepare, model, and visualize data in order to communicate a story that would address the question(s) proposed by the participating body (viz., liaison) about cognitive functioning. Given the constraints of data to inform this specific question, the project may involve data exploration to tell a story about relationships between variables.\nAny exploratory component allows for a healthy dose of flexibility in team creativity. This open element will also allow teams to develop ideas independently, thereby producing stories that will likely diverge wildly from each other, making the project an exciting foray into data storytelling for many students."
  },
  {
    "objectID": "project/index.html#team-membership-and-roles",
    "href": "project/index.html#team-membership-and-roles",
    "title": "Project",
    "section": "Team Membership and Roles",
    "text": "Team Membership and Roles\nA team of students will work with a project liaison to develop the project and work together to produce the midterm and final deliverables. Rather than having all students in charge of all duties, team members should consider delegating tasks and various types of workloads to students who are best equipped to handle them either because of ability or because of interest and desire. Teams are to meet weekly and members are to complete individual worklog reports, which are used for final grading."
  },
  {
    "objectID": "project/index.html#team-meetings",
    "href": "project/index.html#team-meetings",
    "title": "Project",
    "section": "Team Meetings",
    "text": "Team Meetings\nTeam meetings will be weekly and in-person. The team will determine when all members can meet at the same time each week to discuss their weekly accomplishments, upcoming goals, setbacks, etc. The PM will share with me the time and the location of the meeting."
  },
  {
    "objectID": "project/index.html#deliverables",
    "href": "project/index.html#deliverables",
    "title": "Project",
    "section": "Deliverables",
    "text": "Deliverables\n\nMidterm Presentation\nFinal Presentation\nFinal R Markdown Report and pdf\nWorklogs/GitHub commits"
  },
  {
    "objectID": "project/index.html#project-evaluation",
    "href": "project/index.html#project-evaluation",
    "title": "Project",
    "section": "Project Evaluation",
    "text": "Project Evaluation\nThe project has different components representing it at various stages (e.g., midterm presentation, final presentation and report). See those sections specifically but the following general items will be important to consider.\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organization, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly worklogs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaison’s will also participate in evaluating all teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points.\n\nPresentation Characteristics\nSee the midterm and final presentation guidelines for more detail and rubric but in general, the following characteristics will be evaluated.\n\nClarity: well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization: structured logically; ability to walk audience through the data journey and communicate a story interpretation about data\nThoroughness: all relevant issues discussed thoroughly\nPresentation Style: degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality"
  },
  {
    "objectID": "project/index.html#weekly-worklogreport",
    "href": "project/index.html#weekly-worklogreport",
    "title": "Project",
    "section": "Weekly Worklog/Report",
    "text": "Weekly Worklog/Report\nTracking individual and team goals weekly ensures progress toward the goal, commitment to the project, accountability for oneself, and a record of accomplishments.\nThe Project Manager should inquire with the team about the best way to submit worklogs or transparency and review. This could be a Google Doc File, a spreadsheet, or even a Google From that contains questions to answer, which then get dumped into a Google Spreadsheet for all to review.\n\nFrequency of Worklog\nWorklogs are to be completed by end-of-day following the team meeting, after communicating future goals (distributed equally) to other team members. Please make public for me to review. Meetings should be physical to facilitate team cohesion and conversation, and limit silly technical issues that just waste meeting time.\n\n\nContents of Worklog\nWorklogs should contain information about the reporting date, the team member reporting, that member’s previous week accomplishments, and that member’s future week goals\nThe recommended worklog is accessible here. There is a worksheet for each team. This is a worklog file distributed to DS180 Capstone Faculty to share with their teams."
  },
  {
    "objectID": "project/04_project_report.html",
    "href": "project/04_project_report.html",
    "title": "Final Report",
    "section": "",
    "text": "The final written report for the project will be delivered to me and to your liaison. I can provide a color-printed copy for you to distribute to the liaison and for their offices. The final report is to be created in R Markdown and knit as a Pdf or Word document. An example starter file can be found here. You are not to write the document in GoogleDocs, or other sharing platforms. The course is designed for you to acquire new skills and build confidence in those skills rather than support other skills. Investing in yourself is what will get you internships, jobs, and leadership roles in labs and lab manager roles in graduate school. Thus, the report is to be put in R Markdown and maintained in the remote repository. Because RStudio does not have grammar check capability, you are free to create your own personal content in a Word Processing software like MS Word before you add the content to R Markdown. However, I advise you change the font in that working file to sans serif font because R Markdown may get confused with certain characters (e.g., serif font apostrophes, etc.) and you may need to fix these issues later. After running your grammar and spelling check, then add the content to the .Rmd file. If you do work in a separate file, you will need to make sure to save this file to the project /report directory and ensure you push that file to the remote repository. Also, make sure you use your initials in the file name so that team members don’t all have the same file names.\nA code lead should take on the responsibility to save the file to /report the team project, add, commit, and push the file to the remote repo on GitHub. When the team works on this report file shared with others on GitHub, I recommend two different approaches:\n\nThe team agrees to request adding changes to the document on a case-by-case basis. The PM oversees the process and controls delegation. A member requests permission from the PM to edit the file through the team Discord channel. The PM approves the request and broadcasts to the team on Discord that Member A will issue a pull request to update the local file with the remote file. After pulling the changes, Member A will (1) update the file locally by adding their content, (2) save the file on their local system, (3) knit an HTML version to ensure there are no errors in knitting and so that others can review your edits without actually opening the .Rmd file, (4) and then exit the file so that it is not active in RStudio. Then, they will (5) add, commit (with a description), and push the changed file to the remote repo on GitHub. Once complete, Member A broadcasts to the team on Discord that they have pushed their changes. The PM asks to verify (just to double check) that Member A has actually exited the file. Once verified, the PM broadcasts that other team members can request from the PM permission to edit the file. Do not edit without permission from the PM.\nThe team agrees upon a contribution schedule (dates, hours) and the PM creates and controls delegation of who will be working on which section and at what time. The PM broadcasts to the team on Discord that Member A will issue a pull request to update the local file with remote file. After pulling the changes, Member A will (1) update the file locally by adding their content, (2) save the file on their local system, (3) knit an HTML version to ensure there are no errors in knitting and so that others can review your edits without actually opening the .Rmd file, (4) and then exit the file so that it is not active in RStudio. Then, they will (5) add, commit (with a description), and push the changed file to the remote repo on GitHub. Once complete, Member A broadcasts to the team on Discord that they have pushed their changes. The PM asks to verify (just to double check) that Member A has closed the file. Then the PM broadcasts that the file can be edited by the next team member according to the schedule agreed upon. Do not edit without permission from the PM.\nThe team decides to work in separate files and create copies of the main .Rmd document that include team member’s initials as a suffix to the filename. The team delegates the sections to be written by specific team members. Each member edits their file, saves it, and ensures they can knit an HTML version of the file. If successful without error, then, they and add, commit, and push changes to the remote so. Team members can view the HTML version without actually opening your file. Although this approach may appear easiest, it presents other problems which is a reason why I recommend it as a third option. A major limitation of this approach is with integrating work. Arranging, rearranging, revising work is more difficult when you are dealing with multiple files. Weaving pieces into one another can be difficult. Team members who need to integrate sections will need to identify where content will be inserted (e.g., between what sentences, etc.). This is a common problem with working with separate files whether by yourself or with others. Also, pieces that are in one file may be overlooked and not incorporated. Problems mentioned here as well as others does not make this approach the most convenient in the long long. Moreover, this approach does not involve as much communication between team members, which all of you know is always essential to successful teamwork. Options #1 and #2 ensure this communication.\n\nNote: Remember that with a version control system like Git, you always have access to all versions of the files pushed to GitHub. You can always revert to a prior version. I can help you with this if you get to this point. Good messages in your commits will be helpful here."
  },
  {
    "objectID": "project/04_project_report.html#abstract",
    "href": "project/04_project_report.html#abstract",
    "title": "Final Report",
    "section": "Abstract",
    "text": "Abstract\nThe abstract provides a main summary of data, problem, methods, and key findings."
  },
  {
    "objectID": "project/04_project_report.html#contents",
    "href": "project/04_project_report.html#contents",
    "title": "Final Report",
    "section": "Contents",
    "text": "Contents\nA contents pages, or table of contents, provides a listing of the document sections and subsections as we as a page for location.\n\nTitle Page\nAbstract\nTable of Contents\nAcknowledgments\n\nChapters:\n\nIntroduction\nData\nResults/Findings\nDiscussion\nConclusion\nReferences"
  },
  {
    "objectID": "project/04_project_report.html#sources-of-data",
    "href": "project/04_project_report.html#sources-of-data",
    "title": "Final Report",
    "section": "Sources of Data",
    "text": "Sources of Data\nWhat was the data source/where did you obtain it from? Include the source URL of the website from which you accessed the data.The data were obtained from https://www.tfrrs.org/. Include information about where and how the data were collected or obtained. Specify whether the data were obtained from internal databases, external sources, or gathered through specific methods (surveys, sensors, web scraping, etc.)."
  },
  {
    "objectID": "project/04_project_report.html#data-characteristics",
    "href": "project/04_project_report.html#data-characteristics",
    "title": "Final Report",
    "section": "Data Characteristics",
    "text": "Data Characteristics\nDiscuss the data in detail. In which format was the data stored? How many cases were there in total? How many variables were contained? What variables were contained? What were the key variables you used?\nDescribe the types of variables present in the data set (numerical, categorical, text, etc.). When discussing variables of the visualization in the results chapter, make sure to provide clarity about the variable, its metric, and reason for using that variable (e.g., mean, max, median, mean of max values, median of max values, dispersion measures, etc.).\nList and briefly describe each attribute, feature, or variable in the data set, paying special attention to those used for the project."
  },
  {
    "objectID": "project/04_project_report.html#data-quality-and-data-preprocessing",
    "href": "project/04_project_report.html#data-quality-and-data-preprocessing",
    "title": "Final Report",
    "section": "Data Quality and Data Preprocessing",
    "text": "Data Quality and Data Preprocessing\nDescribe the steps taken to clean and prepare the data for investigation. This description may include removing duplicates, standardizing formats, trimming, correcting inconsistencies, etc. Explain any criteria used to select variables or features for visualization, focusing on those with the greatest impact or insight for the organization’s understanding.\nSome key details to address include:\n\nMissing Values: Explain the presence and treatment of any missing data. Explain how missing values were handled during analysis (removal, replacement, etc.).\nOutliers and Anomalies: Mention any identified outliers or anomalies and how they were addressed (treatment or exclusion).\nVariables Created: Describe the variables created, their units of measurement, etc. Explain if any normalization or scaling procedures applied to create the variables and to ensure data consistency and comparability across measures.\n\nAlso, specify where the cleaned data may be obtained."
  },
  {
    "objectID": "project/04_project_report.html#data-limitations",
    "href": "project/04_project_report.html#data-limitations",
    "title": "Final Report",
    "section": "Data Limitations",
    "text": "Data Limitations\nHighlight any limitations or constraints of the data set that affected the team’s ability to address the initial problem. Similarly, describe how any limitations might affect the interpretation of the findings."
  },
  {
    "objectID": "project/02_project_midterm.html",
    "href": "project/02_project_midterm.html",
    "title": "Midterm presentation",
    "section": "",
    "text": "After having several weeks to clean and manipulate project data, brainstorm potential key items to address, identify potential story lines, and create some data summaries, the next step is to present the progress to the class. You goal for the midterm presentation will be to present a clear representation of the research problem to the class (and later liaison) and demonstrate your ability to use R code to a achieve your goals. Compared with the final presentation, the mid-term presentation is designed to showcase your code rather than test models and draw inferences from data.\nYou should describe the problem, outline relevant cognitive tasks, summarize key references and theory, describe the data that will be used to address the problem, and describe your plans to satisfy the question for your liaison. As with all data-science projects, your plan will involve data cleaning. Some that cleaning will have been completed so you can describe what you needed to do in order to get the data in order to tackle subsequent tasks.\nYou will be evaluated on you and your team’s ability to convey the project purpose and goals, your intended plan to meet those goals, and the steps taken to select and prepare data necessary to meet those goals. If you have prepared data in some way, you should share your code and describe the functions used and approach taken to achieve those goals. If you have not prepared all data, you should outline what you need to do in order to prepare and clean it, again my sharing the functions needed and approach. If you have examined some data and prepared any visualizations that could be used to fulfill the project goals, you should share them as well.\nTeams will have slightly different projects guided by the interests of the liaisons, so coding approaches may differ, data preparation may differ, visualizations may differ, and the story told about data will differ. Include code where appropriate to communicate how you achieved your goals.\nAt this stage in the project, the important point is that all team members have been working to understand the problem and its goals. You should have distributed and read the papers outlined by the project liaison in order to and understood some basic findings in the literature, the major theories/explanations for those findings, and have formulated a clear idea about your intended plan to meet the very minimum expectations of the liaison. Regarding data and code, all team members have been challenging themselves to think about data and practice using {dplyr} and other libraries to wrangle and prepare data. In other words, all team members must discuss their role in helping prepare data for the project in some way, whether that be preparing a different task, recoding a different set of variables, or preparing data visualization. In rare events, if the project does not require cleaning and preparation of enough tasks or variables to distribute, team members can work independently to solve the same problem and share the steps taken to achieve the goal."
  },
  {
    "objectID": "project/02_project_midterm.html#the-project-description-and-relevance",
    "href": "project/02_project_midterm.html#the-project-description-and-relevance",
    "title": "Midterm presentation",
    "section": "The Project Description and Relevance",
    "text": "The Project Description and Relevance\nYou should communicate the project question clearly, making sure to address background research and findings, theory, and theoretical or practical importance of the project. Without a clear representation of the research problem, variable selection, variable cleaning, and modeling will be unclear. In the end, you should aim to tell a story with data. The story of data will have key characters (e.g., theories, variables, etc.) and supporting characters (e.g., other variables, relationships, etc.). There will be protagonists (e.g., prominent variables and theories) and antagonists (e.g., competing theories and variables) etc. All of these characters have back stories as well (e.g., past research, references, etc.). When you introduce the project, its relevance, you should ensure that you address the key elements so that the liaison has confidence that you have conceptualized and understand the problem accurately. This includes summarizing the research in the readings and clarifying the theories that motivate the question. At the same time, all good stories of science building tension in the audience. Nothing is preordained and if it were, there would be no reason to clean up and examine the data. For example, there may be clear reasons for discovering relationships among variables yet there may be reasons why those relationships may not exist, why they may be accounted for a different variable or set of variables."
  },
  {
    "objectID": "project/02_project_midterm.html#data-preparation",
    "href": "project/02_project_midterm.html#data-preparation",
    "title": "Midterm presentation",
    "section": "Data Preparation",
    "text": "Data Preparation\nYou should communicate steps taken to select and clean data. I recommend sharing your code where appropriate. The audience should understand the code and may have the capacity to identify errors.\n\nTasks and Variable Selection\n\nCommunicate the variables needed\nCommunicate relevant cognitive tasks (what they are, what they measure)\n\n\n\nGeneral Data Cleaning\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of {dplyr} functions like group_by(), mutate(), filter(), ungroup(), or other functions from {stringr}, {tidyr} or otherwise for merging/joining, adding new variables, etc.\n\n\n\nData Summaries\n\nCommunicate how you calculated and/or obtained summary metrics\nCommunicate any usage of functions like group_by(), summarize(), filter(), or ungroup() to ensure your data are computed correctly\n\n\n\nData Visualization\n\nCommunicate the variables used in the visualization\nCommunicate any usage of functions to create the visualization"
  },
  {
    "objectID": "project/02_project_midterm.html#project-description-30-pts",
    "href": "project/02_project_midterm.html#project-description-30-pts",
    "title": "Midterm presentation",
    "section": "Project Description (30 pts)",
    "text": "Project Description (30 pts)\n\nCommunicate the proposed problem\nCommunicate the relevant background research, theories, etc.\nCommunicate the relevant cognitive tasks and variables\nCommunicate the project goals and timeline to address those goals"
  },
  {
    "objectID": "project/02_project_midterm.html#data-preparation-and-variable-creation-30-pts",
    "href": "project/02_project_midterm.html#data-preparation-and-variable-creation-30-pts",
    "title": "Midterm presentation",
    "section": "Data Preparation and Variable Creation (30 pts)",
    "text": "Data Preparation and Variable Creation (30 pts)\n\nCommunicate steps taken to clean data to fulfill sub-goals\nCommunicate how you modified variables and/or computed variables of interest\nCommunicate any usage of functions to ensure your data are computed correctly\nCommunicate any aggregation methods and summary data frames per plot"
  },
  {
    "objectID": "project/02_project_midterm.html#presentation-characteristics-20-pts",
    "href": "project/02_project_midterm.html#presentation-characteristics-20-pts",
    "title": "Midterm presentation",
    "section": "Presentation Characteristics (20 pts)",
    "text": "Presentation Characteristics (20 pts)\n\nClarity (5pts): well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization (5pts): structured logically; ability to walk audience through some story line or the a story about the problem and decision processes\nThoroughness (5pts): all relevant issues discussed thoroughly\nPresentation Style (5pts): degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality"
  },
  {
    "objectID": "project/02_project_midterm.html#team-and-team-member-evaluation-5-pts",
    "href": "project/02_project_midterm.html#team-and-team-member-evaluation-5-pts",
    "title": "Midterm presentation",
    "section": "Team and Team Member Evaluation (5 pts)",
    "text": "Team and Team Member Evaluation (5 pts)\n\nEvaluation of personal contributions toward the project as evaluated by other team members (claims partially validated using on-time weekly report submissions).\nThe audience (your client) will also provide an overall review for the team and individual team members."
  },
  {
    "objectID": "project/02_project_midterm.html#self-evaluation-5-pts",
    "href": "project/02_project_midterm.html#self-evaluation-5-pts",
    "title": "Midterm presentation",
    "section": "Self Evaluation (5 pts)",
    "text": "Self Evaluation (5 pts)\nEvaluation of your personal contributions toward the project as evaluated by yourself (claims partially validated using on-time weekly report submissions)."
  },
  {
    "objectID": "modules/summarizing_data_advanced.html",
    "href": "modules/summarizing_data_advanced.html",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "",
    "text": "This module introduces some somewhat advanced approaches to summarizing data. They are advanced insofar as they involve creating lists of summary functions and using dplyr::across() to run those functions across multiple variables. They are more complicated than adding lines of expressions to summarize() but the cost associated with greater complexity buy you simplicity of code and reproducibility."
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#summarizing-vectors",
    "href": "modules/summarizing_data_advanced.html#summarizing-vectors",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Summarizing Vectors",
    "text": "Summarizing Vectors\n\nmean(DATA$x, na.rm = T)\n\n[1] 28\n\nmean(DATA$y, na.rm = T)\n\n[1] 24.4\n\nmedian(DATA$x, na.rm = T)\n\n[1] 21\n\nmedian(DATA$y, na.rm = T)\n\n[1] 20\n\n\nNOTE: The mean and median of x differ."
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#summarizing-vectors-in-data-frames",
    "href": "modules/summarizing_data_advanced.html#summarizing-vectors-in-data-frames",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Summarizing Vectors in Data Frames",
    "text": "Summarizing Vectors in Data Frames\n\n1 Variable, 2 Metrics\n\nDATA |&gt;\n  summarize(x = mean(x, na.rm = TRUE),\n            x_median = median(x, na.rm = TRUE)\n            )\n\n# A tibble: 1 × 2\n      x x_median\n  &lt;dbl&gt;    &lt;dbl&gt;\n1    28       28\n\n\nWarning: The mean and median of x are the same. The median() is computed based on the new value of x that is assigned by the first line in summarize() (e.g x = mean(x, na.rm = TRUE)). You would want to use a new variable name.\nSolution: Assigning to names other than x:\n\nDATA |&gt;\n  summarize(mean = mean(x, na.rm = TRUE),\n            median = median(x, na.rm = TRUE)\n            )\n\n# A tibble: 1 × 2\n   mean median\n  &lt;dbl&gt;  &lt;dbl&gt;\n1    28     21\n\n\n\n\n2 Variables, 1 Metric\n\nDATA |&gt;\n  summarize(x_mean = mean(x, na.rm = TRUE),\n            y_mean = mean(y, na.rm = TRUE),\n            )\n\n# A tibble: 1 × 2\n  x_mean y_mean\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     28   24.4\n\n\nNOTE: Are the means really the same?\n\n\n2 Variables, 2 Metrics\n\nDATA |&gt;\n  summarize(x_mean = mean(x, na.rm = TRUE),\n            y_mean = mean(y, na.rm = TRUE),\n            x_median = median(x, na.rm = TRUE),\n            y_median = median(y, na.rm = TRUE)\n            )\n\n# A tibble: 1 × 4\n  x_mean y_mean x_median y_median\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     28   24.4       21       20\n\n\n\n\n2 Variables, 2 Metrics with Grouping\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(x_mean = mean(x, na.rm = TRUE),\n            y_mean = mean(y, na.rm = TRUE),\n            x_median = median(x, na.rm = TRUE),\n            y_median = median(y, na.rm = TRUE)\n            )\n\n# A tibble: 2 × 5\n  group x_mean y_mean x_median y_median\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 a       15     27.7     13       30  \n2 b       47.5   19.5     47.5     19.5"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#summarizing-across-with-dplyracross",
    "href": "modules/summarizing_data_advanced.html#summarizing-across-with-dplyracross",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Summarizing Across with dplyr::across()",
    "text": "Summarizing Across with dplyr::across()\nacross() is used when you want to iterate a function or set of functions across a multiple variables. The function will require you to pass arguments for the columns you want to summarize, the function(s) specifying how to summarize, and the names of the new output variables. By default, the\nacross(.cols, \n       .fns, ..., \n       .names = NULL, \n       .unpack = FALSE\n       )"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#dplyracross-parametersarguments",
    "href": "modules/summarizing_data_advanced.html#dplyracross-parametersarguments",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "dplyr::across(): Parameters/Arguments",
    "text": "dplyr::across(): Parameters/Arguments\n\n.cols: the columns to perform a function upon\n.fns: the function(s) to apply to the column in .cols\n.names: a glue specification that describes how to name the output columns; use {.col} to stand for the selected column name, and {.fn} for the function being applied; defaults to \"{col}_{fn}\""
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#dplyracross-passing-arguments",
    "href": "modules/summarizing_data_advanced.html#dplyracross-passing-arguments",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "dplyr::across(): Passing Arguments",
    "text": "dplyr::across(): Passing Arguments\n\n.cols = c(x, y)\n.fns = ~mean(x, na.rm = TRUE)\n\nAccepting the default argument for .names:\n\n.names = NULL\n\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = ~mean(.x, na.rm = TRUE)\n                   )\n            )\n\n# A tibble: 2 × 3\n  group     x     y\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5\n\n\nPassing an argument to .names:\n\n.names = \"{col}_{fn}\"\n\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = ~mean(.x, na.rm = TRUE),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5\n\n\nOr using a quoted vector: .cols = c(\"x\", \"y\")\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(\"x\", \"y\"), \n                   .fns = ~mean(.x, na.rm = TRUE),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5\n\n\nOr passing a quoted vector:\n\nmust use all_of() or any_of() for variable selection\n.cols = all_of(summarize_these)\n.cols = summarize_these will produce a warning\n\n\nsummarize_these &lt;- c(\"x\", \"y\")  # create the vector to pass\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = any_of(summarize_these), \n                   .fns = ~mean(.x, na.rm = TRUE),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5\n\n\nNote: defining a vector of variables can be a helpful solution when you have multiple summary tables for which you use the same variables."
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#annoyances-with-across",
    "href": "modules/summarizing_data_advanced.html#annoyances-with-across",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Annoyances with across()",
    "text": "Annoyances with across()\n\nMore complicated\nAlthough {col} is useful (e.g., x and y), {fn} results in a numeric value which is not diagnostic of the function"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#passing-a-list-of-functions-to-.fns",
    "href": "modules/summarizing_data_advanced.html#passing-a-list-of-functions-to-.fns",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Passing a List of Functions to .fns",
    "text": "Passing a List of Functions to .fns\n\n.cols = c(x, y)\n.fns = list(~mean(x, na.rm = TRUE))\n\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = list(~mean(.x, na.rm = TRUE)),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5\n\n\nNote: The ~ is use as a lambda-like operator that results in iterating the function over all instances of x. In this case, list(~mean(x, na.rm = TRUE), the x is not referring to the x column in the data frame but instead the values in all variables passed to .cols. In this case, the x would be both x and y, in that order."
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#same-annoyances",
    "href": "modules/summarizing_data_advanced.html#same-annoyances",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Same Annoyances",
    "text": "Same Annoyances\n\nMore complicated (requires remembering the function, in the list, and the ~)\nAlthough {col} is useful (e.g., x and y), {fn} results in a numeric value which is not diagnostic of the function"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#giving-the-list-elements-names",
    "href": "modules/summarizing_data_advanced.html#giving-the-list-elements-names",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Giving the List Elements Names",
    "text": "Giving the List Elements Names\n\n.cols = c(x, y)\n.fns = list(some_name = ~mean(x, na.rm = TRUE))\n\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = list(some_name = ~mean(.x, na.rm = TRUE)),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group x_some_name y_some_name\n  &lt;chr&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 a            15          27.7\n2 b            47.5        19.5"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#annoyances",
    "href": "modules/summarizing_data_advanced.html#annoyances",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Annoyances",
    "text": "Annoyances\n\nStill complicated (requires remembering the function, in the list, and the ~)"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#passing-a-list-object-to-.fns",
    "href": "modules/summarizing_data_advanced.html#passing-a-list-object-to-.fns",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Passing a List Object to .fns",
    "text": "Passing a List Object to .fns\n\ncreate summary_funcs list of function(s)\n.fns = summary_funcs\n\nCreate a list containing ~mean(x, na.rm = TRUE)) used in previous example:\n\nsummary_funcs &lt;- list(\n  mean = ~mean(na.omit(.x))  \n  )\n\nThen pass to .fns, .fns = summary_funcs:\n\nDATA |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            ) \n\n# A tibble: 1 × 2\n  x_mean y_mean\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     28   24.4\n\n\nPair with .cols = summarize_these to summarize the variables in summarize_these using the function(s) in summary_funcs:\nDATA |&gt;\n  summarize(across(.cols = summarize_these,\n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            ) \nNote: If you try to execute this, pay attention to the warning Message!\n! Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(summarize_these)\n\n  # Now:\n  data %&gt;% select(all_of(summarize_these))\n  \nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.  \nSolution: When passing an external vector, you need to use all_of() or any_of().\n\nDATA |&gt;\n  summarize(across(.cols = all_of(summarize_these),\n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            ) \n\n# A tibble: 1 × 2\n  x_mean y_mean\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     28   24.4"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#annoyancesbenefits",
    "href": "modules/summarizing_data_advanced.html#annoyancesbenefits",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Annoyances/Benefits",
    "text": "Annoyances/Benefits\n\nRequires creating other objects\nSimplifies the code\nDoes not require remembering the functions, the list, and ~ after created once"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#adding-more-functions-as-list-elements",
    "href": "modules/summarizing_data_advanced.html#adding-more-functions-as-list-elements",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Adding More Functions as List Elements",
    "text": "Adding More Functions as List Elements\nAdd functions to the list to accomplish more\n\nsummary_funcs &lt;- list(\n  mean = ~mean(na.omit(.x)),\n  median = ~median(na.omit(.x)),\n  sd = ~sd(na.omit(.x)),\n  n = ~length(na.omit(.x))\n  )"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#passing-the-list-object-to-.fns-grouping",
    "href": "modules/summarizing_data_advanced.html#passing-the-list-object-to-.fns-grouping",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Passing the List Object to .fns: Grouping",
    "text": "Passing the List Object to .fns: Grouping\n\ngroup_by(group)\n\n.fns = summary_funcs\n\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = all_of(summarize_these),\n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 9\n  group x_mean x_median  x_sd   x_n y_mean y_median  y_sd   y_n\n  &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 a       15       13    5.29     3   27.7     30   6.81      3\n2 b       47.5     47.5  4.95     2   19.5     19.5 0.707     2"
  },
  {
    "objectID": "modules/summarizing_data_advanced.html#annoyancesbenefits-1",
    "href": "modules/summarizing_data_advanced.html#annoyancesbenefits-1",
    "title": "Summarizing Data: Using across() and Lists",
    "section": "Annoyances/Benefits",
    "text": "Annoyances/Benefits\n\nCreating and remembering the list object name\nSolution: Add an .R script to your functions directory and make a code snippet for the object name."
  },
  {
    "objectID": "modules/19_exploratory_data_analysis.html",
    "href": "modules/19_exploratory_data_analysis.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/19_exploratory_data_analysis.html#readings-and-preparation",
    "href": "modules/19_exploratory_data_analysis.html#readings-and-preparation",
    "title": "Exploratory Data Analysis",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/19_exploratory_data_analysis.html#supplementary-readings",
    "href": "modules/19_exploratory_data_analysis.html#supplementary-readings",
    "title": "Exploratory Data Analysis",
    "section": "Supplementary Readings",
    "text": "Supplementary Readings\n\nExploratory Data Analysis"
  },
  {
    "objectID": "modules/19_exploratory_data_analysis.html#libraries",
    "href": "modules/19_exploratory_data_analysis.html#libraries",
    "title": "Exploratory Data Analysis",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management"
  },
  {
    "objectID": "modules/17_strings_and_factors.html",
    "href": "modules/17_strings_and_factors.html",
    "title": "Strings, Factors, and Regular Expressions",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/17_strings_and_factors.html#readings-and-preparation",
    "href": "modules/17_strings_and_factors.html#readings-and-preparation",
    "title": "Strings, Factors, and Regular Expressions",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/17_strings_and_factors.html#libraries",
    "href": "modules/17_strings_and_factors.html#libraries",
    "title": "Strings, Factors, and Regular Expressions",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management"
  },
  {
    "objectID": "modules/15_joining_project_data.html",
    "href": "modules/15_joining_project_data.html",
    "title": "Joining Project Data",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/15_joining_project_data.html#supplementary-readings",
    "href": "modules/15_joining_project_data.html#supplementary-readings",
    "title": "Joining Project Data",
    "section": "Supplementary Readings",
    "text": "Supplementary Readings\n\nR Workflow Basics"
  },
  {
    "objectID": "modules/15_joining_project_data.html#task",
    "href": "modules/15_joining_project_data.html#task",
    "title": "Joining Project Data",
    "section": "Task",
    "text": "Task"
  },
  {
    "objectID": "modules/15_joining_project_data.html#libraries",
    "href": "modules/15_joining_project_data.html#libraries",
    "title": "Joining Project Data",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management\n{readr} 2.1.4: for reading .csv, .tsv, and .fwf files\n{openxlsx} 4.2.5.2: for reading Excel spreadsheets from a URL and writing Excel files\n{haven} 2.5.4: for reading SPSS, Stata, and SAS files (e.g., .sav, .dta, .sas7bdat, etc. )\n{rio} 1.0.1: a Swiss-Army knife for data I/O\n\nRelated:\n\n{readxl} 1.4.3: for reading Excel spreadsheets"
  },
  {
    "objectID": "modules/13_visualizing_data.html",
    "href": "modules/13_visualizing_data.html",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/13_visualizing_data.html#readings-and-preparation",
    "href": "modules/13_visualizing_data.html#readings-and-preparation",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/13_visualizing_data.html#supplemental-readings",
    "href": "modules/13_visualizing_data.html#supplemental-readings",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Supplemental Readings",
    "text": "Supplemental Readings\n\nHuber: Graphing\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Introduction"
  },
  {
    "objectID": "modules/13_visualizing_data.html#load-libraries",
    "href": "modules/13_visualizing_data.html#load-libraries",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/13_visualizing_data.html#external-functions",
    "href": "modules/13_visualizing_data.html#external-functions",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nIf saved, source locally:\n\nsource(here::here(\"r\", \"my_functions.R\"))\n\nOr Source online:\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/fods24/main/r/functions/view_html.R\")"
  },
  {
    "objectID": "modules/13_visualizing_data.html#ggplot-plot-composition",
    "href": "modules/13_visualizing_data.html#ggplot-plot-composition",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "{ggplot} Plot Composition",
    "text": "{ggplot} Plot Composition\nThere are five mapping components:\n\nLayer containing geometric elements and statistical transformations:\n\n\nData a tidy data frame, most typically in long/narrow format\nMapping defining how vector variables are visualized (e.g., aesthetics like shape, color, position, hue, etc.)\nStatistical Transformation (stat) representing some summarizing of data (e.g., sums, fitted curves, etc.)\nGeometric object (geom) controlling the type of visualization\nPosition Adjustment (position) controlling where visual elements are positioned\n\n\nScales that map values in the data space to values in aesthetic space\nA Coordinate System for mapping coordinates to the plane of a graphic\nA Facet for arranging the data into a grid; plotting subsets of data\nA Theme controlling the niceties of the plot, like font, background, grids, axes, typeface etc.\n\nThe grammar does not:\n\nMake suggestions about what graphics to use\nDescribe interactivity with a graphic; {ggplot2} graphics are static images, though they can be animated"
  },
  {
    "objectID": "modules/13_visualizing_data.html#initializing-the-plot-object",
    "href": "modules/13_visualizing_data.html#initializing-the-plot-object",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Initializing the Plot Object",
    "text": "Initializing the Plot Object\nWhat is a ?ggplot object? Review the docs first. Let’s apply the base layer using ggplot(). This function takes a data set and simply initializes the plot object so that you can build other components on top of it. By default, data = NULL so, you will need to pass some data argument. There is also a mapping parameter for mapping the aesthetics of the plot, by default, mapping = aes(). If you don’t pass a data frame to data, what happens?\nggplot(data = NULL, \n       mapping = aes()\n       )\nParameters/Arguments:\n\ndata: Default data set to use for plot. If not already a data.frame, will be converted to one by fortify(). If not specified, must be supplied in each layer added to the plot.\nmapping: Default list of aesthetic mappings to use for plot. If not specified, must be supplied in each layer added to the plot.\n\n\nggplot()\n\n\n\n\nAn object is created but it contains no data. The default is some rectangle in space."
  },
  {
    "objectID": "modules/13_visualizing_data.html#passing-the-data-to-ggplot",
    "href": "modules/13_visualizing_data.html#passing-the-data-to-ggplot",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Passing the Data to ggplot()",
    "text": "Passing the Data to ggplot()\nYou cannot have a plot without data, so we need some data in a tidy format. We can read in a data set or create one.\n\nDATA &lt;- data.frame(\n A = c(1, 2, 3, 4), \n B = c(2, 5, 3, 8), \n C = c(10, 15, 32, 28), \n D = c(\"Task A\", \"Task A\", \"Task B\", \"Task B\"),\n E = c(\"circle\", \"circle\", \"square\", \"square\")\n)\n\nNow we can pass data = DATA to ggplot():\n\nggplot(data = DATA)\n\n\n\n\nOr we can pipe the data to ggplot().\n\nDATA |&gt;\n  ggplot()\n\n\n\n\nOK, so still nothing. That’s because we haven’t told ggplot what visual properties or aesthetics to include. Importantly, we don’t have do this in a base layer. If we set data = DATA, the subsequent layers will inherit that data frame if you don’t pass the argument in a different layer. However, you are not limited to passing only one data set. You might wish to plot the aesthetics of one data frame in one layer and then add another layer of aesthetics taken from a different data frame. TLDR; you can pass data or not in the initialization of the base layer."
  },
  {
    "objectID": "modules/13_visualizing_data.html#scalingscale-transformation",
    "href": "modules/13_visualizing_data.html#scalingscale-transformation",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Scaling/Scale Transformation",
    "text": "Scaling/Scale Transformation\n\nDATA\n\n  A B  C      D      E\n1 1 2 10 Task A circle\n2 2 5 15 Task A circle\n3 3 3 32 Task B square\n4 4 8 28 Task B square\n\n\nLooking at the data, we have columns and rows. Looking at the data frame, you see the ‘identity’ of each case. Ease case is a numeric value, character, or factor. What you for each is there identity. Of course, we can change their identity in some way by transforming the values to z scores, log values, or each average them together to take their count and then plot those data. But those are not their true identity.\nIn order to take the data units in the data frame so that they can be represented as physical units on a plot (e.g., points, bars, lines, etc.), there needs to be some scaling transformation. The plot needs to understand how many pixels high and wide to create a plot and the plot needs to know the limits of the axes for example. Similarly, it needs to know what shapes to present, how many, etc. By default, the statistical transformation is an ‘identity’ transformation, of one that just takes the values and plots them as their appear in the data (their identity)."
  },
  {
    "objectID": "modules/13_visualizing_data.html#choosing-a-coordinate-system",
    "href": "modules/13_visualizing_data.html#choosing-a-coordinate-system",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Choosing a Coordinate System",
    "text": "Choosing a Coordinate System\nAll we have now is the base layer taking on some coordinates. For example, where are the points plotted on the plot? The system can follow the Cartesian coordinate system or a Polar coordinate system. An example of this will follow later. For now, the default is chosen for you."
  },
  {
    "objectID": "modules/13_visualizing_data.html#adding-aesthetic-mappings",
    "href": "modules/13_visualizing_data.html#adding-aesthetic-mappings",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Adding Aesthetic Mappings",
    "text": "Adding Aesthetic Mappings\nIf you wanted a plot geometry to inherit properties of the initialized base layer, you could pass aesthetics to the mapping argument, mapping = aes().\n\nDATA |&gt;\n  ggplot(mapping = aes())\n\n\n\n\nBut this doesn’t do anything because we haven’t added information to pass to the aesthetics in aes(). Looking at ?aes, we see that aes() maps how properties of the data connect to or map onto with the features of the graph (e.g., axis position, color, size, etc.). The aesthetics are the visual properties of the plots, so they are essential to map by passing arguments to aes(). But how many and what variables do we reference? Looking at ?aes, you see that x and y are needed.\nBecause we passed data = DATA in ggplot(), we can reference the variables by their column names without specifying the data frame. Choosing x = A and y = B will\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         )\n\n\n\n\nWe can see that the aesthetic layer now applied to the plot scales the data to present A along the x-axis with a range from lowest to highest value from that vector. Similarly, the mapping presents B along the y-axis with a range from lowest to highest value in the vector. Also, the aesthetics include the variable name as a the label for the x and y axes. Of course, these could be changed in a layer as well. More on that later.\nYou might have been tempted to pass the variable names a quoted strings (e.g., “A” and “B) but if you do that, you’ll get something different.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = \"A\", \n                       y = \"B\")\n       )\n\n\n\n\nIf we want to plot the data as they are in the data frame, we would apply the ‘identity’ transformation. By identity, we just need to instruct ggplot() to use the data values in the data set. If you wanted to plot the means, frequency count, or something else, we would need to tell ggplot() how to transform the data."
  },
  {
    "objectID": "modules/13_visualizing_data.html#adding-plot-geometries",
    "href": "modules/13_visualizing_data.html#adding-plot-geometries",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Adding Plot Geometries",
    "text": "Adding Plot Geometries\nWe don’t yet have any geometries, or geoms, added. Geoms can take many forms, including, points, lines, bars, text, etc. If we want the values in A and B to be plotted as x and y coordinates representing points on the plot, we can add a point geometry using geom_point().\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B\n                       )\n       ) +\n  geom_point()\n\n\n\n\nThe points geometry has now been applied, which takes the aesthetic mapping and makes them into points.\nBut geometries also have aesthetics, or visual properties so for each geom, you can pass arguments to aes(). For example, the xy points have to take some shape, color, and size in order for them to be visible. By default, these have been determined or otherwise you wouldn’t see black circles of any size.\nChecking ?geom_point, you will see at the bottom of the arguments section, that by default inherit.aes = TRUE, which means the aesthetic mappings in geom_point() will be inherited by default. Similarly, data = NULL so the data and the aesthetic mapping from ggplot() don’t need to be specified as data = DATA and mapping = aes(x = A, y = B), unless of course we wanted to overwrite them. Though not inherited, other aesthetics have defaults for geom_point(). If we wanted to be verbose, we could include all of them and see how this plot compares with that above.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(x = A, \n                           y = B\n                           ),   \n             data = NULL, \n             stat = \"identity\", \n             position = \"identity\", \n             size = 1.5\n             )\n\n\n\n\n\nHow and Where to Map Aesthetics?\nYou might be wondering how you map these aesthetic properties so that when you attempt to do so, you don’t get a bunch of errors. There are two places you can map aesthetics:\nEither in the initialized plot object:\n\nggplot(data = data, mapping = aes(x, y)) + geom_point()\n\nOr in the geometry:\n\nggplot() +geom_point(data = data, mapping = aes(x, y))\n\nWe can map aesthetics in the initialize plot object by also assigning this to an object named map just so we can reference it as need. When we do this mapping…\n\nmap &lt;- DATA |&gt;\n  ggplot(mapping = aes(A, C))\n\nThe aesthetics are inherited by the geometries that follow, which then do not require any mapping of their own…\n\nmap + \n  geom_point() + \n  geom_line()\n\n\n\n\nBut when aesthetics are NOT mapped in initialized plot…\n\nmap &lt;- ggplot() \n\nThere are no aesthetics to be inherited by the plot geometry functions because they are not passed to the ggplot() object. In this case they must be mapped as arguments the geometries themselves.\nPlot points…\n\nmap + \n  geom_point(data = DATA, \n             mapping = aes(A, C)) \n\n\n\n\nPlot a line…\n\nmap + \n  geom_line(data = DATA, \n            mapping = aes(x = A, y = B))\n\n\n\n\nIn a later section, we will differentiate between setting and mapping aesthetic attributes.\nAdd labels, a coordinate system, scaling, and a theme\nPretty much the same? For completeness, there are also x and y label layers and a coordinate system also applied by default. Let’s add them to the plot by adding layers.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(x = A, \n                           y = B\n                           ),   \n             data = NULL, \n             stat = \"identity\", \n             position = \"identity\", \n             size = 1.5,\n             color = \"black\") +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  labs(title = \"\") +\n  xlab(\"A\") +\n  ylab(\"B\") +\n  coord_cartesian() +\n  theme()\n\n\n\n\nNotice the plot is the same. The take-home message is that each visualization uses a data set which will be used to provide some aesthetic mapping. That mapping takes some geometric form, or geom. The geom needs information about the data, the statistical transformation (or an its ‘identity’ in the data frame), some position in space, some size, and some color. Also the axes have labels and follow some rules about their scaling. All of this follows some coordinate system. A theme is also used to decorate the plot in different ways. The default is theme().\nChange the coordinate system, color, and labels\nIf we wanted to change the coordinate system, then the visualization would look much different. We can also change the color and label names. And because they are independent layers, we could add them in different orders.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B\n                       )\n       ) +\n  geom_point(mapping = aes(x = A, \n                           y = B\n                           ),   \n             data = NULL, \n             stat = \"identity\", \n             position = \"identity\", \n             size = 1.5,\n             color = \"blue\") +\n  coord_polar() +\n  xlab(\"A Variable\") +\n  ylab(\"B Variable\") +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  theme()\n\n\n\n\nBut because those are defaults, we don’t need to code all those plot layers. We can simply add a geom_point() layer. And because we pass DATA as the first argument and the mapping next, we could be even less wordy.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point()"
  },
  {
    "objectID": "modules/13_visualizing_data.html#how-and-where-to-map-aesthetics",
    "href": "modules/13_visualizing_data.html#how-and-where-to-map-aesthetics",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "How and Where to Map Aesthetics?",
    "text": "How and Where to Map Aesthetics?\nYou might be wondering how you map these aesthetic properties so that when you attempt to do so, you don’t get a bunch of errors. There are two places you can map aesthetics:\nEither in the initialized plot object:\n\nggplot(data = data, mapping = aes(x, y)) + geom_point()\n\nOr in the geometry:\n\nggplot() +geom_point(data = data, mapping = aes(x, y))\n\nWe can map aesthetics in the initialized plot object by also assigning this to an object named plot just so we can reference it as need.\nWhen we do this mapping:\n\nplot &lt;- ggplot(data = SWIM, \n              mapping = aes(Year, Time)\n              )\n\nThe aesthetics are inherited by the geometries that follow, which then do not require any mapping of their own…\n\nplot + \n  geom_point() + \n  geom_line()\n\n\n\n\nBut when aesthetics are NOT mapped in initialized plot:\n\nplot &lt;- ggplot() \n\nThere are no aesthetics to be inherited by the plot geometry functions because they are not passed to the ggplot() object. In this case they must be mapped as arguments the geometries themselves.\nPlot points:\n\nplot + \n  geom_point(data = SWIM, \n             mapping = aes(Year, Time)\n             ) \n\n\n\n\nPlot a line:\n\nplot + \n  geom_line(data = SWIM, \n            mapping = aes(x = Year, y = Time)\n            )\n\n\n\n\nIn a later section, we will differentiate between setting and mapping aesthetic attributes."
  },
  {
    "objectID": "modules/13_visualizing_data.html#mapping-a-variable-as-is-from-the-data-frame",
    "href": "modules/13_visualizing_data.html#mapping-a-variable-as-is-from-the-data-frame",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Mapping a variable as-is from the data frame`",
    "text": "Mapping a variable as-is from the data frame`\nggplot() defines the data as well as variables in aes(). You can easily map the x or y variable to the geom_*().\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = Year))"
  },
  {
    "objectID": "modules/13_visualizing_data.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "href": "modules/13_visualizing_data.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Mapping a variable that differs from what’s in the data frame",
    "text": "Mapping a variable that differs from what’s in the data frame\nYou can also change a variable type in the scope of the plot without modifying it in the data frame. Let’s change Year to numeric to see what happens:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = as.numeric(Year)))\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\n\n\n\n\nSimilarly, if we had a numeric variable and wanted to make a factor():\n\nSWIM &lt;- SWIM |&gt;\n  mutate(Year2 = as.numeric(Year))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Year2 = as.numeric(Year)`.\nCaused by warning:\n! NAs introduced by coercion\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = as.factor(Year2)))\n\n\n\n\nOr make a character:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = as.character(Year2)))\n\n\n\n\nYou may have noticed that when mapped variables are numeric, the aesthetics are applied continuously and when they are character (e.g., categorical, factors), they are applied discretely. Here is a good example of mapping variable Year not as itself but by changing it to a as.numeric() or changing numeric variables to either a factor() or a character vector. You might notice that the content in the legend is messy now. Fixing this is something we will work on as we progress."
  },
  {
    "objectID": "modules/13_visualizing_data.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "href": "modules/13_visualizing_data.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Mapping a variable that is not defined in the aes() mapping of ggplot()",
    "text": "Mapping a variable that is not defined in the aes() mapping of ggplot()\nSometimes you may wish to map a variable that is not defined in ggplot(). We can map a variable that is neither x nor y:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) + \n  geom_point(mapping = aes(color = Team))\n\n\n\n\nThis is no problem because Team exists in the SWIM data passed to data in the ggplot() object."
  },
  {
    "objectID": "modules/13_visualizing_data.html#setting-and-mapping-combinations",
    "href": "modules/13_visualizing_data.html#setting-and-mapping-combinations",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Setting and Mapping Combinations",
    "text": "Setting and Mapping Combinations\nWe can also combine setting aesthetics and mapping them as long as mappings are inside aes() and settings are not.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(color = \"green\", \n             mapping = aes(shape = D)\n             )\n\n\n\n\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(color = \"blue\", \n             mapping = aes(size = A)\n             )\n\n\n\n\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(shape = 21, \n             mapping = aes(color = D)\n             )\n\n\n\n\nImportantly, just as you cannot pass constant values to aesthetics in aes(), you cannot pass a variable to an aesthetic in the geom function unless it is inside aes().\nFor example, passing color = A in this instance will throw an error.\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) + \n  geom_point(color = A)    # color needs to be set in aes()\nIn summary, when you want to set an aesthetic to a constant value, do so in the geometry function (e.g., geom_point()), otherwise, pass an aes() to the geometry function. Color options can be discovered using colors(). Linetype has fewer options. To make the color more or less transparent, adjust alpha (from 0 = invisible to 1).\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point() +\n  geom_line(linetype = \"dashed\",\n            color = \"red\",\n            alpha = .3\n            )"
  },
  {
    "objectID": "modules/11_summarizing_cognitive_task_data.html",
    "href": "modules/11_summarizing_cognitive_task_data.html",
    "title": "Summarizing Cognitive Task Data",
    "section": "",
    "text": "Overview\nThere is nothing special in this module. We will work on using group_by() and summarize() in a class exercise to summarize data. Come prepared to utilize this knowledge. Also, come prepared for an assessment on content covered in previous modules."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html",
    "href": "modules/09_working_with_cognitive_task_data.html",
    "title": "Working with Cognitive Task Data",
    "section": "",
    "text": "We will work with cognitive task data relevant for your team project. This module serves to remind you of libraries and functions presented in other modules so that you can utilize them efficiently during class time.\n\n\nAt this point in the semester, you have some experience working with RStudio, R objects, and R Markdown. You are also familiar with using different libraries and functions in service of completing in-class exercises and homework assignments using functions.\nThere will also be a 10 minute in-class practice assessment to assess your knowledge of R up to this point. The assessment will familiarize you with the type of assessments you will experience in future weeks. The assessment will be paper-and-pencil format without the use of the computer. Questions will be assess your knowledge and familiarity with different libraries, functions, your ability to identify and fix errors in code, your ability to determine which functions produce a certain output, etc.\n\n\n\nBefore Class: Read the module content to familiarize yourself with concepts that you will use to work with task data. In addition, review the content on the tasks so that you gain more appreciation of the tasks participants have completed and their relevance to the project."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#upcoming-assessments-heads-up",
    "href": "modules/09_working_with_cognitive_task_data.html#upcoming-assessments-heads-up",
    "title": "Working with Cognitive Task Data",
    "section": "",
    "text": "At this point in the semester, you have some experience working with RStudio, R objects, and R Markdown. You are also familiar with using different libraries and functions in service of completing in-class exercises and homework assignments using functions.\nThere will also be a 10 minute in-class practice assessment to assess your knowledge of R up to this point. The assessment will familiarize you with the type of assessments you will experience in future weeks. The assessment will be paper-and-pencil format without the use of the computer. Questions will be assess your knowledge and familiarity with different libraries, functions, your ability to identify and fix errors in code, your ability to determine which functions produce a certain output, etc."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#readings-and-preparation",
    "href": "modules/09_working_with_cognitive_task_data.html#readings-and-preparation",
    "title": "Working with Cognitive Task Data",
    "section": "",
    "text": "Before Class: Read the module content to familiarize yourself with concepts that you will use to work with task data. In addition, review the content on the tasks so that you gain more appreciation of the tasks participants have completed and their relevance to the project."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#libraries",
    "href": "modules/09_working_with_cognitive_task_data.html#libraries",
    "title": "Working with Cognitive Task Data",
    "section": "Libraries",
    "text": "Libraries\nAre you familiar with {here}, {dplyr}, and {readr} and key functions in those libraries?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#scripts-and-r-markdown",
    "href": "modules/09_working_with_cognitive_task_data.html#scripts-and-r-markdown",
    "title": "Working with Cognitive Task Data",
    "section": "Scripts and R Markdown",
    "text": "Scripts and R Markdown\nAre you familiar with creating R script files and R Markdown files? Do you know how to create code blocks in R Markdown as well as in-line R objects?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#importing-scripts-and-data-files",
    "href": "modules/09_working_with_cognitive_task_data.html#importing-scripts-and-data-files",
    "title": "Working with Cognitive Task Data",
    "section": "Importing Scripts and Data Files",
    "text": "Importing Scripts and Data Files\nAre you familiar with importing different types of data files? Do you know how to read script files from a different script or R Markdown file so that you can execute code that is saved in a different file?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#exporting-data-frames",
    "href": "modules/09_working_with_cognitive_task_data.html#exporting-data-frames",
    "title": "Working with Cognitive Task Data",
    "section": "Exporting Data Frames",
    "text": "Exporting Data Frames\nCan you export data frame objects as files of different file formats?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#vectors",
    "href": "modules/09_working_with_cognitive_task_data.html#vectors",
    "title": "Working with Cognitive Task Data",
    "section": "Vectors",
    "text": "Vectors\nCan you create vectors that are independent from/external to a data frame? Can you create vector variables inside a data frame? Are you familiar with element position in a vector?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#variable-names",
    "href": "modules/09_working_with_cognitive_task_data.html#variable-names",
    "title": "Working with Cognitive Task Data",
    "section": "Variable Names",
    "text": "Variable Names\nDo you know how to extract the variable names from a data frame and rename variables?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#data-wrangling-and-manipulation",
    "href": "modules/09_working_with_cognitive_task_data.html#data-wrangling-and-manipulation",
    "title": "Working with Cognitive Task Data",
    "section": "Data Wrangling and Manipulation",
    "text": "Data Wrangling and Manipulation\nAre you familiar with creating new variables or modify existing variables in a data frame? Can you select subsets of variables from a data frame? Are you familiar with how filtering works in order to filter rows from a data frame? Can you reorder variable position in a data frame?"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#key-components-of-the-gono-go-task",
    "href": "modules/09_working_with_cognitive_task_data.html#key-components-of-the-gono-go-task",
    "title": "Working with Cognitive Task Data",
    "section": "Key Components of the Go/No-Go Task",
    "text": "Key Components of the Go/No-Go Task\n\nResponse Inhibition: Ability to inhibit automatic responses to certain stimuli.\nImpulse Control: Capacity to resist impulsive responses.\nExecutive Function: Cognitive processes like planning and decision-making.\nAttentional Control: Ability to focus on relevant stimuli.\nError Monitoring: Detecting and correcting errors in real-time.\n\nThe Go/No-Go task is correlated with various cognitive behaviors, including:"
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#relationships-with-other-cognitive-behaviors",
    "href": "modules/09_working_with_cognitive_task_data.html#relationships-with-other-cognitive-behaviors",
    "title": "Working with Cognitive Task Data",
    "section": "Relationships with other Cognitive Behaviors",
    "text": "Relationships with other Cognitive Behaviors\n\nResponse inhibition: The ability to withhold a prepotent or automatic response in the presence of inhibitory cues (No-Go stimuli).\nImpulse control: The capacity to resist impulsive responses and act in accordance with task instructions.\nExecutive function: The cognitive processes involved in planning, decision-making, and cognitive flexibility, which are necessary for effective performance on the task.\nAttentional control: The ability to selectively attend to relevant stimuli while ignoring irrelevant or distracting stimuli.\nError monitoring: The capacity to detect and correct errors in real-time, which is crucial for adaptive behavior in changing environments.\n\nOverall, the Go/No-Go task provides valuable insights into the functioning of various cognitive processes related to inhibition and self-regulation, making it a widely used tool in cognitive neuroscience and clinical psychology research."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#the-gono-go-task-understanding-inhibitory-control-and-drug-use",
    "href": "modules/09_working_with_cognitive_task_data.html#the-gono-go-task-understanding-inhibitory-control-and-drug-use",
    "title": "Working with Cognitive Task Data",
    "section": "The Go/No-Go Task: Understanding Inhibitory Control and Drug Use",
    "text": "The Go/No-Go Task: Understanding Inhibitory Control and Drug Use\nThe Go/No-Go task has been extensively used in research examining the relationship between cognitive functions, particularly inhibitory control, and drug use. Individuals with substance use disorders often exhibit deficits in inhibitory control, and the Go/No-Go task is one of the tools used to assess these deficits. Here are some key findings related to drug use and the Go/No-Go task:\nImpaired Inhibitory Control in Substance Use Disorders: Individuals with substance use disorders, such as those involving alcohol, cocaine, cannabis, and stimulants, often show impaired inhibitory control as measured by the Go/No-Go task. This suggests that difficulties in suppressing automatic responses may contribute to the development and maintenance of addictive behaviors.\nPredictive Value for Substance Use Outcomes: Deficits in inhibitory control, as assessed by the Go/No-Go task, have been found to be predictive of substance use outcomes. Individuals with poorer inhibitory control on the task may be at a higher risk of continued substance use, relapse, or difficulties in maintaining abstinence.\nNeural Correlates: Neuroimaging studies have explored the neural correlates of inhibitory control deficits in substance use. Dysfunction in brain regions associated with inhibitory control, such as the prefrontal cortex, has been observed in individuals with substance use disorders during the performance of the Go/No-Go task.\nTreatment Implications: The Go/No-Go task has also been used to evaluate the effects of interventions and treatments for substance use disorders. Improvements in inhibitory control, as measured by the task, have been associated with successful treatment outcomes.\nPolydrug Use: Research has investigated inhibitory control in individuals with polydrug use, examining how the task performance may vary across different substances. Different substances may have distinct effects on inhibitory control, and the Go/No-Go task helps in understanding these nuances.\nOverall, the Go/No-Go task serves as a valuable tool in studying the cognitive aspects of substance use disorders, providing insights into the relationship between inhibitory control deficits and drug use behaviors. This research contributes to a better understanding of the underlying mechanisms of addiction and aids in the development of targeted interventions and treatments."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#gono-go-and-nicotine",
    "href": "modules/09_working_with_cognitive_task_data.html#gono-go-and-nicotine",
    "title": "Working with Cognitive Task Data",
    "section": "Go/No-Go and Nicotine",
    "text": "Go/No-Go and Nicotine\nThere are relationships between the Go/No-Go task and nicotine use. Studies have shown that individuals who smoke cigarettes or use nicotine in other forms may exhibit differences in inhibitory control as measured by the Go/No-Go task.\nInhibitory Control Deficits: Individuals who smoke cigarettes or use nicotine products have been found to demonstrate deficits in inhibitory control. They may have difficulties inhibiting responses to No-Go stimuli compared to non-smokers or individuals who do not use nicotine.\nImpact on Decision-Making: Nicotine use has been associated with alterations in decision-making processes, which are closely related to inhibitory control. The Go/No-Go task assesses the ability to make rapid decisions and inhibit inappropriate responses, and nicotine use may impact performance on this task.\nWithdrawal Effects: Research suggests that acute nicotine withdrawal may further impair inhibitory control. Individuals undergoing nicotine withdrawal may exhibit greater difficulties in inhibiting responses to No-Go stimuli, potentially leading to increased impulsivity and risk-taking behaviors.\nCognitive Processing: Nicotine affects various cognitive processes, including attention, working memory, and inhibitory control. The Go/No-Go task provides insights into the specific cognitive domains affected by nicotine use and withdrawal, helping to elucidate the underlying mechanisms.\nTreatment Response: Studies have investigated the effects of nicotine replacement therapy (NRT) and other smoking cessation interventions on inhibitory control. Improvements in inhibitory control following smoking cessation may contribute to successful quitting outcomes and relapse prevention."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#symmetry-span-and-inhibition",
    "href": "modules/09_working_with_cognitive_task_data.html#symmetry-span-and-inhibition",
    "title": "Working with Cognitive Task Data",
    "section": "Symmetry Span and Inhibition",
    "text": "Symmetry Span and Inhibition\nSymmetry Span performance is correlated with inhibition, the ability to suppress or ignore irrelevant information or responses while focusing on relevant stimuli or tasks. This ability is closely related to executive functioning and is an essential component of cognitive control.\nIn the Symmetry Span Task, participants need to inhibit the interference caused by the unrelated items presented between the displays while focusing on the primary task of assessing symmetry. Individuals must resist the temptation to let the interference items disrupt their performance on the symmetry judgment task or interfere with their ability to recall the items presented during the interference phase.\nIndividuals with better inhibition skills are expected to perform better on the Symmetry Span Task because they can more effectively manage competing demands on their attention and resist interference from irrelevant information. Conversely, individuals with weaker inhibition skills may struggle more on the task, as they may have difficulty maintaining focus and effectively managing the interference. Therefore, the Symmetry Span Task serves as a measure of not only working memory capacity but also the ability to inhibit irrelevant information, making it correlated with inhibition as one aspect of executive functioning."
  },
  {
    "objectID": "modules/09_working_with_cognitive_task_data.html#symmetry-span-and-gono-go",
    "href": "modules/09_working_with_cognitive_task_data.html#symmetry-span-and-gono-go",
    "title": "Working with Cognitive Task Data",
    "section": "Symmetry Span and Go/No-Go",
    "text": "Symmetry Span and Go/No-Go\nThe correlation between performance on the Symmetry Span Task and performance on a Go/No-Go task is complex and not direct. Although both tasks involve aspects of executive functioning and cognitive control, they assess somewhat different cognitive processes.\nThe Symmetry Span Task primarily measures working memory capacity and the ability to maintain and manipulate information in memory while managing interference from unrelated items. It also taps into aspects of attention control and inhibition, as participants need to resist interference from irrelevant information during the task.\nThe Go/No-Go task, however, typically measures response inhibition and impulse control. In a Go/No-Go task, participants respond (Go) to one type of stimulus while withholding their response (No-Go) to another type of stimulus. This task primarily assesses the ability to inhibit pre-potent responses and to control impulsivity.\nWhile both tasks involve aspects of inhibition and cognitive control, they assess different aspects of inhibition and may rely on somewhat different neural mechanisms. As a result, the correlation between performance on the Symmetry Span Task and performance on a Go/No-Go task may not be particularly strong or straightforward. However, individuals who perform well on tasks requiring inhibition and cognitive control may also perform well on both tasks due to shared underlying cognitive processes and executive functioning skills."
  },
  {
    "objectID": "modules/07_variables_and_measures_of_cognition.html",
    "href": "modules/07_variables_and_measures_of_cognition.html",
    "title": "Variables and Measures of Cognition",
    "section": "",
    "text": "In this module, we will consider different cognitive tasks, understand how those are measured, and understand the variables associated with them.\n\n\nThere are no formal readings assigned for this topic. We will use class time to discuss the symmetry span and the go/no-go tasks, how they are performed by participants, what variables are measured, and how those tasks are correlated with other variables.\nBecause you will read papers related to cognitive tasks in order to inform your team project, paper that introduce either complex-working memory span tasks (e.g., symmetry span) or the go/no-go task would benefit you during class time. Reading through a relevant paper would help you answer questions and conceptualize the task and its relation to the larger project."
  },
  {
    "objectID": "modules/07_variables_and_measures_of_cognition.html#readings-and-preparation",
    "href": "modules/07_variables_and_measures_of_cognition.html#readings-and-preparation",
    "title": "Variables and Measures of Cognition",
    "section": "",
    "text": "There are no formal readings assigned for this topic. We will use class time to discuss the symmetry span and the go/no-go tasks, how they are performed by participants, what variables are measured, and how those tasks are correlated with other variables.\nBecause you will read papers related to cognitive tasks in order to inform your team project, paper that introduce either complex-working memory span tasks (e.g., symmetry span) or the go/no-go task would benefit you during class time. Reading through a relevant paper would help you answer questions and conceptualize the task and its relation to the larger project."
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html",
    "href": "modules/05_vectors_and_data_frame_basics.html",
    "title": "Vectors and Data Frame Basics",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#readings-and-preparation",
    "href": "modules/05_vectors_and_data_frame_basics.html#readings-and-preparation",
    "title": "Vectors and Data Frame Basics",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#libraries",
    "href": "modules/05_vectors_and_data_frame_basics.html#libraries",
    "title": "Vectors and Data Frame Basics",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management\n\n\nTo Do\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. Concepts will be applied in class in order to complete activities, however. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence."
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#combining-elements-into-vectors-using-c",
    "href": "modules/05_vectors_and_data_frame_basics.html#combining-elements-into-vectors-using-c",
    "title": "Vectors and Data Frame Basics",
    "section": "Combining elements into vectors using c()",
    "text": "Combining elements into vectors using c()\nOne way to create vectors is by using the combine function, c(). You can combine numeric and character elements into a vector. Let’s create some examples and assign names to them.\n\nNumeric vector:\n\nnumeric_vector &lt;- c(23, 22, 35)\n\nCall the object:\n\nnumeric_vector\n\n[1] 23 22 35\n\n\nNotice that the 3 returned elements of the vector are numbers.\n\n\nCharacter vector:\n\ncharacter_vector &lt;- c(\"Salle\", \"Jane\", \"Beavis\")\n\ncharacter_vector\n\n[1] \"Salle\"  \"Jane\"   \"Beavis\"\n\n\nNow, the 3 returned elements are enclosed by quotation marks, \". The quotes help you understand that the vector is character type.\n\n\nNumeric values as a character:\n\nquote_num_vector &lt;- c(\"23\", \"22\", \"35\")\n\nquote_num_vector\n\n[1] \"23\" \"22\" \"35\"\n\n\nAlthough the elements are numbers, they are in quotes, which indicates that the vector is character type.\n\n\nNumbers and characters:\n\nnum_char_vector &lt;- c(23, \"22\", \"35\")\n\nnum_char_vector\n\n[1] \"23\" \"22\" \"35\"\n\n\nAlthough one of the elements of the vector is numeric, the entire vector is returned as character. This is an important characteristic of vectors in R. They can be numeric or character but not both. If there is even one number enclosed by quotes, the vector is character as seen here.\n\nc(23, 22, 35, \"30\")\n\n[1] \"23\" \"22\" \"35\" \"30\""
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#creating-vectors-using-rnorm",
    "href": "modules/05_vectors_and_data_frame_basics.html#creating-vectors-using-rnorm",
    "title": "Vectors and Data Frame Basics",
    "section": "Creating vectors using rnorm()",
    "text": "Creating vectors using rnorm()\nLet’s use rnorm() to create a numeric vector object that will represent sampling from a random normal distribution. The distribution will have a certain number of observations, n, a mean, mean, and a standard deviation, sd. We will need to pass arguments to create the data.\nParameters/Arguments:\n\nn: the number of elements in the vector\nmean: the mean of the elements\nsd: the standard deviation of the elements\n\nLet’s create a random normal distribution with a length of 1000 values. The mean should be 100 and standard deviation 15 (e.g., IQ distribution).\n\niq &lt;- rnorm(n = 1000, mean = 100, sd = 15)  \n\nRemember, as long as the order is correct, you do not have to specify the parameter names. You only need to specify the arguments for the parameters.\n\niq &lt;- rnorm(1000, 100, 15)      \n\nLook at the object’s head using head() in order to inspect the first 6 elements:\n\nhead(iq)                        \n\n[1]  89.81548  86.61583 106.33264 100.20147 143.39356  99.31722\n\n\nOr inspect the first 10 elements by setting n = 10.\n\nhead(iq, n = 10)\n\n [1]  89.81548  86.61583 106.33264 100.20147 143.39356  99.31722 104.20972\n [8]  95.85224  94.92441  82.81541"
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#creating-number-sequences-using-seq",
    "href": "modules/05_vectors_and_data_frame_basics.html#creating-number-sequences-using-seq",
    "title": "Vectors and Data Frame Basics",
    "section": "Creating number sequences using seq()",
    "text": "Creating number sequences using seq()\nYou can dig a little more deeply into the functionality of seq() by looking at the help documentation, help(seq) or ?seq.\nParameters/Arguments:\n\nfrom, to: the starting and (maximal) end values of the sequence. Of length 1 unless just from is supplied as an unnamed argument.\nby: number: increment of the sequence.\nlength.out: desired length of the sequence. A non-negative number, which for seq and seq.int will be rounded up if fractional.\nalong.with: take the length from the length of this argument.\n\n\nSequences from one value to another\nUse seq() to create a sequence FROM 1 TO 10:\n\nseq(from = 1, to = 10)       \n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe help documentation will inform you that the from and to parameters are in the first and second position, respectively. We can specify their arguments without using the parameter explicitly.\nReference only to:\n\nseq(1, to = 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nOr, remove both:\n\nseq(1, 10) \n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe returned result will be the same.\n\n\nSequences with increments using the by argument\nWe can also modify the from and to step through using the by function such that the numbers will increment by the value of by.\n\nseq(2, 10, by = 2)           # FROM 2 TO 10 BY 2s, dropping from and to arguments\n\n[1]  2  4  6  8 10\n\n\nUsing another example, create a sequence from 1 to 1000 and assign that to an object named id.\n\nid &lt;- seq(1, 1000)            # assign a sequence of 1 to 1000 to a vector named id\n\nInspecting the head:\n\nhead(id)\n\n[1] 1 2 3 4 5 6\n\n\n\n\nObtaining the number of elements using length()\nIf the number of elements in a vector variable changes, hard coding can be troublesome. We can return the length() of the sex vector and pass that as the sequence value. This approach is useful for objects that get modified. This approach would be more flexible.\n\nlength(sex)                # length will return the length of the vector, including NAs\n\n[1] 1000\n\n\nGreat, we get 1000!\n\n\nCreating a sequence using other functions\nThe argument for a function can also be another function. If we have the number of elements in a vector, we could also create a sequence from a starting number to the ending number as defined the another function.\nAssign a sequence of 1 to the length() of the sex object and assign that to an object named id. To make the code more easy to read, we will place the parameters on separate lines.\n\nid &lt;- seq(from = 1, \n          to = length(sex)\n          )  \n\nAnd look at the head:\n\nhead(id)\n\n[1] 1 2 3 4 5 6"
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#converting-numeric-or-characters-containing-numbers-to-integer",
    "href": "modules/05_vectors_and_data_frame_basics.html#converting-numeric-or-characters-containing-numbers-to-integer",
    "title": "Vectors and Data Frame Basics",
    "section": "Converting numeric or characters containing numbers to integer",
    "text": "Converting numeric or characters containing numbers to integer\nConvert to integer:\n\niq &lt;- as.integer(iq)\n\nNow they are integers:\n\nhead(iq)\n\n[1]  89  86 106 100 143  99"
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#converting-numeric-vectors-to-character",
    "href": "modules/05_vectors_and_data_frame_basics.html#converting-numeric-vectors-to-character",
    "title": "Vectors and Data Frame Basics",
    "section": "Converting numeric vectors to character",
    "text": "Converting numeric vectors to character\nIf the characters are numbers, pass an existing vector into as.character() to convert\n\niq &lt;- as.character(iq)                # make is a character vector  \n\nNow the numbers are in quotes representing strings.\n\nhead(iq)               \n\n[1] \"89\"  \"86\"  \"106\" \"100\" \"143\" \"99\""
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#converting-character-vectors-to-numeric",
    "href": "modules/05_vectors_and_data_frame_basics.html#converting-character-vectors-to-numeric",
    "title": "Vectors and Data Frame Basics",
    "section": "Converting character vectors to numeric",
    "text": "Converting character vectors to numeric\nIf the elements are characters, pass an existing vector into as.integer() to convert.\n\niq &lt;- as.integer(iq)  \n\nNow elements are integers, not floats.\n\nhead(iq)\n\n[1]  89  86 106 100 143  99\n\n\nYou can also wrap a function in another function when the initial object is created. Here, as.integer() converts the vector returned by rnorm() into an integer.\n\niq &lt;- as.integer(rnorm(1000, 100, 15))                 # create initially by wrapping as.integer() around rnorm()"
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#using-piping-operators-and",
    "href": "modules/05_vectors_and_data_frame_basics.html#using-piping-operators-and",
    "title": "Vectors and Data Frame Basics",
    "section": "Using piping operators |> and %>%",
    "text": "Using piping operators |&gt; and %&gt;%\nAlternatively, if nesting functions and reading them from the inside out confuses you, you can instead use piping operators to pass objects from function to function. Piping also improves code readability.\nBase R now includes it’s own piping operator, |&gt;. In the past, piping was accomplish using {magrittr} piping operators and sometimes those operators work better than the base R pipe. The main piping operator from {magrittr} is %&gt;%. To use it, we will need to load the library first using library(), though you should loads all libraries at the top of your file. We will use both piping operators to illustrate differences in functionality. I may use them interchangeably in materials.\nLoad the library:\n\nlibrary(magrittr)\n\nCreate the iq vector:\n\niq &lt;- rnorm(1000, 100, 15)        # create the random normal dist\n\nCheck whether the vector is an integer:\n\nis.integer(iq)\n\n[1] FALSE\n\n\nis.integer() is a logical test, so it will return either TRUE or FALSE. You see that the vector is not an integer as FALSE was returned. Because IQ scores are integers, let’s use the process to make it an integer.\n\niq &lt;- rnorm(1000, 100, 15) %&gt;%    # create the random normal dist\n    as.integer()                  # pipe to make integer\n\nUsing base R’s piping operator:\n\niq &lt;- rnorm(1000, 100, 15) |&gt;     # create the random normal dist\n    as.integer()                  # pipe to make integer"
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#examine-the-head-of-the-object",
    "href": "modules/05_vectors_and_data_frame_basics.html#examine-the-head-of-the-object",
    "title": "Vectors and Data Frame Basics",
    "section": "Examine the head() of the object",
    "text": "Examine the head() of the object\nHowever you create the vector, we can examine the head of the vector using head():\n\nhead(iq)\n\n[1] 103 103 116 106 104  90\n\n\nA note about pipes: If you did not pipe the object from one function to another, you would need to wrap the functions as layers. The the function in the inner layer would be executed first and the function of the outer layer would be executed last.\nas.integer(rnorm(1000, 100, 15))\nAlthough there is nothing incorrect with this code, readability is compromised because you have to read the functions from the inside out. Piping objects to functions allows for reading functions from top to bottom."
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#plotting-the-vector-using-hist",
    "href": "modules/05_vectors_and_data_frame_basics.html#plotting-the-vector-using-hist",
    "title": "Vectors and Data Frame Basics",
    "section": "Plotting the vector using hist()",
    "text": "Plotting the vector using hist()\nAnd to see a plot, use hist(iq):\n\nhist(iq)\n\n\n\n\nOr pass the object using a pipe (e.g., |&gt; or %&gt;%) and pipe the vector to the histogram function in base R:\n\niq %&gt;% hist()\n\n\n\n\n\niq |&gt; hist()\n\n\n\n\nNotice that this approach changes the title. When piping objects with {magrittr}’s pipe, the object is referenced using . so this because the name of the object."
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#adding-a-title-to-the-plot",
    "href": "modules/05_vectors_and_data_frame_basics.html#adding-a-title-to-the-plot",
    "title": "Vectors and Data Frame Basics",
    "section": "Adding a title to the plot",
    "text": "Adding a title to the plot\nTO add a title, pass a string argument to main:\n\niq |&gt; hist(main = \"IQ Distribution\")"
  },
  {
    "objectID": "modules/05_vectors_and_data_frame_basics.html#recoding-vectors",
    "href": "modules/05_vectors_and_data_frame_basics.html#recoding-vectors",
    "title": "Vectors and Data Frame Basics",
    "section": "Recoding vectors",
    "text": "Recoding vectors\nSometimes elements of vectors are messy and need to be fixed. In general, this process is referred to as recoding. There are various ways to recode in R and there are special libraries dedicated to recoding. Now, we will perform some simple recoding.\nYou can use ifelse() or dplyr::case_when() to test whether the elements of a vector match some condition and if yes (do one thing), otherwise no (do something else). In order to understand how these functions and many others work we need to understand a logical test.\n\nifelse()\ndplyr::case_when()\n\n\nPerforming a logical test\nWe can perform a logical test on all types of objects but this example will focus on vectors, for which all elements will be examined. The logical test will return TRUE or FALSE for each vector element depending on whether the case matches a test condition.\nRather than illustrate this the 1000 element sex vector, we will create a vector of length 5 called temp_sex. In this example, you will also see what happens when you need to clean up and recode the sloppy data. You can see are composed of both upper and lower case letters presumably corresponding to biological sex. Because R is a case-sensitive language, \"M\" and \"m\" represent different objects even though the intent is for them to be the same.\n\ntemp_sex &lt;- c(\"M\", \"m\", \"F\", \"f\", NA)\n\nYou can see that some character elements in the vector are upper- and lowercase m’s and f’s. Let’s see what happens when we perform a logical test of the vector. Remember that by itself = will be assignment (like &lt;-). In order to determine whether an object or elements of an object is equal to something, we use ==.\nFor example, temp_sex == \"M\":\n\ntemp_sex == \"M\"\n\n[1]  TRUE FALSE FALSE FALSE    NA\n\n\nThe returned vector is of the same length as the vector tested. Each element of the vector was tested and those elements that matched the character \"M\" returns TRUE. The other elements are FALSE, except of the NA, or missing value. Importantly, the logical test does not return FALSE for NAs.\n\n\nRecoding using ifelse()\nLet’s perform the logical test inside ifelse(). The function will test each element and IF it is TRUE (matches the condition) will assign 0, else/otherwise assign 1 in order to recode the letters into numbers. Of course, you may often wish to recode letters into other letters.\n\nifelse(temp_sex == \"M\", 0, 1)\n\n[1]  0  1  1  1 NA\n\n\nWe can see that all of the TRUEs are 0 and all else except for NA are 0. You can see that only the \"M\" was recoded to 0 and all other elements that were not NA were recoded as 1. Clearly, this is not correct. We can use multiple ifelse() functions but the solution won’t be offered here because it’s just really messy. Instead of focusing on bad code, let’s just focus on offering better solutions.\nPerforming the same test on sex but piping the vector to head() will allow for inspection of the first few elements.\n\nifelse(sex == \"M\", 0, 1) |&gt;\n  head()\n\n[1] 1 1 1 1 1 1\n\n\nThe ifelse() approach is fine for two groups. When there are more than two groups, however, re-coding can be confusing with ifelse() because you’ll need to nest an ifelse() inside an ifelse(). The popular {dplyr} library also has a couple functions similar to ifelse(), for example, if_else() and case_when().\n\n\nRecoding using dplyr::case_when()\nThe case_when() function will also perform logical tests but you can easily specify more than one. The help documentation tells us that “This function allows you to vectorise multiple if_else() statements. Each case is evaluated sequentially and the first match for each element determines the corresponding value in the output vector. If no cases match, the .default is used as a final”else” statement.” And later “If none of the cases match and no .default is supplied, NA is used.\nWith case_when(), we will perform a logical test of the elements against the character string \"M\" first. The elements that match \"M\" will evaluate as TRUE and will be recoded as 0. Then the elements of the new recoded vector will be tested again against \"F\". Those that are TRUE will be recoded as 1. Anything else will be assigned NA for missing because they matched neither \"M\" nor \"F\".\nWe wee that only the first element returns TRUE. Other elements are FALSE or NA.\n\ndplyr::case_when(\n  temp_sex == \"M\" ~ 0,\n  temp_sex == \"F\" ~ 1\n  ) \n\n[1]  0 NA  1 NA NA\n\n\nBut note that if the character case is inconsistent, NA’s will replace elements that are \"m\" and \"f\". An easy fix for casing is to convert the vector (without assignment) by passing it to tolower() or toupper() and then perform the logical conversion on the case change elements.\n\ndplyr::case_when(\n  toupper(temp_sex) == \"M\" ~ 0,\n  toupper(temp_sex) == \"F\" ~ 1\n  ) \n\n[1]  0  0  1  1 NA\n\n\nYou can now see that all elements will evaluate to TRUE and are recoded except for the NA in the vector. Keep in mind that strings may be very messy and require careful inspection and cleaning. Sometimes simple case recoding solves your problems.\nNote: There is a much powerful library called {stringr} for wrangling strings. We will use this library to perform other tasks. If you wanted to familiarize yourself with making strings upper or lowercase using that library, use stringr::str_to_lower() and stringr::str_to_upper().\nTo illustrate:\n\nlibrary(stringr)            # load the library first\n\ndplyr::case_when(\n  str_to_upper(temp_sex) == \"M\" ~ 0,\n  str_to_upper(temp_sex) == \"F\" ~ 1\n  ) \n\n[1]  0  0  1  1 NA\n\n\nWhen you have more logical tests to perform, you can specify them on a new line. Using the existing vector, we can illustrate with a silly example.\n\ndplyr::case_when(\n  temp_sex == \"m\" ~ \"Young Men\",\n  temp_sex == \"M\" ~ \"Old Men\",\n  temp_sex == \"f\" ~ \"Young Women\",\n  temp_sex == \"F\" ~ \"Old Women\",\n  ) \n\n[1] \"Old Men\"     \"Young Men\"   \"Old Women\"   \"Young Women\" NA           \n\n\nWe have not recoded the vector to have clear names for 4 groups, plus and NAs. Of course, you have not changed temp_sex unless you assign the returned vector to a name.\n\ntemp_sex\n\n[1] \"M\" \"m\" \"F\" \"f\" NA \n\n\nAssign to temp_sex to overwrite:\n\ntemp_sex &lt;- dplyr::case_when(\n  temp_sex == \"m\" ~ \"Young Men\",\n  temp_sex == \"M\" ~ \"Old Men\",\n  temp_sex == \"f\" ~ \"Young Women\",\n  temp_sex == \"F\" ~ \"Old Women\",\n  ) \n\n\ntemp_sex\n\n[1] \"Old Men\"     \"Young Men\"   \"Old Women\"   \"Young Women\" NA"
  },
  {
    "objectID": "modules/02_using_git_and_github.html",
    "href": "modules/02_using_git_and_github.html",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#overview",
    "href": "modules/02_using_git_and_github.html#overview",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Overview",
    "text": "Overview\nIn order to maintain organization, you will set up a class folder/directory on your computer. You will then create an RStudio project and connect it to GitHub. Finally, you will create directories within your new project directory so that you have an organized directory structure for storing your files. This process will also ensure that all student’s computers are configured in the same manner.\nIn class, we will use Git to interact with a remote repository connected to a Project in RStudio. Reading through these steps, however, will facilitate your ability to apply the concepts and run the associated functions in class. in order to create project for class exercises (and homework) as well as your team project.\n\nReadings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\nTo Do: Steps of the Task\n\nSet up your class space\n\n\nCreate top-level /fods24 directory\n\n\nCreate Version Control Projects in RStudio\n\n\nExercises\n\nTeam Project (will do in class)\n\n\nMake file edits, stage the, and commit them\nPush commits to GitHub\n\nClass Activity:\nWhen you collaborate with others, you have to be more mindful of the changes you make and those that others make, ensuring that the repository can incorporate the changes. Thus, we will interact with Git in class in a slightly different way.\nThings we will do:\n\nCreate a new project and connect to a remote repository\nCreate a branch (connect to a branch)\nMake file edits, stage them, and commit them\nPush commits to GitHub\nMerge your branch with the main brain"
  },
  {
    "objectID": "modules/02_using_git_and_github.html#libraries-used",
    "href": "modules/02_using_git_and_github.html#libraries-used",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Libraries Used",
    "text": "Libraries Used\n\n{usethis}: 2.2.2: for project workflow automation\n{gitcreds}: 0.1.2: for querying git credentials"
  },
  {
    "objectID": "modules/02_using_git_and_github.html#creating-a-local-directory-for-class",
    "href": "modules/02_using_git_and_github.html#creating-a-local-directory-for-class",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Creating a Local Directory for Class",
    "text": "Creating a Local Directory for Class\nCreate a folder (aka directory) named \"fods24\" on your computer. I recommend creating the directory someplace where you might not accidentally delete it."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#connecting-the-repository-to-an-rstudio-project",
    "href": "modules/02_using_git_and_github.html#connecting-the-repository-to-an-rstudio-project",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Connecting the Repository to an RStudio Project",
    "text": "Connecting the Repository to an RStudio Project\n\nIn RStudio, File &gt; New Project &gt; Version Control &gt; Git.\nIn the pop-up, you will see a request for the “repository URL”. Paste the URL of the GitHub repository. This URL will be the same as what you see on your GitHub account. However, we need to add .git to the end of it.\n\n    https://github.com/&lt;your_github_username&gt;/fods-exercises.git\n\nWhen you create the project, a directory will be created as a sub-directory of /fods24 and its name should auto populate (e.g., 'fods-exercises').\n\nWARNING: Do not create the project inside of an existing project’s directory.\n* Note: I recommend that you also select *\"Open in new session\"* in order to compartmentalize projects. When you work on the team project, open the project. When you work on your homework or other class exercises, open your *homework* project.\n\nClick “Create Project” to create the new project directory, which will create:\n\na project directory on your computer\na project file with file extension .Rproj\na Git repository or link to the remote GitHub repository for the project (also an RStudio Project)\n\n\nIf the repository already exists on GitHub (and it does in this instance) you should see RStudio flash a connection to GitHub and likely pull the repo contents down to your newly-created project directory. In this case, however, your repository will contain few files."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#creating-project-relevant-directories",
    "href": "modules/02_using_git_and_github.html#creating-project-relevant-directories",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Creating Project Relevant Directories",
    "text": "Creating Project Relevant Directories\nNow, inside the /fods24/fods-exercises directory, create directories named:\n\ndata\ndocs\nfigs\nr\nrefs\nreport\n\nYou will now see the directory structure, though all your directories will be empty. Moving forward, save all data to /data, create all .R files in /r, and create all exercise or homework R Markdown files (e.g., .Rmd) in /report. Any readings or references can can saved in /refs and any other document files can be saved in /docs. Finally, reserve /figs for saving plots or figures."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#understanding-git-workflow-basics",
    "href": "modules/02_using_git_and_github.html#understanding-git-workflow-basics",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Understanding Git Workflow Basics",
    "text": "Understanding Git Workflow Basics\nThere are three main parts to Git Workflow:\n\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)"
  },
  {
    "objectID": "modules/02_using_git_and_github.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "modules/02_using_git_and_github.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\nMaking a local change\n\nCreate a .R script and name it something like yourname.R. Where should you save it? You guessed it: /r.\n\nChecking the status of local file changes\n\nCheck for the local changes you have made at the Terminal by typing git status and press return/enter\n\n$ git status\n\nIf you made changes, Git will tell you what those changes are. For example, there will be a new file, a deleted file, a modified file, etc.\n\nStaging Changes (Add Changes)\n\nStage a specific change: If you made multiple changes and all you want to do is commit a single change and no others, you can specify the change you want to add. For example, if you want only to add a specific file, like yourname.R, you will use git add &lt;file&gt;... such that &lt;file&gt; refers to the file name.\n\nAt the Terminal prompt, type git add followed by &lt;file&gt; to include in what will be committed)\n$ git add r/yourname.R\n\nStage all change(s): When you make numerous changes, you may wish not to specify each file individually as that could be tedious. In this case, you may wish to stage all of your changes. Assuming everything you are doing is relevant to the project, one of the easiest ways to add changes is to just add all of your file changes. Note, your changes should not be done inside data files (e.g., .csv, .xlsx). Changes should only be done using R code. If not, your project will not be reproducible.\n\nAt the Terminal, you can type git add . which tells Git that you are adding all of those changes to commit them.\n$ git add .\n\n\nCommitting the change(s)\n\nNow that you made a change, you will commit it and assign a useful message to remind your future self and collaborators what you just did.\n\nAt the Terminal, type git commit to commit the changes, add -m to tell git you want a message, and then type the message as a string, \"my message here\" and then press enter/return to commit the changes.\n$ git commit -m \"added my first .R file\"\n\n\nPush the change to the remote repository\n\nWe need to push the changes to the remote GitHub repository for version control and for collaborators to access\n\nAt the Terminal, you will push those changes using git push and press enter/return to push.\n$ git push\n\nIf you navigate to your GitHub account in your web browser, you will see the changes there as soon as they arrive. Congrats!\n\nPractice (Yes, seriously): Changing, Committing, and Pushing Again\n\nYou know that file with your name is not needed for the project. Delete it from the project as you normally would delete a file (no need to use the Terminal) and then add the change, commit the change with message “deleted my silly file”, and push changes.\nIf for some reason, your push did not work, you may need to specify the project branch. Branching is beyond the scope of this course. If team members are working on separate tasks, their code will be compartmentalized so you can use the main branch.\n\nYou can set the branch to the main branch at the Terminal using git branch -M main.\n$ git branch -M main\n\n\nPushing Specific File Changes\n\nYou should not push all of your edits. For example, if you edit a file and save it but it is incomplete (e.g., it contains errors) that will create problems for your team members, you do not want to push them to the repo. If you do, your team member’s code will also break if they are sourcing (e.g., source()) your script file. Similarly, if the data file you write out contains errors, a teammate cannot read that file in successfully. So make sure that what you push is correct and accurate before pushing.\n\nPulling Changes from the Remote\n\nThe opposite of push is pull. When your teammates push their changes (e.g., data cleaning, file creation, etc.) to the repo and your code depends on those files, you will want to make sure their edits are in your local project so that you can use them.\n\nTo pull the changes down to your project, at the Terminal, type git pull.\n$ git pull\n\nYou should find the changes appear in your local project directory."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#using-the-git-tab-in-your-rstudio-pane",
    "href": "modules/02_using_git_and_github.html#using-the-git-tab-in-your-rstudio-pane",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Using the Git Tab in your RStudio Pane",
    "text": "Using the Git Tab in your RStudio Pane\nIf you do not use the Terminal to run Git commands (e.g., add, commit, and push), you can also use Git with RStudio, though I tend to find this process creates an annoying lag when there are many files.\nWhen you edit files (e.g., made changes and saved the file), the file will be detected in the project if you have set up Git. The changes detected will be listed in the window for this tab. You can then stage, commit the changes, push the changes using this RStudio GUI.\n\nClick the Git tab\nCheck the box under Staged next to the file\n\nNote: There may be a delay.\n\nClick the Commit icon on the toolbar directly above Status\n\nA window will pop up showing some of the edits to the file\nA window for Commit message will also appear for adding your message. This window is where you want to be.\n\nType your commit message in that window\n\nYour message should be clear and useful to remind your future self or colleagues of the edits but not be overly wordy.\n\nClick Commit to commit the change\nClick the Green Arrow to Push your committed change up to the remote repository.\n\nNote: You will click the Blue Arrow to Pull the changes down from the remote repository what were pushed there by your collaborators"
  },
  {
    "objectID": "modules/02_using_git_and_github.html#creating-a-version-control-project-in-rstudio-for-the-team-project",
    "href": "modules/02_using_git_and_github.html#creating-a-version-control-project-in-rstudio-for-the-team-project",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Creating a Version Control Project in RStudio for the Team Project",
    "text": "Creating a Version Control Project in RStudio for the Team Project\n\nIn RStudio, File &gt; New Project &gt; Version Control &gt; Git.\nIn the pop-up, you will see a request for the “repository URL”. Paste the URL of the GitHub repository based on your liaison name. This URL will be the same as what you see on your GitHub account. However, we need to add .git to the end.\n\n    https://github.com/slicesofdata/fods24-&lt;to_be_announced&gt;.git\n\nWhen you create the project, a directory will be created, a name will auto populate (e.g., ‘fods24-liaison’). If you change the name, name it something that you will know as your team project. In order to keep the class organized, I might suggest you create the project in your FODS course directory. You should already have a R project for you homework called something like homework.Rproj in that course directory. WARNING: Do not create the project inside of an existing project’s directory.\n\nNote: I recommend that you also select “Open in new session” in order to compartmentalize projects. When you work on the team project, open the project. When you work on your homework or other class exercises, open your homework project.\n\nClick “Create Project” to create the new project directory, which will create:\n\na project directory on your computer\na project file with file extension .Rproj\na Git repository or link to the remote GitHub repository for the project (also an RStudio Project)\n\n\nIf the repository already exists (and it does in this instance) you should see RStudio flash a connection to GitHub and likely pull the repo contents down to your newly-created project directory. You will see the directory structure and corresponding files. Your code files should be saved to /r, the data you read or save to /data, your RMarkdown report files to /report, etc.\nThese directories are there for project management purposes. Also, to maintain a clean project, create sub-directories within those directories as needed; create new directories if and only if its contents differ qualitatively from what is in the existing directories. Because the project report will need to be reproduced, don’t complicate your code by creating RMarkdown files for code used to perform some task when only code is needed. In those cases, use .R code script files. Use .Rmd files only for a report containing text and minor code. You cannot easily source() .Rmd files and creating them will be a a hassle to deal with later. Project organization is an element of the project."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#summary",
    "href": "modules/02_using_git_and_github.html#summary",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Summary",
    "text": "Summary\nYou now understand how to create projects in R, how to connect projects to remote GitHub repositories, and how to use Git to track your work in your local repository and a remote one. These simple commands are basic but provide you some exposure to and confidence with using Git for version control."
  },
  {
    "objectID": "modules/02_using_git_and_github.html#other-resources",
    "href": "modules/02_using_git_and_github.html#other-resources",
    "title": "Project Management 02: R Projects, Git, and GitHub",
    "section": "Other Resources",
    "text": "Other Resources\n\nGit Client:\n\nGit clients work like the RStudio Gui option described above but likely much better. One client is GitKraken. * If you find the Terminal command line daunting or limiting, I might recommend a Git Client to use as I am not a big fan of the RStudio interface. * GitKraken is a good option and they have lots of tutorials on their website. GitKraken is seamless to set up. Install, connect your GitHub account, select your repo to add, and voilà. You can stage, commit, and push from there.\n\nhappygitwithr"
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html",
    "title": "Introduction to RStudio and R Markdown",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#readings-and-preparation",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#readings-and-preparation",
    "title": "Introduction to RStudio and R Markdown",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#supplementary-readings",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#supplementary-readings",
    "title": "Introduction to RStudio and R Markdown",
    "section": "Supplementary Readings",
    "text": "Supplementary Readings\n\nHuber: RMarkdown"
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#libraries",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#libraries",
    "title": "Introduction to RStudio and R Markdown",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management\n{rmarkdown} 2.25: for creating markdown files"
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-is-an-interpreted-language",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-is-an-interpreted-language",
    "title": "Introduction to RStudio and R Markdown",
    "section": "R is an Interpreted Language",
    "text": "R is an Interpreted Language\nR is an interpreted language. This means that code or programs you write may be executed by the R interpreter in real time. The code you write does not need to be compiled prior to being executed. Rather, the R interpreter translates your code in real time if it understands your code. If the R interpreter doesn’t understand your code, it will be unable to translate and you will receive some error."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#functions",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#functions",
    "title": "Introduction to RStudio and R Markdown",
    "section": "Functions",
    "text": "Functions\nThe code you write for the interpreter will involve referencing functions. You have used a function already when installing libraries (e.g., install.packages(). A function is nothing more than a set of statements organized together to perform some desired operation. In R, a function is an object. This means the R interpreter passes control to the function, along with any arguments that are necessary for the function to perform that operation and return the result of that operation."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#a-function-example",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#a-function-example",
    "title": "Introduction to RStudio and R Markdown",
    "section": "A Function Example",
    "text": "A Function Example\nFor example, reading a file into R involves using a function that performs that operation. For these functions to read a file containing data, you will need to specify the required and/or optional arguments for given parameters of the function. Functions and coding basics will be covered more extensively in a later topic. For now, one such function is read.table() with is used to read tabular data files. Another function is read.csv(), which is a special case of the former function. For this function to read a file, you would need to specify the file argument (and file path if the file is not in your working directory) argument at very least so that R knows what file to read. Another function you may use is data.frame() which is used to create data frames. Using R depends on using functions that are designed to handle various tasks. Unlike some langauges, we will not have to create many of our own functions but instead will leverage the work of R developers."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#internal-help",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#internal-help",
    "title": "Introduction to RStudio and R Markdown",
    "section": "Internal Help",
    "text": "Internal Help\nYou will certainly run into problems coding. When you don’t speak the language perfectly, R will let you know there are errors. So, how do you find help in R?\nTo ask R about what a function does, you can use ? paired with the function. In the Help window, you will see information about the package the function is from, how it is used, how to use it by specifying arguments (more on this later), and usually some examples of how it is used.\n?install.packages\n?install.packages\nAlternatively, you can use the help() function:\n\nhelp(\"install.packages\")\nhelp(\"install.packages\", package = \"utils\")\n\nThese methods are all equivalent ways of getting help:\nhelp(\"summarize\")\n?summarize\n?summarize::summarize\nYou can also simply type a query into the search bar in the RStudio Help menu tab (likely to the right)."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#external-help",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#external-help",
    "title": "Introduction to RStudio and R Markdown",
    "section": "External Help",
    "text": "External Help\nSometimes you need to find help outside of the R environment. In this case, just use Google. Type in your query by including the letter R to narrow the search results and you will see a lot that pops up. https://stackoverflow.com will likely be returned in your search results with questions that people have posted to the website for help from others. This is a community of coders helping coders. You can create an account if you wish, but reading questions and answers to those questions is free. Perhaps in years from now, you can answer questions for others.\nFor example, if you know you are using the {dplyr} library and you are using a function called starts_with(), you can search Google for “dplyr starts_with r” and this is what you will see"
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-code-execution",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-code-execution",
    "title": "Introduction to RStudio and R Markdown",
    "section": "R Markdown: Code Execution",
    "text": "R Markdown: Code Execution\nThis exercise is created with R Markdown code. R Markdown is a version of Markdown, which is a markup language for creating formatted text output using a plain-text. You are likely familiar with the most famous markup language, HTML (Hypertext Markup Language), which makes websites readable for us all.\nWithin this R Markdown file, the code is written between particular tick marks ``` and curly braces and {r}. These special character combinations simply allow RStudio to know what is R code (e.g., the lowercase r) and what is written text.\nIn RStudio, you can modify the code block/chunk by clicking the gear to make changes. You can specify whether the code shows the output only, shows the code and the output, whether the code is executed but not shown, or whether the code is not run at all. You can also toggle one and off options to display warnings, message, and other details. You can also review other options if you wish. You’ll notice that warnings and messages will make your output ugly so hiding them is often ideal.\nThis exercise serves as a tutorial with the goal of familiarizing you with using R and R Markdown. The output will be a nice HTML file containing your results. Within the code blocks, to execute code you would put your cursor on the line and press the RUN button (see top right) or press CONTROL+ENTER for PC or COMMAND+ENTER for Mac."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-cheat-sheet",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-cheat-sheet",
    "title": "Introduction to RStudio and R Markdown",
    "section": "R Markdown: Cheat Sheet",
    "text": "R Markdown: Cheat Sheet\nThere are many ways to customize an R Markdown file. You will need to insert R code, write text descriptions, create plots and tables, etc. In some instances you would want to include your R code or hide it from the output in their certain ways for doing that in the R Markdown language. Some of these ways are created automatically for you in RStudio when you initiate new R Markdown file. others can be be found in this R Markdown cheat sheet. RStudio also has various cheat sheets which you can find here. You can also read more in Huber: CH 2\nOn the course site, there are additional cheat sheet files located on the Cheat sheet tab."
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-the-definitive-guide",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#r-markdown-the-definitive-guide",
    "title": "Introduction to RStudio and R Markdown",
    "section": "R Markdown: The Definitive Guide",
    "text": "R Markdown: The Definitive Guide\nXie, Allaire, and Grolemund have an advanced guide for all the things you can do with R Markdown. It’s called R Markdown: The Definitive Guide"
  },
  {
    "objectID": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#some-things-you-can-do-with-rmarkdown",
    "href": "modules/01_introduction_to_r_rstudio_and_rmarkdown.html#some-things-you-can-do-with-rmarkdown",
    "title": "Introduction to RStudio and R Markdown",
    "section": "Some things you can do with RMarkdown",
    "text": "Some things you can do with RMarkdown\nWrap text in * to make text italics\nItalicize this\nWrap text in ** to make text bold\nBold this\nEmbed R code inside text using r\nFor example, the average mpg for cars in the mtcars data set is 20.090625 thought that should be rounded 20.1 to be more clear.\nEmbed R code blocks using ```{r}\nAutomatically enumerate text sections flagged using #\nExample:\n# Main Section\n## 2nd Level\n### 3rd Level"
  },
  {
    "objectID": "index.html#psyc-166-foundations-of-data-science-human-cognition",
    "href": "index.html#psyc-166-foundations-of-data-science-human-cognition",
    "title": "**PSYC166**",
    "section": "PSYC 166: Foundations of Data Science (Human Cognition)",
    "text": "PSYC 166: Foundations of Data Science (Human Cognition)\nThis is the course website for PSYC 166: Foundations of Data Science (Human Cognition), taught by Prof. Gabriel I. Cook; 1 credit\nDescription\nThis course introduces students to R, a programming language for statistical computing and graphics. Students will learn how to clean, manipulate, transform, join, and tidy data sets to prepare for statistical modeling. Supervised (e.g., regression) and unsupervised (e.g., clustering) approaches will be applied to understand simple and complex relationships between cognitive and non-cognitive variables (e.g., biology, aging, education, socioeconomic, health, etc.). Students will apply their skills to wrangle, explore, and model relevant data sets for a hands-on project for local scholars, offices, organizations, or industry participants. Data sets and relevant readings will change depending on semester."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Nothing to see here"
  },
  {
    "objectID": "cheatsheets_and_tips/symbols.html",
    "href": "cheatsheets_and_tips/symbols.html",
    "title": "Symbols",
    "section": "",
    "text": "Symbol\nTerm\n\n\n\n\n&lt;-\nassignment operator\n\n\n()\n(round) brackets / parentheses\n\n\n[]\nsquare brackets\n\n\n{}\ncurly brackets\n\n\n&lt;&gt;\nchevrons/angled brackets\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n#\nhash/pound\n\n\n/\nforward slash\n\n\n\\\nbackslash\n\n\n-\ndash/hyphen/minus\n\n\n_\nunderscore\n\n\n*\nasterisk/star\n\n\n^\ncaret/power symbol\n\n\n~\ntilde/twiddle\n\n\n=\nequal sign\n\n\n==\ndouble equal sign (logical equivalence)\n\n\n.\nfull stop/period/point\n\n\n|&gt;\npipe (see also %&gt;% for {magrittr})\n\n\n&\nampersand/and (“and” operator)\n\n\n|\nvertical bar/pipe (“or” operator)\n\n\n!\nexclamation mark/bang (“not” operator)\n\n\n?\nquestion mark\n\n\n’\nsingle quote/apostrophe"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html",
    "href": "modules/01_installing_r_and_rstudio.html",
    "title": "Installing R & RStudio",
    "section": "",
    "text": "For this course, we will use the R programming language and the RStudio IDE for manipulating data and creating data visualizations."
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#tasks",
    "href": "modules/01_installing_r_and_rstudio.html#tasks",
    "title": "Installing R & RStudio",
    "section": "Tasks",
    "text": "Tasks\nThe first step is to install these pieces of software so that you can use them.\n\nDownload and Install R\nDownload and Install RStudio\nConfigure RStudio"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#readings",
    "href": "modules/01_installing_r_and_rstudio.html#readings",
    "title": "Installing R & RStudio",
    "section": "Readings",
    "text": "Readings\n\nIntro to R\nWorking with RMarkdown"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#install-r-first-and-then-install-rstudio",
    "href": "modules/01_installing_r_and_rstudio.html#install-r-first-and-then-install-rstudio",
    "title": "Installing R & RStudio",
    "section": "Install R first and then install RStudio",
    "text": "Install R first and then install RStudio\nInstalling should be easy and you can accept all of the defaults although the desktop icons are not needed, especially for R because you will never need it; RStudio will find R for you. You can follow these videos for simple installing.\nPC: How to Install R and R Studio on Windows 10/11\nMac: Installing R and RStudio on a Mac\nNote: If you leave the desktop icon for R, you can remove that later. You will never need it because RStudio will find R for you."
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#additional-step-for-mac-users",
    "href": "modules/01_installing_r_and_rstudio.html#additional-step-for-mac-users",
    "title": "Installing R & RStudio",
    "section": "Additional Step for Mac Users:",
    "text": "Additional Step for Mac Users:\nDownload and Install XQuartz\nSome functions in R require an “X11 Server” and/or libraries associated with an X11 server. Apple does not provide this software with OS X anymore so unfortunately you have to do it on your own via a third-party application called XQuartz for OS X 10.9 or later.\nUse the url below to download the XQuartz file and save it to your computer. Follow the same install instructions as above for installing the XQuartz file.\nFor macOS 10.9 or later, download this XQuartz file and save it to your computer and install: https://github.com/XQuartz/XQuartz/releases/download/XQuartz-2.8.5/XQuartz-2.8.5.pkg"
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html",
    "href": "modules/02_installing_and_setting_up_git_and_github.html",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#overview",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#overview",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Overview",
    "text": "Overview\nWe will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\nTo Do: Steps of the Task\n\nCreate a GitHub account\nCreate GitHub repository: “fods-exercises”\nInstall Git on your computer (if not already installed)\nConfigure Git for R, within R/RStudio (a familiar context)\n\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using your PAT)"
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#libraries-used",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#libraries-used",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Libraries Used",
    "text": "Libraries Used\n\n{usethis}: 2.2.2: for project workflow automation\n{gitcreds}: 0.1.2: for querying git credentials"
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#git-why-go-through-the-trouble",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#git-why-go-through-the-trouble",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Git: Why Go Through the Trouble?",
    "text": "Git: Why Go Through the Trouble?\nProjects are rarely done without collaborators. Teams collaborate, leveraging team members’ work and accomplishments. Using R in conjunction with the a distributed version control system, like Git, will facilitate that collaboration process. Writing flexible R code that does not hard-code objects will allow your research project to be reproducible, for example, when variables and data change (e.g., new data added, a new year added, etc.). Git long with GitHub will allow you to track your edits (the version control) and share your code with your collaborators or interested scholars.\nSome benefits of using version control:\n\nFacilitates project sharing (once it’s setup, you’ll get there)\nFacilitates collaboration. Others can also report errors or suggest features to your project.\nMakes reverting back to previous states easy. You can easily revert back to a previous version of your code in the event you discover errors or you delete critical details accidentally.\nServes as a memory for edits when memory fails. All changes across different versions of your code or written content is available.\n\nRStudio integrates support for Git but this interface is a little clunky. You can use it but RStudio also allows for communication via the command line Terminal, which will be the preferred method shared here."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#creating-a-github-account",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#creating-a-github-account",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Creating a GitHub Account",
    "text": "Creating a GitHub Account\n\nGo to GitHub and create a free GitHub account. Make note of your username and your associated e-mail as you will need those for configuring Git with R.\n\nConsider this brief 15-minute TryGit Tutorial.\n\nStay logged in so that you can complete a later step.\nSend your PM your GitHub username. Your PM will send those to me and I will add you to a private repo. Once you are added to the repo, you can do the next step."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#creating-a-repository-on-github",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#creating-a-repository-on-github",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Creating a Repository on GitHub",
    "text": "Creating a Repository on GitHub\nYou will need to create a repository by following the option to do so using the GitHub UI. Use that link if necessary but the images below should suffice.\n\nOnce logged into your GitHub account, you will see a + along the top of your account earn your profile icon. Click the option to create a “New Repository”.\n\n\n\n\n\n\n\nName the repository fods-exercises and provide a description like “for fods class exercises and homework”.\n\n\n\n\n\n\n\nSelect the option to make the repository Private, check to add a README file, and add a .gitignore file by scrolling to find R:\n\n\n\n\n\n\n\nClick Create Repository"
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#installing-git",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#installing-git",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Installing Git",
    "text": "Installing Git\n\nDo I need to install Git?\n\nMac OS Users can check whether Git is already installed by typing git --version at the Mac Terminal. If a version number is returned, then Git is installed.\nWindows Users can press the Windows key (or click the Start button) and type Git in the search bar. If you see Git or Git Bash listed, then Git is installed. At the R console, you can also type system(\"git --version\") and if it is installed, the function should return the version number.\n\nDownload and Install Git (if necessary)\n\nMac OS Users may experience problems and see instructions at the Git download site to install Homebrew and then set the PATH variable. You don’t need to do that. Instead, I recommend downloading the binary version here and download it to install.\nWindows Users can download the latest version of Git here. Download and install Git, making a note of where on your computer you are install it as you may need to locate the path for RStudio, especially if you use a portable version of Git."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Checking Git Setup in RStudio",
    "text": "Checking Git Setup in RStudio\nYou will need to tell RStudio where to find the Git program as this may not be recognize automatically.\n\nFind the path to the Git program executable that was installed in an earlier step.\n\nIn the Terminal within RStudio (not the R console), type: where git on Windows and which git on Mac/Linux to find the path to the program. If there are more than one paths listed, just make note of one of them.\nIf for some reason you don’t see a path listed using that approach, type: Sys.which(\"git\") in your R console. The path here will likely be truncated so you will have to try to fill in the gaps when performing the step to set the path. See me for help.\n\nIn 1RStudio1, go to Tools &gt; Global Options and click on left side bar menu item Git/SVN.\nSelect the option at the top to Enable version control interface for RStudio projects if it is not selected.\nSet the path to the Git executable if it is not already there. Browse to the path to where Git.exe installed on your computer. Windows Users should make note that this path should be a path containing Git.exe and not a path containing git-bash.exe.\nClick Apply and then click OK."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#configuring-git-and-github",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#configuring-git-and-github",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Configuring Git and GitHub",
    "text": "Configuring Git and GitHub\nThere are two ways you can set up, either using R (console) or the command line (terminal). My recommendation is to use R because that is where you are likely most familiar, if even a small degree. We will use functions from the {usethis} library to help you. This library should be installed already as part of the class setup. If you get an error stating that the library is not installed when executing the steps below, just type install.packages(\"usethis\", dep = TRUE) at your R console.\nThe {usethis} library will make connecting your R project to your github account simple. You will use usethis::use_git_config() to configure your GitHub account with Git on your computer; if you did not create, see earlier step. In the below example, you will see that we need to provide two character strings as arguments to the function. The strings are used to set your user.name and your user.email (the e-mail attached to your GitHub account). Double check your GitHub e-mail and username.\nEdit the following code to include your username and email and then execute your modified R code:\nusethis::use_git_config(user.name = \"github_username\", \n                        user.email = \"github_email@gitrdone.com\"\n                        )\nDone!"
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Creating a Personal Access Token (PAT) for GitHub",
    "text": "Creating a Personal Access Token (PAT) for GitHub\nBefore completing this step, log into your GitHub account to facilitate the communication between RStudio and GitHub.\nYou will need a personal access token (PAT) for making remote changes to GitHub. A first step then is to create a PAT using usethis::create_github_token(). Second, you will register your PAT with the Git credential manager used by your computers operating system using gitcreds::gitcreds_set(). Keep in mind that if you use a different computer (e.g., you get a new one), you’ll need to register the PAT on that computer following the same steps described here.\nTo create your personal access token (PAT), type the following at your R console: \nusethis::create_github_token()\nAfter executing the code, you will be taken to your GitHub account (if you remained logged in). Go to the bottom of the page and click generate token. You should add a description for it so that you can understand its use case. For example, describe it based the computer you are using it on, “my computer make and model”. You may also describe it based on a project you are working on, “token-for-project-xyz”. If you do not add a description, you will likely become overwhelmed and/or confused when you have multiple tokens. When you need to regenerate or delete a token that expires, you will not be able to determine what they are for if you do not add a description.\nAfter creating your token, Copy it to your computer’s clipboard and save it someplace safe. Do not share your token with anyone because anyone who has it can access your public or private GitHub repositories.\nWarning: Your PAT will expire after some duration, usually 30 days unless you change it. For this project, I suggest you change the expiration to a date after the semester ends to ensure you don’t have to go through this process again during the semester. Getting a new PAT is not difficult, however. If your PAT will soon expire, GitHub will send you an e-mail alerting you also. You can regenerate a PAT from a link in your e-mail, so make sure your associated e-mail is one you check."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Setting your Git Credentials (using PAT)",
    "text": "Setting your Git Credentials (using PAT)\nNow that you have a PAT, we now need to set those credentials for RStudio to communicate with your GitHub account.\nExecute the following R code to set your credentials:\ngitcreds::gitcreds_set()\nYou may see a set of number options with corresponding descriptions. If you see them, enter the number corresponding to the option that makes the most sense for what you are trying to accomplish, for example, something like “set or replace your credentials”.\nWhen should then see a prompt like ? Enter new password or token. At this point, paste your PAT here and press return/enter. Then remove the PAT from your clipboard so that you don’t paste them someplace.\nYou can check that your credentials are stored by typing the following R code in the console:\ngh::gh_whoami()\n\nUpdating your Personal Access Token (PAT)\nAt some point, even if you set your PAT to expire after the semester, it will expire and you will need to update it. When it’s about to expire, or if it has expired, you can go to https://github.com/settings/tokens while logged into your GitHub account and regenerate the token and change the expiration date. Then, copy the PAT to the clipboard and set your credentials again using gitcreds::gitcreds_set()."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#summary",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#summary",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Summary",
    "text": "Summary\nYou have now created your GitHub account, created a repository, created a PAT, and installed and/or set up Git with RStudio. The next step will be to connect the remote GitHub repository with your R/RStudio setup."
  },
  {
    "objectID": "modules/02_installing_and_setting_up_git_and_github.html#optional-resources",
    "href": "modules/02_installing_and_setting_up_git_and_github.html#optional-resources",
    "title": "Project Management 01: Installing and Setting Up Git and GitHub for R",
    "section": "Optional Resources",
    "text": "Optional Resources\nIf you find yourself working on complicated projects, you might benefit from using a Git client or need to troubleshoot events. Although you won’t need to do this for this course, I’m providing some resources for your future. Feel free to come back to this course site to review content as I don’t intend to remove anything.\n\nGit Client: Git clients work like the RStudio Gui option described above but likely much better. If you find the Terminal command line daunting or limiting, I might recommend a Git Client to use as I am not a big fan of the RStudio interface.\n\nGitKraken is a good option and they have lots of tutorials on their website. GitKraken is seamless to set up. Install, connect your GitHub account, select your repo to add, and voilà. You can stage, commit, and push from there.\nGitHub Desktop is another common option. Install, connect your GitHub account and select your repo to add, and voilà. You can stage, commit, and push from there.\n\nTroubleshooting: happygitwithr is a resource for troubleshooting Git issues specifically with R."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html",
    "href": "modules/04_functions_and_scripts.html",
    "title": "Functions, Arguments, and R scripts",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#readings-and-preparation",
    "href": "modules/04_functions_and_scripts.html#readings-and-preparation",
    "title": "Functions, Arguments, and R scripts",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#supplementary-readings",
    "href": "modules/04_functions_and_scripts.html#supplementary-readings",
    "title": "Functions, Arguments, and R scripts",
    "section": "Supplementary Readings",
    "text": "Supplementary Readings\n\nR Workflow Basics\nHuber: Functions\n\n\nTo Do\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. Concepts will be applied in class in order to complete activities, however. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#libraries",
    "href": "modules/04_functions_and_scripts.html#libraries",
    "title": "Functions, Arguments, and R scripts",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#external-functions",
    "href": "modules/04_functions_and_scripts.html#external-functions",
    "title": "Functions, Arguments, and R scripts",
    "section": "External Functions",
    "text": "External Functions\nview_html(): for viewing data frames in html format\nYou can access remotely using this code, though you do not need to do so now.\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/fods24/main/r/functions/view_html.R\")"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#examples-of-objects",
    "href": "modules/04_functions_and_scripts.html#examples-of-objects",
    "title": "Functions, Arguments, and R scripts",
    "section": "Examples of objects",
    "text": "Examples of objects\nYou can also think of an object as a sort of container that holds something. Containers of different types hold different things and so is true in computer programming. A container for holding water may look different from a container for holding books. In computer speak, one type of container can hold numbers, another can hold characters, another can hold a data frame, etc. The container object is holding whatever you have assigned it to hold.\nWe will deal with different types of objects in data science. Without providing too complicated or technical of descriptions, some are described below.\n\nnumeric objects: representing numeric information (e.g., one’s age)\ncharacter objects: representing character information (e.g., one’s name or race)\nvector objects: representing more than one numeric object (e.g., ages of participants)\ndata frame objects: containing vectors of data (e.g., column variables and row instances of data)\nfunction objects: that accept one object and return an other object (e.g., the mean of numeric vector)\n\nThere are other type of objects that you will learn about and encounter but for now, those are the most relevant."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#a-character-example",
    "href": "modules/04_functions_and_scripts.html#a-character-example",
    "title": "Functions, Arguments, and R scripts",
    "section": "A character example",
    "text": "A character example\nLet’s start with an example of an object called name, which we would like to assign a set of characters, like Jim Bob.\nIn order to create such an object, we would need to place the characters within quotation marks (e.g., single or double, does not matter). The quotes let R know the contents of name are characters (aka strings).\n\"Jim Bob\"\nWhen dealing with data, you will encounter many character objects as they often represent factor variables (e.g., race, ethnicity, favorite game, etc.) but you will also see lots of objects that are numeric in some form (e.g., age, rating, cognitive performance, etc.)."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#assignment-provides-meaning-or-definition",
    "href": "modules/04_functions_and_scripts.html#assignment-provides-meaning-or-definition",
    "title": "Functions, Arguments, and R scripts",
    "section": "Assignment provides meaning or definition",
    "text": "Assignment provides meaning or definition\nAssignment is akin to creating a new word and assigning a meaning to it. You could also think of an assignment statement as a way to tell R to “create this thing and set it equal to something” so that the computer understand what association represents."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#a-character-object-a-silly-example",
    "href": "modules/04_functions_and_scripts.html#a-character-object-a-silly-example",
    "title": "Functions, Arguments, and R scripts",
    "section": "A character object: A silly example",
    "text": "A character object: A silly example\nIf objects are like containers holding things, we can use name of the object (e.g., container) and then assign \"things\" to it using &lt;-. In order to create a character object, we would need to place the characters within quotation marks (e.g., single or double, does not matter). The quotes let R know the contents of container are characters (aka strings).\n\"things\"\nWhen dealing with data, you will encounter many character objects as they often represent factor variables (e.g., race, ethnicity, favorite game, etc.) but you will also see lots of objects that are numeric in some form (e.g., age, rating, cognitive performance, etc.).\nSilly Example:\n\n\"something\" assigned to container\ncontainer &lt;- \"something\"\n\n\ncontainer &lt;- \"things\"\n\nAnd to see its contents, use print() to return the objects content:\n\nprint(container)\n\n[1] \"things\"\n\n\nOr just type the name of the object and you will see the returned object is \"things\".\n\ncontainer\n\n[1] \"things\"\n\n\nFor another example, we could also create an object called name, which we could assign a set of characters, like Jim Bob, making the object a character object.\n\nname &lt;- \"Jim Bob\"\n\nTo see what is returned:\n\nname\n\n[1] \"Jim Bob\"\n\n\nWhether you name is or is not Jim Bob, you can see that name contains the characters that represent the name of someone named “Jim Bob”. Although we assigned \"Jim Bob\" to name, we could have assigned it a given name. The assignment process simply stores the assigned information as an object using of whatever name you decided to call it (e.g., name, Name, NAME, xyz, etc.). We will discuss more on these letter casing differences later.\nYou could also assign the character to the object this way.\n\n\"things\" -&gt; container\n\nHowever, we won’t use much of this approach for different reasons. One reason is that doing so does not follow the R Style Guide. The style guide defines a set of guidelines for coding in R. Rather than memorize all of the styling, pay careful attention to the way code appears in the examples provided and try your best to model your code after the examples. For example, don’t do something this container&lt;-\"things\" just so you save space as doing so makes the code more difficult for you and others to read and understand.\nOK, back to Jim Bob. Of course, there are different people other than Jim Bob who exist in the world but when coding, they do not exist unless you create them. So, let’s create an object that holds the name of \"Jim Bob\".\nname &lt;- \"Jim Bob\"\n\nname &lt;- \"Jim Bob\"     # assign string to object named name\n\n\nName &lt;- \"Jim Bob\"     # we could have assigned it a different name, say Name\n\n\nNAME &lt;- \"Jim Bob\"     # or assigned it in all caps\n\nWhenever you reference the object name (or Name), R will return the contents of the object to you, which in this case will be a character or string object containing a single person’s name because that’s how we assigned it.\n\nname               # call object to return contents of \"name\"\n\n[1] \"Jim Bob\"\n\n\nAnd again, we can use print() to do the same thing:\n\nprint(name)\n\n[1] \"Jim Bob\"\n\n\n\nBeing mindful of case sensitivity\nA word of warning is needed here. Although name, Name, and NAME all contain the same four characters, n a m and e all arranged it he same order, the objects are all different. They just happen to hold the same content. The reason for there being three different object is because R is a case-sensitive language, which means that the letter case matters. In some programming languages, the case is ignored.\nTo illustrate, consider an example for which you assign different names to the object.\nname &lt;- \"Jim Bob\"     # create the object\n\n\nName &lt;- \"Bob\"         # then change it\n\n\nNAME &lt;- \"Jim\"         # then change it again\nIn those languages, if you asked what the name object contained, the program would return \"Jim\" because these characters were assigned last, even though they were assigned to an uppercase version, NAME. With R, you will need to be mindful of the letter case. This is by design, perhaps an advantage rather than a disadvantage."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#a-numeric-object",
    "href": "modules/04_functions_and_scripts.html#a-numeric-object",
    "title": "Functions, Arguments, and R scripts",
    "section": "A numeric object",
    "text": "A numeric object\nWhat about numeric information? We can create an object called year and assign the current year to it; let’s have this object contain the current year in numeric form, not as a string. Remember to use &lt;- for assignment.\n\nyear &lt;- 2024    # assign a number to year ; notice no quotes\n\nIn order to know whether this year object now contains the year, we can check by typing the name of the object or use print() to print the returned value.\n\nyear\n\n[1] 2024\n\nprint(year)\n\n[1] 2024"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#inspecting-vectors-with-some-functions",
    "href": "modules/04_functions_and_scripts.html#inspecting-vectors-with-some-functions",
    "title": "Functions, Arguments, and R scripts",
    "section": "Inspecting vectors with some functions",
    "text": "Inspecting vectors with some functions\nname and year are very simple objects. name is a simple character/string object we created, which contains only the name of 1 person and year only holds the current year. There is something else important about how R treats them that you cannot see on the surface. Both of these objects are also vectors. Vectors are one-dimensional arrays containing n pieces of information. You might also think of a vector so a variable (e.g., IQs of people). Both the name and year vectors contain only one piece of information, however. If you don’t believe me, we can use some functions that will answer this for us.\n\nis.vector() is a function that returns a logical (T or F) about whether the object is a vector\nlength() is a function that returns a non-negative numeric integer representing the number of elements contained\ntypeof() is a function that returns the object’s type\n\nLet’s try them by passing the object name inside the function.\n\nis.vector(name)   # is it a vector?\n\n[1] TRUE\n\n#?length\nlength(name)      # how many elements?\n\n[1] 1\n\ntypeof(name)      # what is it's type?\n\n[1] \"character\"\n\n\nIf name contained more than one object, it would still be a vector having a different length. But in order to create such vectors, each element of the vector needs to be separated by a comma and each elements needs to be wrapped by quotes.\nIf you do not separate strings by a comma…\n\nname &lt;- \"Jim Bob Kendra\"\n\n\nname                                # return object; also print(name)\n\n[1] \"Jim Bob Kendra\"\n\nis.character(name)                  # is it a character?\n\n[1] TRUE\n\nlength(name)                        # what is its length?\n\n[1] 1\n\n\nIf you do use quotes for each element and separate each by a comma, you need to use a function to combine them, which is c().\n\nname &lt;- c(\"Jim Bob\", \"Kendra\")  # two names, combine with c()\n\n\n\nis.character(name)        \n\n[1] TRUE\n\nlength(name)                   # vector with length 2\n\n[1] 2\n\n\nThe more you work with character vector, the more you way want to avoid some annoyances of creating them.\nThe {Hmisc} library has a function called Cs() that obviates the inclusion of the quotes.\n\nHmisc::Cs(Jim, Kendra, Bill, Sandy)\n\n[1] \"Jim\"    \"Kendra\" \"Bill\"   \"Sandy\" \n\n\nBeware of vectors containing elements with space like this:\nHmisc::Cs(Jim Bob, Kendra)\nR will throw an error to inform you that something is wrong. For example: Error: unexpected symbol in \"Hmisc::Cs(Jim Bob\"."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#elements-of-vectors",
    "href": "modules/04_functions_and_scripts.html#elements-of-vectors",
    "title": "Functions, Arguments, and R scripts",
    "section": "Elements of vectors",
    "text": "Elements of vectors\nAs a side note, the pieces/values of a vector are referred to as elements. You can reference elements by number representing their position in the vector.\n\nname[1]   # first element\n\n[1] \"Jim Bob\"\n\nname[2]   # second element\n\n[1] \"Kendra\"\n\nname[3]   # a third element? No. It only has length 2\n\n[1] NA\n\n\nObjects in R, however, can take on many forms other than strings or numbers just illustrated. Objects can be strings/characters, numeric values, character strings, functions, data frames, vectors, lists, matrices, plots, etc. If you use typeof() on a data frame object, the function will return \"list\" because a data frame is also a list. More on this later."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#creating-a-.r-script-file-to-source",
    "href": "modules/04_functions_and_scripts.html#creating-a-.r-script-file-to-source",
    "title": "Functions, Arguments, and R scripts",
    "section": "Creating a .R script file to source()",
    "text": "Creating a .R script file to source()\nThere are a few ways to create files for your R project. You can do so easily from RStudio or you can do so more quickly using Git.\n\nCreating a .R script using RStudio\nYou can easily create an .R script file from RStudio. You are most likely familiar with this file creation process.\nFirst, go to File &gt; New File &gt; R Script\nSecond, File &gt; Save As, browse to the projects /r directory, name it my_first_script.R and click save.\nIn it, type message(\"My first script file.\") and save it as my_first_script (the .R should be automatic) in your \"/r\" directory.\nYour file will be written to the r/ directory and will be opened in RStudio.\nBecause the .Rmd file you are working with is already saved in \"/r\" (if you saved it there correctly), you can source the file by name.\n\n\nCreating a .R script file using the Terminal\nFirst, go to your Terminal in RStudio. This is located by the Console tab and is the same place you type your Git commands.\nSecond, you can use the touch function to create the file. You will want to specify the directory to write the file and the name of the file to write.\nThird, to create a file named my_first_script.R, type:\ntouch r/my_first_script.R and your file will be written to the r/ directory.\nTo open the file in RStudio, the easiest way to go to the Files pane in RStudio, locate it and click it so that it appears as an open tab.\nIf you want to add it to Git, type:\ngit add r/my_first_script.R and it will be staged.\nIf you misspelled the file name and want to delete it, or just need to delete it for some reason, you can type:\nrm r/my_first_script.R\nTo delete it and remove from Git, type:\ngit rm r/my_first_script.R"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#adding-code-to-the-script-file",
    "href": "modules/04_functions_and_scripts.html#adding-code-to-the-script-file",
    "title": "Functions, Arguments, and R scripts",
    "section": "Adding code to the script file",
    "text": "Adding code to the script file\nWe will now add code to the file. To demonstrate how this works, let’s just add a message to the file using message() which is a simple stand-in for a bunch of lines of code.\nIn the script file, type:\nmessage(\"My first script file.\")\nNote: Make sure you save the file."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#sourcing-the-script-file",
    "href": "modules/04_functions_and_scripts.html#sourcing-the-script-file",
    "title": "Functions, Arguments, and R scripts",
    "section": "Sourcing the script file`",
    "text": "Sourcing the script file`\nNow, to run the code saved in my_first_script.R, we will source() the file by specifying the path to it using {here}.\n\nsource(file = here::here(\"r\", \"my_first_script.R\"))\n\nMy first script file.\n\n\nBut you can omit using file because you are only passing one argument and it’s file.\n\nsource(here::here(\"r\", \"my_first_script.R\"))\n\nMy first script file."
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#sourcing-multiple-script-files",
    "href": "modules/04_functions_and_scripts.html#sourcing-multiple-script-files",
    "title": "Functions, Arguments, and R scripts",
    "section": "Sourcing multiple script files",
    "text": "Sourcing multiple script files\nWhen you have multiple files to source(), you can source them individually, making sure that they are ordered in the order you wish to run them. They will execute line by line.\nsource(here::here(\"r\", \"read_data.R\"))\nsource(here::here(\"r\", \"clean_data.R\"))\nsource(here::here(\"r\", \"create_plots.R\"))\nYou can also create a new .R script file that contains the above three lines of source code and add them to another file, named appropriately like read_clean_plot_data.R. and then source that file like this:\nsource(here::here(\"r\", \"read_clean_plot_data.R\"))"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#sourcing-all-files-in-a-directory",
    "href": "modules/04_functions_and_scripts.html#sourcing-all-files-in-a-directory",
    "title": "Functions, Arguments, and R scripts",
    "section": "Sourcing all files in a directory",
    "text": "Sourcing all files in a directory\nIf all those files to source are in a directory, you can use a special source function from {R.utils} R.utils::sourceDirectory(). For example, if you have all of personal or project-related functions nicely organized in a directory like r/funcions/, you can easily source it like this. The benefit here is that you don’t have to specify all of the files individually.\n\nR.utils::sourceDirectory(here::here(\"r\", \"functions\"))"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#an-alternative-to-view",
    "href": "modules/04_functions_and_scripts.html#an-alternative-to-view",
    "title": "Functions, Arguments, and R scripts",
    "section": "An alternative to View()",
    "text": "An alternative to View()\nAs an alternative to View(), a function that I wrote using the {DT} library to display the data in an HTML table that allows you to sort the data.\n\nview_html() (lowercase v): returns an filterable html table of the data frame; my alternative to View()\n\nIf you want to use this function, you can source() the raw code from the course site using the code below. Because I use this function often, you might wish to add it to your /r/functions/ directory and simply source all of the files in that directory as describe above.\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/fods24/main/r/functions/view_html.R\")"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#getting-the-head-of-a-data-frame",
    "href": "modules/04_functions_and_scripts.html#getting-the-head-of-a-data-frame",
    "title": "Functions, Arguments, and R scripts",
    "section": "Getting the head() of a data frame`",
    "text": "Getting the head() of a data frame`\nIf you query the function in the console by typing using ?head or help(head), you will see in there are two main parameters.\nParameters/Arguments:\n\nx: a vector or data frame object\nn: a value of the indices to be selected (e.g., elements of vector, rows in data frame)\n\nhead() needs an object x in order to do anything. We can pass the USArrests data frame as the argument and if all goes well, we will only see the top or head of this data frame.\n\nhead(x = USArrests)   # 6 rows by default\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\nAnd if you pass arguments to parameters in function according to their order (e.g., position), you do not need to reference the parameters by name when passing arguments. For example, we can remove the reference to x.\n\nhead(USArrests)   # 6 rows by default\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\nThe second parameter for head() is n, the number of rows for the function to return. The default number was 6. We can change the default operation by passing 3 as the argument to it.\nBut as long as we pass the arguments to x and then to n, then we do not need to reference either by name. Instead, we can just pass the arguments.\nBut if you change order, you will need to reference the arguments. You cannot call head(3, USArrests) for example but you can call head(n = 3, x = USArrests). You normally would not wish to change the order of arguments for head() but for more complicated functions, you might wish to for different reasons.\nUsing the viewing options:\n\n#View(USArrests)                            # the standard viewer\n\n#view_html(USArrests, rows = T, show = 5)   # but same as \n\n#view_html(head(USArrests), rows = T)"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#checking-whether-an-object-is-a-data-frame-using-is.data.frame",
    "href": "modules/04_functions_and_scripts.html#checking-whether-an-object-is-a-data-frame-using-is.data.frame",
    "title": "Functions, Arguments, and R scripts",
    "section": "Checking whether an object is a data frame using is.data.frame()",
    "text": "Checking whether an object is a data frame using is.data.frame()\nYou can also check whether the USArrests data file is a data frame using is.data.frame(), which will return TRUE indicating that it is indeed a data frame.\n\nis.data.frame() returns logical ( T or F) about data frame as two-dimensional array"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#checking-the-structure-of-a-data-frame-using-str",
    "href": "modules/04_functions_and_scripts.html#checking-the-structure-of-a-data-frame-using-str",
    "title": "Functions, Arguments, and R scripts",
    "section": "Checking the structure of a data frame using str()",
    "text": "Checking the structure of a data frame using str()\nThat seems tedious, however. You can learn a lot more about the data frame by examining its structure using str(). The USArrests object is a data frame, contains 50 observations (e.g., rows) and 4 variables (columns). All column variables appear to contains numbers, with two of them being numeric, abbreviated num and two are integers, abbreviated int.\n\nstr() returns the structure of a data frame"
  },
  {
    "objectID": "modules/04_functions_and_scripts.html#using-other-functions",
    "href": "modules/04_functions_and_scripts.html#using-other-functions",
    "title": "Functions, Arguments, and R scripts",
    "section": "Using other functions`",
    "text": "Using other functions`\nAnd you can check the names of the columns using names(). What is actually returned to you is a character vector, or a vector whose elements are of character type. You can test whether the column names is a vector by wrapping names() with the is.vector() function. Similarly, wrapping names() in typeof() will tell you the type is character.\n\nnames(): returns names of data frame\nis.vector(): returns logical if/if not a vector (see other is. functions)\ntypeof(): returns the type of the object\n\n\nnames(USArrests)           # get the names of the columns?\n\n[1] \"Murder\"   \"Assault\"  \"UrbanPop\" \"Rape\"    \n\nis.vector(names(USArrests))\n\n[1] TRUE\n\ntypeof(names(USArrests))   # get the type of structure are the names\n\n[1] \"character\""
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html",
    "href": "modules/06_importing_and_exporting_data.html",
    "title": "Importing and Exporting Data Frames",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#readings-and-preparation",
    "href": "modules/06_importing_and_exporting_data.html#readings-and-preparation",
    "title": "Importing and Exporting Data Frames",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nThis module contains information for importing and reading data that you might experience either in this class or beyond. Several concepts are covered along with examples in the event that you encounter some issue in the future, you know you can return to this module to help you. However, you many not deal with they special instances. For example, we will work primarily with .csv and .Rds files which will be provided to you. That being said, I obtained the data as a .sas7bdat SAS data file which I converted to .Rds for you. You may similarly find yourself at some point in the future needing libraries to open special files types, so I present some details here simply to make you aware that reading them can be easy if you are aware of the correct tools. In addition. We also will not typically access data from a URL or webpage for this course but I show you that’s possible too.\nWhat’s most relevant for reading:\n\nWhat tidy data are\nWide versus long data formats/structures\nUnderstanding what filename extensions are\nUnderstanding what a comma-separated values file is\nManaging file paths with {here} with R projects (we will use the each week)\nWriting compressed .Rds files with saveRDS()\nReading compressed .Rds files with readRDS()\nWriting .csv files with readr::write_csv()\nImporting files with RStudio for the less confident\n\nWhat you can overlook unless you are curious\nUnless you are curious, you don’t need to: understand how to read or write .tsv SPSS, Stata Files, or Excel files using special libraries like {haven}, {foreign}, {readxl}, {openxlsx}, {rio}, or others. You don’t need to know how to handle messages with importing files or how to quiet messages unless you start seeing messages you don’t want. You won’t really need to know how to change column variable types because we will generally save data as .Rds files in order to prevent such problems. You also won’t need to know the differences between read.table(), read.csv(), and readr::read_csv() though you might at some point experience these differences when collaborating with others to handle data using different libraries that we will use.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises. Specifically, we will use readr::write_csv(), readr::read_csv(), saveRDS(), and readRDS()."
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#supplementary-readings-if-you-want-to-dig-deeper",
    "href": "modules/06_importing_and_exporting_data.html#supplementary-readings-if-you-want-to-dig-deeper",
    "title": "Importing and Exporting Data Frames",
    "section": "Supplementary Readings (if you want to dig deeper)",
    "text": "Supplementary Readings (if you want to dig deeper)\n\nData Import\nHuber: Data Import I and II"
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#tidy-files",
    "href": "modules/06_importing_and_exporting_data.html#tidy-files",
    "title": "Importing and Exporting Data Frames",
    "section": "Tidy Files",
    "text": "Tidy Files\nThere are many sources of data files and data files take many forms and are structured in different ways. They can be tidy or they can be messy. In general, tidiness refers to a data structure. Much of data science involves wrangling data sets to make them tidy. Whether a data set is tidy or messy depends on how the rows and columns are matched up with cases/observations.\nSo what’s is considered tidy?\n\nEach variable is represented as a column\nEach case/observation is represented as a row\nEach value is represented in a row/column cell\n\nIn other words, data that are tidy are generally structured as two-dimensional flat files of data neatly arranged in rows and columns specifically such that columns are variables and rows contain observations. Cell contain the value of an observation for a variable. Whether data are tidy or messy, data files created by software will be saved to disk and will be recognized by a filename extension. Before addressing more about file names and extensions, let’s first get the look and feel of different structures or arrangements of data.\nFor example:\nname age iq\nBill 28  130\nJane 35  145\nSal  55  125\nAlthough we work with importing data files rather than create them, if you wanted to create the data frame for R we can to so easily with different function. We will discuss standard data frames and data frames that are tibbles later, we can create data frames in base R using the data.frame() function. We would name a variable and then assign the observations/cases as elements of a vector using the combine function, c().\n\ndata.frame(\n  name = c(\"Bill\", \"Jane\", \"Sal\"),\n  age  = c(28, 35, 55), \n  iq   = c(130, 145, 125)\n)\n\n  name age  iq\n1 Bill  28 130\n2 Jane  35 145\n3  Sal  55 125\n\n\nSimilarly, using the tribble() function from the {tibble} library, we can also create a special type of data frame known as a tibble. For tibbles, the arrangement of data is similar to how the data would appear in a file – variables as columns and cases as rows.\n\ntibble::tribble(\n  ~name, ~age, ~iq,\n  \"Bill\", 28, 130,\n  \"Jane\", 35, 145,\n  \"Sal\", 55, 125\n  )\n\n# A tibble: 3 × 3\n  name    age    iq\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Bill     28   130\n2 Jane     35   145\n3 Sal      55   125\n\n\nNotice that tibbles don’t take vector objects created using c() with which you are familiar by now. Whether created as a standard data frame or a tibble, the structure is the same but this example represents only one structure. Data sets do not always take this structure, so let’s consider formats that are considered wide-format or long-format so that you understand the difference. Later on, we will explore converted data in one format to the other format.\n\nWide-Format Data Files\nThe organization of those variables and observations can change based on the person or system creating them or based on an analytics software’s expectations for working with those values. In many instances, columns of data sets represent variables and the rows represent the cases/observations. SPSS for example, works with data sets organized in wide-format.\nLet’s work through an example of a wide-format data file. Weight could be an interesting property to measure for tracking a weight-loss program or a body-building program. Weight could be measured weekly or monthly (repeated measures). Let’s say you have measured weight for three or more individuals on three different occasions. In wide-format, the cases correspond to rows and the variables as columns but each measurement is treated as a separate variable combination of weight and time.\n\ntibble::tribble(\n  ~name, ~weight_time1, ~weight_time2, ~weight_time3,\n  \"Bill\", 175, 172, 160,\n  \"Jane\", 135, 130, 131,\n  \"Sal\", 160, 158, 150\n  )\n\n# A tibble: 3 × 4\n  name  weight_time1 weight_time2 weight_time3\n  &lt;chr&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Bill           175          172          160\n2 Jane           135          130          131\n3 Sal            160          158          150\n\n\nWe see here that all of the variables are not represented by columns. The individuals name is a variable but weight and time are somewhat confounded. The time variable should be a column and the cell for a row/column should represent the weight. What if the same data had a different structure?\n\n\nLong-Format Data Files\nR and R libraries generally prefer with data sets organized in long-format. In long-format, the cases still correspond to rows and the variables as columns. The difference is that the repeated measurements of weight are organize as separate rows. Because weight is measure at different time, each measurement of weight is associated explicitly with a new column variable time.\n\ntibble::tribble(\n  ~name, ~time, ~weight, \n  \"Bill\", 1, 175,\n  \"Bill\", 2, 172, \n  \"Bill\", 3, 160,\n  \"Jane\", 1, 135, \n  \"Jane\", 2, 130, \n  \"Jane\", 3, 131,\n  \"Sal\", 1, 160, \n  \"Sal\", 2, 158, \n  \"Sal\", 3, 150\n  ) \n\n# A tibble: 9 × 3\n  name   time weight\n  &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Bill      1    175\n2 Bill      2    172\n3 Bill      3    160\n4 Jane      1    135\n5 Jane      2    130\n6 Jane      3    131\n7 Sal       1    160\n8 Sal       2    158\n9 Sal       3    150\n\n\nNote that this format is tidy. Each row represents an observation. For example, the first row corresponds to “Bill” who weighed 175 lbs at time 1. Similarly, each row contains observations for each variable and each cell contains a row/column value.\n\n\nRearranging Data Files\nDepending on the source of data or the requirement by a client or piece of software, you may sometimes need to rearrange data. For example, you may need to change a wide-formatted file to a long-formatted file or vice versa. For such instances, we will use pivoting functions from {tidyr}."
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#filename-extensions-general",
    "href": "modules/06_importing_and_exporting_data.html#filename-extensions-general",
    "title": "Importing and Exporting Data Frames",
    "section": "Filename Extensions: General",
    "text": "Filename Extensions: General\nA filename extension is the suffix of the filename following the dot/period. For example, .txt is used for text files, .csv for comma-separated values files, .jpg or .png for image files, and .xls or xlsx for MS Excel files among many file types. The extension is used to help understand how the file should be opened (or read) using a program that can understand that file format. To some extent, extensions are arbitrary; you can change the extension of myfile.xlsx to myfile.txt. Changing the extension does not, however, change the format. Thus, extensions are not arbitrary to the extent that you will need a program that reads the file appropriately. The program that tries to read your newly named myfile.txt will assume the file is in a text format because of its new extension and will fail to open the file correctly. Using MS Excel to read the file will open it just fine because Excel understand the saved format.\nSo why does any of this matter? You may have never thought too much about filenames and extensions before. In fact, your computer may not even be set up to display extensions for common file types. Because data scientists deal with files of all different types, knowing these extensions is necessary for reading and writing data files appropriately. If your computer does not show file extensions, I recommend you change your computer settings so that you can see them by following these links for Mac or Windows PC computers.\n\nFilename Extensions for Data Files\nData files are often associated with .csv, .tsv, and .xlsx file extensions. If you have worked with various statistics software, you may be familiar with other formats like .sav for SPSS data files, .dta for Stata data files, or .sas7bdat for SAS data files. Knowing the file format will prove exceptionally helpful when trying to read data files. In fact, libraries like {haven} and more extensively {foreign} are dedicated specifically to reading data files into R that have been saved by data analytics software packages such as SPSS, Stata, SAS, Minitab, etc.\n\nComma-Separated Files, .csv\nEven for tidy data arranged neatly in rows and columns, one must know the structure of the data file in order to read the file and make sense of its contents.\nExample 1:\nAssume the following data were saved as a file with a .txt extension. The extension is not very diagnostic of the data structure.\n134 66 2000\n128 60 1985\nDo the two rows of data in the above example represent a single column corresponding to social security numbers or do they represent three columns corresponding to variables like weight, height, and year of birth? Both could be true.\nExample 2a, as comma-separated:\nWhen column values of data are separated by a comma ',', the file type is referred to as comma-separated values:\n134, 66, 2000\n128, 60, 1985\nAssuming the commas separate the variables, R would read the file and assign variable names to the columns. In this example, R tells you that there are 3 variables, which it automatically names, V1, V2, and V3.\n\n\n   V1 V2   V3\n1 134 66 2000\n2 128 60 1985\n\n\nExample 2b, as comma-separated:\n134 66 2000,\n128 60 1985,\nReading the data and telling R that commas separate the variables, R would read the file as:\n\n\n           V1 V2\n1 134 66 2000 NA\n2 128 60 1985 NA\n\n\nR is telling you that there are 2 variables, which it automatically names, V1 and V2. The first variable contains the numbers and the second variable contains NA values (missing values). Two variables are specified because the comma splits the row into two pieces representing two variable columns.\nJust because there are commas in a data file, this does not require that you read the file that way. By reading the same data but now telling R that spaces separate the variables rather than commas, R would read the same file as:\n\n\n   V1 V2    V3\n1 134 66 2000,\n2 128 60 1985,\n\n\nR now tells you that there are 3 variables but the last variable contains the comma. A comma is likely not relevant and would need to be removed as part of data cleaning.\nExample 3, comma-separated with variable headers:\nSome data files can include variable names (also separated by columns) at the top of the file. These are helpful with reading in the columns. The next example show what the file might look like.\nname, age, iq\nBill, 28, 130\nJane, 35, 145\nSal, 55, 125\nWhen R reads the file, useful variable names are displayed.\n\n\n  name age  iq\n1 Bill  28 130\n2 Jane  35 145\n3  Sal  55 125"
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#writing-.csv-files",
    "href": "modules/06_importing_and_exporting_data.html#writing-.csv-files",
    "title": "Importing and Exporting Data Frames",
    "section": "Writing .csv Files",
    "text": "Writing .csv Files\n\nWriting with write.table()\nTo understand what arguments you need to supply to the function parameters, check the help documentation, help(write.table). This step is relevant if you are trying to understand what a function is doing – don’t just assume you know how a function works.\nParameters/Arguments:\n\nx: we need an argument for the object to be written\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\nsep: we need a field separator string argument specifying how columns should be separated\n\nThe data frame is DAT3 and the file is the file name along with the file path. How to get the file path? Use {here}. To show that the file extension is not strictly important, we can name the file \"example3.txt\" even though the file format is comma-separated based on passing a comma for the separator parameter, sep = \",\".\n\nwrite.table(x = DAT3,                                  # data frame object\n            file = here::here(\"data\", \"example3.txt\"), # project path + data + filename\n            sep = \",\"                                  # delimiter\n)\n\nWarning: If you specify name only of the file (e.g., file = \"example3.txt\"), the data frame will be written to a default location because no file path was provided along with the file name. So where is that default location? Well it depends and it’s complicated depending on whether you are writing code inside files that are .R or .Rmd. By default, .Rmd files will assume the directory from which the .Rmd file is saved and opened. An .Rmd file, however, if not a data file; it’s an R Markdown file for the default directory will likely be someplace other than /data.\nIf you are organized, you (a) save your .R and .Rmd files in a code directory (e.g., /r) or a report directory (e.g., /reports), (b) save your data files in a /data directory, and (c) are using an RStudio Project. The TLDR is that the default is a problem. The solution is to specify the file path using file = the full file path, which is easy to do using here::here(), so just make this a habit now and save yourself from future headaches.\n\n\nWriting with write.csv()\nLet’s do the same using write.csv(). Again, check the help documentation, help(write.csv).\nParameters/Arguments:\n\nx: we need an argument for the data frame object to be written\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\nsep: the default is \",\", so we don’t need to supply it\n\nThe data frame is DAT and the file is file name along with the file path Let’s just change the filename extension to \".csv\" so that we don’t overwrite the previous example.\n\nwrite.csv(x = DAT3,\n          file = here::here(\"data\", \"example3.csv\")\n)\n\nNote: If you open this file with an editor on your computer, you will see a new column is added to it by default. This column has no name and each row of the file will contain a number reflecting the row number. Adding row names is the default before for the function. To omit these row numbers when writing your data, add row.names = FALSE. This is a recommendation and I believe good practice if using write.csv().\nExample:\nwrite.csv(x = DAT3,\n          file = here::here(\"data\", \"example3.csv\"),\n          row.names = FALSE\n)\n\n\nWriting with readr::write_csv()\nDespite it’s name, the {readr} library can save data frames too. Interestingly, at least at the time of this writing, {readr} allows you to write files in excel format even though you cannot open them.\nParameters/Arguments:\n\nx: we need an argument for the data frame object to be written\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\nsep: the default is \",\", so we don’t need to supply it\n\nLet’s now save DAT2a.\n\nreadr::write_csv(x = DAT2a,\n                 file = here::here(\"data\", \"example2a_readr.csv\")\n                 )\n\nNote: Unlike write.csv(), readr::write_csv() does not append the row number to a column."
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#writing-compressed-.rds-files",
    "href": "modules/06_importing_and_exporting_data.html#writing-compressed-.rds-files",
    "title": "Importing and Exporting Data Frames",
    "section": "Writing Compressed .Rds Files",
    "text": "Writing Compressed .Rds Files\nSometimes you are dealing with large data sets. Saving large files will take up a lot of disk space. Larger files typically take longer to read as well. A solution is to compress the files. The base R function saveRDS() will be the go-to here. By default, saveRDS() compresses the file. Compression will matter for larger data files.\nAlso, when you manipulate data frames, you may change variable types, create new variables of a certain type, etc. Writing you data out as a .csv file will not preserve these characteristics.\nBecause we have not yet addressed how to create or modify variable columns in data frames, we won’t actually change the data type of the data frame. However, if we modified a data frame and wanted to preserve the data types of the columns, saveRDS() would take care so this for us. When you have many variables to manage, you certainly don’t want to specify whether they are factors, ordered factors, numeric, etc. every time you read the file.\nSome key details of .Rds files:\n\ndata are compressed\nread/restore quickly\nspecific characteristics are store in the data (e.g., attributes, variable types, etc).\n\nGive these advantages, we will rely heavily on .rds files once wrangling and cleaning occurs.\nParameters/Arguments:\n\nobject: we need an argument for the data frame to write\nfile: we need an argument for the data frame to write\n\n\nsaveRDS(object = DAT3,\n        file = here::here(\"data\", \"example3.rds\")\n        )"
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#writing-.xlsx-files",
    "href": "modules/06_importing_and_exporting_data.html#writing-.xlsx-files",
    "title": "Importing and Exporting Data Frames",
    "section": "Writing .xlsx Files",
    "text": "Writing .xlsx Files\nWe will use {openxlsx} to write Excel files. - openxlsx::write.xlsx()\nParameters/Arguments:\n\nx: we need an argument for the data frame object to be written\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\n\n\nopenxlsx::write.xlsx(\n  x = DAT3,\n  file = here::here(\"data\", \"example3.xlsx\")\n  )\n\nThis is the simple usage of writing Excel files. You can do more with {openxlsx} like adding worksheets, writing data to certain rows, etc. but this is beyond the scope of these examples. You can find more here."
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#reading-.csv-files",
    "href": "modules/06_importing_and_exporting_data.html#reading-.csv-files",
    "title": "Importing and Exporting Data Frames",
    "section": "Reading .csv Files",
    "text": "Reading .csv Files\nReading .csv files can be accomplished in a variety of ways, most typically using base R functions or those from {readr}.\n\nBase R:\n\nread.table(file = \"my_filename.csv\", sep = \",\") is a flexible function requiring setting the separator character argument for sep\nread.csv(file = \"my_filename.csv\") is the same as above except that sep = \",\" is * {readr}:\nreadr::read_csv(file = \"my_filename.csv\")\n\n\nNOTE: Another term for the separator is delimiter, so you may see this used in documentation.\n\nReading with read.table()\nParameters/Arguments:\n\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\nsep: we need an argument for the character used to separate column variables (e.g., \" \", \",\", \"|\", \"\\t\", etc.)\n\nBecause the columns are separated by a comma, set sep = \",\":\n\nread.table(file = here::here(\"data\", \"example3.txt\"),\n           sep = \",\"\n           )\n\n  name age  iq\n1 Bill  28 130\n2 Jane  35 145\n3  Sal  55 125\n\n\n\n\nReading with read.csv()\nThis function is the same as read.table() except the separator has already been set to a comma.\nParameters/Arguments:\n\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\nsep: already predefined by default\n\n\nread.csv(file = here::here(\"data\", \"example3.txt\"))\n\n  name age  iq\n1 Bill  28 130\n2 Jane  35 145\n3  Sal  55 125\n\n\n\n\nReading with readr::read_csv()\nParameters/Arguments:\n\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\n\nBecause the columns are separated by a comma, set sep = \",\":\n\nreadr::read_csv(file = here::here(\"data\", \"example2a_readr.csv\"))\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): wt_lbs, ht_in, yob\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n  wt_lbs ht_in   yob\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    134    66  2000\n2    128    60  1985\n\n\n\nHandling Messages with Importing\nWhen reading with this function, there will be some messaging in the console. One is to examine the column specifications using spec() or specifically readr::spec(). We can .\nspec() has one parameter x, which stands for the data frame. Because the file read is a data frame, we can just wrap the function in spec().\n\nreadr::spec(readr::read_csv(file = here::here(\"data\", \"example2a_readr.csv\")))\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): wt_lbs, ht_in, yob\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\ncols(\n  wt_lbs = col_double(),\n  ht_in = col_double(),\n  yob = col_double()\n)\n\n\nAlternatively, if you read in the data frame and assigned it to an object name, you could call the object name itself as seen here.\n\nexample2a_readr &lt;- readr::read_csv(file = here::here(\"data\", \"example2a_readr.csv\"))\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): wt_lbs, ht_in, yob\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCall the data frame:\n\nexample2a_readr\n\n# A tibble: 2 × 3\n  wt_lbs ht_in   yob\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    134    66  2000\n2    128    60  1985\n\n\nExamine the column types of example2a_readr with spec():\n\nreadr::spec(example2a_readr)\n\ncols(\n  wt_lbs = col_double(),\n  ht_in = col_double(),\n  yob = col_double()\n)\n\n\nWe now see the column types are all numeric, doubles.\n\n\nChanging column variable types\nIf your column variables were not all numeric and you wanted to change them, you could specify the data types in the order the variables appear in the data set (e.g., from left to right). To do this, we need to pass an argument for col_types. Although all the columns are numbers, to illustrate, we will declare one a \"double\", one a \"factor\", and one a \"character\" that is not a factor.\ncol_types = list(\"double\", \"factor\", \"character\")\n\nexample2a_readr &lt;- readr::read_csv(file = here::here(\"data\", \"example2a_readr.csv\"),\n                                   col_types = list(\"double\", \"factor\", \"character\")\n                                   )\n\nCall the data frame:\n\nexample2a_readr\n\n# A tibble: 2 × 3\n  wt_lbs ht_in yob  \n   &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt;\n1    134 66    2000 \n2    128 60    1985 \n\n\nThe tibble now lists the three different data types below the variable names. Remember, you cannot perform math on factors and character variables. Just to solidify just how the variables changed when read in, we can examine each variable to see what the vectors look like.\nThe \"double\" variable reveals numeric values:\n\nexample2a_readr$wt_lbs\n\n[1] 134 128\n\n\nThe \"factor\" variable reveals levels:\n\nexample2a_readr$ht_in\n\n[1] 66 60\nLevels: 66 60\n\n\nThe \"character\" variable reveals the years as strings:\n\nexample2a_readr$yob\n\n[1] \"2000\" \"1985\"\n\n\n\n\nQuieting the message\nThe other part of the message suggested quieting the message, which we can do when reading by setting show_col_types = FALSE:\n\nexample2a_readr &lt;- readr::read_csv(file = here::here(\"data\", \"example2a_readr.csv\"),\n                                   show_col_types = FALSE\n                                   )\n\nCall the data frame object:\n\nexample2a_readr\n\n# A tibble: 2 × 3\n  wt_lbs ht_in   yob\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    134    66  2000\n2    128    60  1985"
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#reading-.rds-files",
    "href": "modules/06_importing_and_exporting_data.html#reading-.rds-files",
    "title": "Importing and Exporting Data Frames",
    "section": "Reading .Rds Files",
    "text": "Reading .Rds Files\n\nBase R:\n\nreadRDS(file = \"my_filename.Rds\") for modified data frames\n\n\nYou can specify datatypes upon reading if using readr::read_csv() but you have to do this every time you read a file. If datatypes for variables change, you would need to track those changes so that you can return the data frame to its last state. An alternative is saveRDS() saves datatypes, file encoding, and also compresses the file. Thus, saveRDS() and readRDS() will be go to functions.\nParameters/Arguments:\n\nfile: we need a character string argument naming a file or a connection open for writing (aka the filepath)\n\n\nreadRDS(file = here::here(\"data\", \"example3.rds\"))\n\n# A tibble: 3 × 3\n  name    age    iq\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Bill     28   130\n2 Jane     35   145\n3 Sal      55   125\n\n\n\nTab-Separated Files, .tsv\nWhen column values of data are separated by a TAB, the file type is referred to as tab-separated values:\nColumns of data are separated by a tab \"\\t\":\nname    age   iq\nBill    28    130\nJane    35    145\nSal   55    125\nLet’s say these files are all simple text files and unlike the previous .csv example are not saved with extension .tsv that would flag the file format. To provide more detail about opening data files, instead assume that the file is saved as a .txt file. Technically speaking, a csv file is also just a raw text file for which the text is separated by commas. In some instances, you will encounter csv files with extensions like .txt, .dat, .raw, etc.\n\nBase R:\n\nread.table(file = \"my_filename.txt\", sep = \"\\t\") is a flexible function requiring setting the separator character argument for sep\nread.tsv(file = \"my_filename.txt\") is the same as above except that sep = \"\\t\" is the default\n\n{readr}:\n\nreadr::read_tsv(file = \"my_filename.txt\")\n\n\nWe likely won’t be dealing with .tsv files, so we won’t work through an example here.\n\n\nReading Excel Data Files, .xlsx\nFirst, we need an .xlsx data file. You can obtain one locally or online from a URL. If you don’t not have one locally, we need to get one.\nWe will first create a character object containing the URL to an .xlsx file online:\n\nurl_file &lt;- \"https://github.com/slicesofdata/fods24/raw/main/data/swim/cms-top-all-time-2023-swim.xlsx\""
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#reading-with-rioimport",
    "href": "modules/06_importing_and_exporting_data.html#reading-with-rioimport",
    "title": "Importing and Exporting Data Frames",
    "section": "Reading with rio::import()",
    "text": "Reading with rio::import()\nThen using {rio}, we will import the binary file from the URL using rio::import(). Pass the URL as the argument to the file parameter.\n\nrio::import(file = url_file)\n\n    score              name year          event   team\n1  525.35       Maia Presti 2015 1-Meter Diving Athena\n2  514.70 Makenna Parkinson 2023 1-Meter Diving Athena\n3  512.05      Emma Ng Pack 2023 1-Meter Diving Athena\n4  494.95         Izzy Doud 2023 1-Meter Diving Athena\n5  462.15     Carli Lessard 2015 1-Meter Diving Athena\n6  447.70     Alexis Romero 2023 1-Meter Diving Athena\n7  426.15        Pam Tanase 1987 1-Meter Diving Athena\n8  422.90    Jacque Desmond 2019 1-Meter Diving Athena\n9  419.60    Monica Emanuel 2008 1-Meter Diving Athena\n10 413.25    Carmen Lundell 2012 1-Meter Diving Athena\n11 527.60 Makenna Parkinson 2023 3-Meter Diving Athena\n12 526.90         Izzy Doud 2023 3-Meter Diving Athena\n13 525.30      Emma Ng Pack 2023 3-Meter Diving Athena\n14 474.20     Carli Lessard 2016 3-Meter Diving Athena\n15 441.40    Jacque Desmond 2020 3-Meter Diving Athena\n16 439.95        Elena Goss 1996 3-Meter Diving Athena\n17 428.05    Carmen Lundell 2013 3-Meter Diving Athena\n18 423.05       Maia Presti 2018 3-Meter Diving Athena\n19 414.30        Nia Cooper 2017 3-Meter Diving Athena\n20 412.00        Pam Tanase 1987 3-Meter Diving Athena\n21 628.60     James Stevick 2015 1-Meter Diving   Stag\n22 594.05  Kendall Hollimon 2017 1-Meter Diving   Stag\n23 557.80     Cyrus Gaylord 2023 1-Meter Diving   Stag\n24 538.00     Jack Griffith 2023 1-Meter Diving   Stag\n25 499.35  Patrick Quarberg 2016 1-Meter Diving   Stag\n26 493.10         Ben Smith 2023 1-Meter Diving   Stag\n27 489.75      Mark Emanuel 2006 1-Meter Diving   Stag\n28 477.70  Bennet Matazzoni 2023 1-Meter Diving   Stag\n29 477.25     Ethan Sattley 2023 1-Meter Diving   Stag\n30 471.05   Derek Eberhardt 1984 1-Meter Diving   Stag\n31 627.60     James Stevick 2015 3-Meter Diving   Stag\n32 624.50  Kendall Hollimon 2018 3-Meter Diving   Stag\n33 588.45     Cyrus Gaylord 2023 3-Meter Diving   Stag\n34 566.20     Jack Griffith 2023 3-Meter Diving   Stag\n35 514.20      Mark Emanuel 2007 3-Meter Diving   Stag\n36 499.60  Patrick Quarberg 2016 3-Meter Diving   Stag\n37 459.70      Brian Weaver 1989 3-Meter Diving   Stag\n38 450.05     Andrew Fevery 2010 3-Meter Diving   Stag\n39 444.40     Eric Moorhead 2008 3-Meter Diving   Stag\n40 415.20     Ethan Sattley 2023 3-Meter Diving   Stag"
  },
  {
    "objectID": "modules/06_importing_and_exporting_data.html#reading-with-openxlsxread.xlsx",
    "href": "modules/06_importing_and_exporting_data.html#reading-with-openxlsxread.xlsx",
    "title": "Importing and Exporting Data Frames",
    "section": "Reading with openxlsx::read.xlsx()",
    "text": "Reading with openxlsx::read.xlsx()\nWe can also use functions from {openxlsx} to read Excel files. The problem is that by default, you will only be able to read the first sheet of a workbook file. If the first sheet is all you need, this can work. Pass the URL as the argument to the xlsxFile parameter and assign its contents to an object named DAT using the assignment operator &lt;-.\n\nDAT &lt;- openxlsx::read.xlsx(xlsxFile = url_file, sheet = 1)\n\nNow that we have an object holding the data frame, we can examine it. Let’s say we want to examine only the head of the data file?\n\nhead(DAT)\n\n   score              name year          event   team\n1 525.35       Maia Presti 2015 1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023 1-Meter Diving Athena\n3 512.05      Emma Ng Pack 2023 1-Meter Diving Athena\n4 494.95         Izzy Doud 2023 1-Meter Diving Athena\n5 462.15     Carli Lessard 2015 1-Meter Diving Athena\n6 447.70     Alexis Romero 2023 1-Meter Diving Athena\n\n\nNote: When you want a different worksheet you will need to pass a sheet name argument to the sheet parameter. Let’s pass the sheet by its name, sheet = \"swim\".\n\nhead(\n  openxlsx::read.xlsx(xlsxFile = url_file, sheet = \"swim\")\n)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nExcel workbooks are more complicated than simple csv files. The can contain numerous worksheets or contain written text on rows that need to be skipped or excluded. The examples here do not address the complexity of reading such files. On one hand, you might consider rejecting them as a file format for saving data files. On the other hand, their worksheet capability make them convenient file types for storing data for annual or regional reporting when those files will be examined by and toggled through by the typical office employee who has not data science experience.\nConsequently, there are"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html",
    "title": "Selecting, Filtering, & Mutating",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#readings-and-preparation",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#readings-and-preparation",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#supplementary-readings-optional",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#supplementary-readings-optional",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Supplementary Readings (Optional)",
    "text": "Supplementary Readings (Optional)\n\nData Transformation\nHuber: Transforming Data"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#libraries",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#libraries",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n{stringr}: 1.5.1: for working with strings\n{tidyselect}: 1.2.0: for selecting sets from strings\n{magrittr}: 2.0.3: for piping with %&gt;% (plus other piping operators)"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#external-functions",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#external-functions",
    "title": "Selecting, Filtering, & Mutating",
    "section": "External Functions",
    "text": "External Functions\nview_html(): for viewing data frames in HTML format. You can source this from your /r/functions directory.\n\nR.utils::sourceDirectory(here::here(\"r\", \"functions\"))\n\nIf for some reason, you do not have the function saved, you can get it from the remote source.\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/fods24/main/r/functions/view_html.R\")"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#selecting-variables-using-dplyrselect",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#selecting-variables-using-dplyrselect",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Selecting Variables using dplyr::select()",
    "text": "Selecting Variables using dplyr::select()\nYou can reference variables by their names or by their column position in a data frame (e.g., 1, 25, etc.).\nUsing select(), you can select columns/variables from a data frame. The variables you select are retained and variables omitted that you don’t select are omitted in the returned data frame.\nBefore using a function you have never used before, you would always review the documentation for what the function is designed to accomplish.\nhelp(dplyr::select)\nOr:\n?dplyr::select\nYou can see that select() is used for selecting variables from a data frame and there are many selection features for accomplishing such tasks.\nParameters/Arguments:\n\n.data: a data frame\n...: one ore more expressions separated by commas\n\nWe will definitely need a data frame and we will need variables to select.\nLet’s start with a data frame. The USAressts data is built into R so let’s just use that for now. Let’s use select() to subset a data frame in two ways, first without piping and then with piping (preferred method).\n\nWithout piping\n\nAt a bare minimum, we will need to pass a data frame to select() at very least. But what happens if we don’t pass variables to select?\n\nselect(.data = USArrests)\n\ndata frame with 0 columns and 50 rows\n\n\nYou will see the that the returned data frame has 0 columns and 50 rows.\n\nPiping using |&gt;\n\nIf you pipe the data frame into the function, .data = USArrests is inherited and you do not need to declare it within select().\n\nUSArrests |&gt;\n  select()\n\ndata frame with 0 columns and 50 rows\n\n\nAgain, the returned data frame has 0 columns and 50 rows. If you use select() without specifying any variables for the function to select, as seen in both examples, you will have data frame that contains no columns. Let’s address some methods for selecting variables.\n\nSelecting Variables by Column Position\nVariables are columns in a data frame, so they can be selected by their element position (previously covered here). If you wanted to select the first and third column, one way is to specify each position separated by a comma.\n\nUSArrests |&gt;        # take the data frame\n  select(1, 3)      # select columns 1 and 3\n\n               Murder UrbanPop\nAlabama          13.2       58\nAlaska           10.0       48\nArizona           8.1       80\nArkansas          8.8       50\nCalifornia        9.0       91\nColorado          7.9       78\nConnecticut       3.3       77\nDelaware          5.9       72\nFlorida          15.4       80\nGeorgia          17.4       60\nHawaii            5.3       83\nIdaho             2.6       54\nIllinois         10.4       83\nIndiana           7.2       65\nIowa              2.2       57\nKansas            6.0       66\nKentucky          9.7       52\nLouisiana        15.4       66\nMaine             2.1       51\nMaryland         11.3       67\nMassachusetts     4.4       85\nMichigan         12.1       74\nMinnesota         2.7       66\nMississippi      16.1       44\nMissouri          9.0       70\nMontana           6.0       53\nNebraska          4.3       62\nNevada           12.2       81\nNew Hampshire     2.1       56\nNew Jersey        7.4       89\nNew Mexico       11.4       70\nNew York         11.1       86\nNorth Carolina   13.0       45\nNorth Dakota      0.8       44\nOhio              7.3       75\nOklahoma          6.6       68\nOregon            4.9       67\nPennsylvania      6.3       72\nRhode Island      3.4       87\nSouth Carolina   14.4       48\nSouth Dakota      3.8       45\nTennessee        13.2       59\nTexas            12.7       80\nUtah              3.2       80\nVermont           2.2       32\nVirginia          8.5       63\nWashington        4.0       73\nWest Virginia     5.7       39\nWisconsin         2.6       66\nWyoming           6.8       60\n\n\nLet’s remind ourselves of how piping works. Remember that piping will modify the data frame in steps, with each pipe passing the current form of the data frame to the next function. Not that you ever want to write two lines of code and perform this extra step to select only column 1 but you could pipe the data frame to another select().\n\nUSArrests |&gt;        # take the data frame\n  select(1, 3) |&gt;   # select columns 1 and 3\n  select(1)         # then select column 1 only\n\n               Murder\nAlabama          13.2\nAlaska           10.0\nArizona           8.1\nArkansas          8.8\nCalifornia        9.0\nColorado          7.9\nConnecticut       3.3\nDelaware          5.9\nFlorida          15.4\nGeorgia          17.4\nHawaii            5.3\nIdaho             2.6\nIllinois         10.4\nIndiana           7.2\nIowa              2.2\nKansas            6.0\nKentucky          9.7\nLouisiana        15.4\nMaine             2.1\nMaryland         11.3\nMassachusetts     4.4\nMichigan         12.1\nMinnesota         2.7\nMississippi      16.1\nMissouri          9.0\nMontana           6.0\nNebraska          4.3\nNevada           12.2\nNew Hampshire     2.1\nNew Jersey        7.4\nNew Mexico       11.4\nNew York         11.1\nNorth Carolina   13.0\nNorth Dakota      0.8\nOhio              7.3\nOklahoma          6.6\nOregon            4.9\nPennsylvania      6.3\nRhode Island      3.4\nSouth Carolina   14.4\nSouth Dakota      3.8\nTennessee        13.2\nTexas            12.7\nUtah              3.2\nVermont           2.2\nVirginia          8.5\nWashington        4.0\nWest Virginia     5.7\nWisconsin         2.6\nWyoming           6.8\n\n\nThe better approach is just to select column 1 in a single line.\n\nUSArrests |&gt;\n  select(1)\n\n               Murder\nAlabama          13.2\nAlaska           10.0\nArizona           8.1\nArkansas          8.8\nCalifornia        9.0\nColorado          7.9\nConnecticut       3.3\nDelaware          5.9\nFlorida          15.4\nGeorgia          17.4\nHawaii            5.3\nIdaho             2.6\nIllinois         10.4\nIndiana           7.2\nIowa              2.2\nKansas            6.0\nKentucky          9.7\nLouisiana        15.4\nMaine             2.1\nMaryland         11.3\nMassachusetts     4.4\nMichigan         12.1\nMinnesota         2.7\nMississippi      16.1\nMissouri          9.0\nMontana           6.0\nNebraska          4.3\nNevada           12.2\nNew Hampshire     2.1\nNew Jersey        7.4\nNew Mexico       11.4\nNew York         11.1\nNorth Carolina   13.0\nNorth Dakota      0.8\nOhio              7.3\nOklahoma          6.6\nOregon            4.9\nPennsylvania      6.3\nRhode Island      3.4\nSouth Carolina   14.4\nSouth Dakota      3.8\nTennessee        13.2\nTexas            12.7\nUtah              3.2\nVermont           2.2\nVirginia          8.5\nWashington        4.0\nWest Virginia     5.7\nWisconsin         2.6\nWyoming           6.8\n\n\n\n\nSelecting Variables by Column Name\nRather than position, you will likely wish to select by variable name. We will address several approaches for doing so. Each approach are benefical in different contexts.\n\nSelecting Variables as Unquoted Expressions\nVariables can be passed separately without quotes. We can pass two arguments, one with Murder and the other with Assault, separating each with a comma. Because of some special characteristics of the {dplyr}, we can use variable names without quotes. Let’s also reduce the returned data frame using head() in order to save space.\n\nUSArrests |&gt; \n  select(Murder, Assault) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\n\n\nSelecting Variables as Characters/Strings\nYou are most likely familiar with variable names as quoted strings. We can pass two arguments here using the variable names in quotes. This approach is more similar to a procedures use with in base R functions as you cannot pass unquoted expressions in base R.\n\nUSArrests |&gt; \n  select(\"Murder\", \"Assault\") |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\n\n\nSelecting Variables as a Character Vector\nWhat if your variables were in a vector, c(\"Murder\", \"Assault\"))?\n\nUSArrests |&gt;\n  select(c(\"Murder\", \"Assault\")) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\nThe same will work if you passed a numeric vector c(1, 3).\n\n\nSelecting Using an External Vector Object\nIn many use cases, you will will have a vector of variable names that would will want to pass rather than type individually. This approach also reduces confusion when you have key variables that you want to work with. Create a vector once and then use again and again. If you make any changes, you will only have to make them once, rather than in multiple places.\nFirst, create the vector object:\n\nkeep_vars &lt;- c(\"Murder\", \"Assault\")\n\nSecond, Then pass the vector into the function:\n\nUSArrests |&gt;\n  select(keep_vars) \n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(keep_vars)\n\n  # Now:\n  data %&gt;% select(all_of(keep_vars))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n               Murder Assault\nAlabama          13.2     236\nAlaska           10.0     263\nArizona           8.1     294\nArkansas          8.8     190\nCalifornia        9.0     276\nColorado          7.9     204\nConnecticut       3.3     110\nDelaware          5.9     238\nFlorida          15.4     335\nGeorgia          17.4     211\nHawaii            5.3      46\nIdaho             2.6     120\nIllinois         10.4     249\nIndiana           7.2     113\nIowa              2.2      56\nKansas            6.0     115\nKentucky          9.7     109\nLouisiana        15.4     249\nMaine             2.1      83\nMaryland         11.3     300\nMassachusetts     4.4     149\nMichigan         12.1     255\nMinnesota         2.7      72\nMississippi      16.1     259\nMissouri          9.0     178\nMontana           6.0     109\nNebraska          4.3     102\nNevada           12.2     252\nNew Hampshire     2.1      57\nNew Jersey        7.4     159\nNew Mexico       11.4     285\nNew York         11.1     254\nNorth Carolina   13.0     337\nNorth Dakota      0.8      45\nOhio              7.3     120\nOklahoma          6.6     151\nOregon            4.9     159\nPennsylvania      6.3     106\nRhode Island      3.4     174\nSouth Carolina   14.4     279\nSouth Dakota      3.8      86\nTennessee        13.2     188\nTexas            12.7     201\nUtah              3.2     120\nVermont           2.2      48\nVirginia          8.5     156\nWashington        4.0     145\nWest Virginia     5.7      81\nWisconsin         2.6      53\nWyoming           6.8     161\n\n\nHmm. Warning message.\nNote: select(keep_vars) is deprecated as a solution, so if you see this approach someplace, it won’t work properly at this time or in the future. The warning message states that cannot do this without some modifications. What is suggested is all_of(). When your variables are in an external variable, all_of(keep_vars) will tell select() that your variables are all of the variables in the vector. Yes, this is an extra step but worth the flexibility.\n\nUSArrests |&gt;\n  select(all_of(keep_vars)) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\nBut this could be problematic if a variable in your vector does not exists. Let’s add some variables that are not in the data frame and then pass that vector.\nkeep_vars_more &lt;- c(\"Murder\", \"Assault\", \"Var_x\", \"Var_y\", \"Var_z\")\n\nUSArrests |&gt;\n  select(all_of(keep_vars_more)) |&gt; \n  head()\nYou will see the following error message:\nError in `all_of()`:\n! Can't subset columns that don't exist.\n✖ Columns `Var_x`, `Var_y`, and `Var_z` don't exist.\nTip: Rather than using all_of(), use any_of(). In this instance, any of the variables that exist in the data frame will be selection. Those variables that are not in the data frame will be ignored. With this approach, your code will not break if there something changes.\n\nUSArrests |&gt;\n  select(any_of(keep_vars_more)) |&gt; \n  head()\n\n           Murder Assault\nAlabama      13.2     236\nAlaska       10.0     263\nArizona       8.1     294\nArkansas      8.8     190\nCalifornia    9.0     276\nColorado      7.9     204\n\n\n\n\nSelecting Variables Starting with or Ending with Certain Characters\nOne thing about {dplyr}, when you load the library, there are functions from other libraries that are imported along with {dplyr}’s own functions. These important functions are designed to work with each other, so the people who maintain the libraries have packaged them up nicely so you don’t have to load separate libraries.\nMany of the functions are imported from the {tidyselect} library and these functions are what give you additional manipulation ability. Some imported functions are: all_of(), any_of(), contains(), ends_with(), everything(), last_col(), matches(), and starts_with().\nWith functions like starts_with(), contains(), and ends_with(), you can select variables containing character patterns in their names. For example, rather than code out all variables for a memory span task, you might want to grab variables that contain the characters \"span\".\nRather than hard coding variable names (e.g., \"span_time1\", \"span_time2\", c(\"Murder\", \"Assault\")) to pass as an argument to select(), you would use another function to perform the heaving lifting for you (e.g.,starts_with()). In this case, the variable names that starts_with() specific character patterns get passed to select(). This process represents a good example of whe what is referred to as functional programming. This is also a good example of working smarter, not harder. Rather than coding specifically what to pass as an argument to another function, you utilize another function to pass its returned object as an argument to another function.\n\n\nSelecting Variables Using starts_with()\n\nUnderstanding starts_with()\nBut first, we need to understand what starts_with(), actually does. The function name should provide you some insight but for more information, use ?starts_with.\nstarts_with(match, \n            ignore.case = TRUE, \n            vars = NULL\n            )\nParameters/Arguments:\n\nmatch: a character vector\nignore.case: if TRUE, the default, ignores case when matching names. This is most flexible.\nvars: a character vector of variable names. If not supplied, the variables are taken from the current selection context (as established by functions like select() or pivot_longer()).\n\nThe best way to understand the function is to use it (after reading the documentation). Let’s try out starts_with(). Let’s set a required pattern match = some character and because vars = NULL by default, let’s just set vars = some character vector. If you reviewed the documentation or looked at the arguments above, vars is not the second parameter, so you will want to name it in the function call if it takes that second position as seen below. We will first test this function without using it on a data frame.\nWe set match = \"a\" and vars = c(\"Hello\", \"Hi\", \"Bye\"). This will look for character \"a\" to match the elements of a character vector c(\"Hello\", \"Hi\", \"Bye\").\n\nstarts_with(match = \"a\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\")\n            )\n\ninteger(0)\n\n\nWhat is returned is integer(0), which is actually speak for “there is no match”. Not very intuitive. Hmm, OK. Let’s try another character.\n\nstarts_with(match = \"b\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\")\n            )\n\n[1] 3\n\n\nOK, so now an integer is returned (yes, try is.integer() if you don’t believe me).\n\nis.integer(\n  starts_with(\"b\", \n              vars = c(\"Hello\", \"Hi\", \"Bye\")\n              ))\n\n[1] TRUE\n\n\nAnd even though you only see one value, this object is still a vector. We can check using is.vector().\n\nis.vector(\n  starts_with(\"b\", \n              vars = c(\"Hello\", \"Hi\", \"Bye\")\n              ))\n\n[1] TRUE\n\n\nImportantly, starts_with() returns a vector of values. What do the values correspond to? The values in the vector refer to the element index/position of a match and the number of the elements in the vector tells refers to the number of matches found. Because the third string element \"Bye\" starts with \"b\", that’s what is returned.\nTry something else:\n\nstarts_with(\"h\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\")\n            )\n\n[1] 1 2\n\n\nNow the function returns a vector containing 1 and a 2, giving length = 2, representing both the first and the second elements start with “h”.\nImportantly, letter casing is ignored because ignore.case = TRUE by default. Set to FALSE if you want your match to be case sensitive.\n\nstarts_with(\"h\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\"), \n            ignore.case = F\n            )\n\ninteger(0)\n\n\nAnd now there are no matches.\n\n\nSelecting Variables from a Data Frame using starts_with()\nYou will typically use starts_with() when working with a data frame and in conjunction with other functions, like select() in order to select variables that start with certain characters. When using starts_with() in the context of select(), the vars argument is essentially passing vars = the names of the columns of the data frame passed to select().\nExample:\nselect(mydataframe,\n       starts_with(match = \"my pattern\",\n                   vars = \"var names of mydataframe\")\n      )\nLet’s provide two use cases:\n\nWithout Piping\n\nYou can pass the data frame as the first argument to select().\n\nselect(USArrests, \n       starts_with(\"m\")\n       ) |&gt; \n  head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nNotice that the only column variable that is returned is Murder.\n\nWith Piping\n\nYou can also pipe the data frame into select(), which assumes the first argument is a data frame. This is a process you will see used often by others.\n\nUSArrests |&gt;\n  select(starts_with(\"m\")) |&gt; \n  head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\n\n\nSelecting Variables using ends_with()\nYou can use ends_with() to find matches at the end of strings. This function is useful if you have variables that end based on their measurement type (e.g., “_rt” or “_acc” for reaction times and accuracy, respectively). Having the foresight to create variables is such a way to make accessing them easily later is a good example of working smarter, not harder.\n\nUSArrests |&gt;\n  select(ends_with(\"t\")) |&gt; \n  head()\n\n           Assault\nAlabama        236\nAlaska         263\nArizona        294\nArkansas       190\nCalifornia     276\nColorado       204\n\n\n\n\n\n\nSelecting and Selecting Out Variables By/Between Index\nSo far, we have address selecting variables. There are, however, many approaches for selecting but also selecting out or omitting column variables. In other words, rather than including 14 out of 15 variables, you could simply exclude 1 of the 15 variables to achieve the same result.\nYou can pass multiple arguments for each specification or you can pass a single vector that contains all specifications.\n\nselect(1, 2): select first and second columns\nselect(c(1, 2)): select first and second columns\nselect(-c(1, 2)): select out first and second columns\nselect(1:2): select first through second columns\nselect(c(1:2)): select first through second columns\nselect(-c(1:2)): select out first through second columns\n\nPotential Recommendation: use options utilizing c() to pass a vector because this habit will be more versatile with base R functionality. However, online solutions will likely not take this approach.\nLet’s make a data frame to work with first. We will name the data frame DAT even though this is a terrible name because it lacks diagnosticity.\n\nDAT &lt;- \n  data.frame(\n    Id  = c(100, 101, 102, 103, 104, 100, 105),\n    Sex = c('male', 'female', 'Male', NA, 'man', \"male\", \"neither\"),\n    Age = c(25, 33, 27, 40, 44, 25, 40),\n    Renting = c(\"yes\", NA, \"yes\", NA, \"no\", \"yes\", \"yes\")\n)\n\nSelect columns 1 and 2:\n\nDAT |&gt;\n  select(1, 2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT |&gt;\n  select(c(1, 2)) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect out columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT |&gt;\n  select(-c(1,2)) \n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect from columns 1 to 2 using the : operator:\n\nDAT |&gt;\n  select(1:2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect from columns 1 through 3 using a vector containing the : operator:\n\nDAT |&gt;\n  select(c(1:3)) \n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out columns 1 through 3 using a vector containing the : operator:\n\nDAT |&gt;\n  select(-c(1:3))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\n\n\nSelecting and Selecting Out Variables By or Between Character Name\nThese approaches are similar to those offered earlier except that some involve passing variables by their name (e.g., character names). Whereas the order of the variables in a data frame may move around, the names may be more stable or permanent, at least after you have cleaned up the names. Consequently, passing variables by name may be more foolproof.\nYou don’t have to be familiar with all approaches and you may settle on using one that makes the most sense to you.\n\nselect(\"var1\", \"var2\")\nselect(c(\"var1\", \"var2\"))\nselect(-c(\"var1\", \"var2\"))\nselect(var1:var2))\nselect(c(\"var1\":\"var2))\nselect(-c(\"var1\":\"var2))\n\nRecommendation: use options utilizing c() as this will be more versatile with base R functionality.\nThese function approaches also work but they may lead to some confusion regarding usage of quotes:\n\nselect(var1, var2)\nselect(c(var1, var2))\nselect(-c(var1, var2))\n\nSelect variables Id though Age using the : operator:\n\nDAT |&gt;\n  select(Id:Age)                            # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age passed as strings using the : operator:\n\nDAT |&gt;\n  select(\"Id\":\"Age\")                        # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT |&gt;\n  select(c(\"Id\":\"Age\"))                     # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT |&gt;\n  select(-c(\"Id\":\"Age\"))                    # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\nYou can also use the ! operator to select NOT these variables (therefore, all others)\n\nDAT |&gt;\n  select(!c(\"Id\":\"Age\"))                    # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\n\n\nSelecting and Selecting Out Variables Characters in Their Names\n\nselect(starts_with(\"characters\"))\nselect(ends_with(\"characters\"))\nselect(contains('e'))\n\n\nSelecting using starts_with()\nSelect variables which start with character “i”:\n\nDAT |&gt; \n  select(starts_with('i'))\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 100\n7 105\n\n\nSelect variables which DO NOT start with character “s”:\n\nDAT |&gt; \n  select(-starts_with('s'))\n\n   Id Age Renting\n1 100  25     yes\n2 101  33    &lt;NA&gt;\n3 102  27     yes\n4 103  40    &lt;NA&gt;\n5 104  44      no\n6 100  25     yes\n7 105  40     yes\n\n\n\n\nSelecting using ends_with()\nSelect variables which end with character “e”:\n\nDAT |&gt; \n  select(ends_with('e'))\n\n  Age\n1  25\n2  33\n3  27\n4  40\n5  44\n6  25\n7  40\n\n\nSelect variables which end with character “e”:\n\nDAT |&gt; \n  select(-ends_with('e'))\n\n   Id     Sex Renting\n1 100    male     yes\n2 101  female    &lt;NA&gt;\n3 102    Male     yes\n4 103    &lt;NA&gt;    &lt;NA&gt;\n5 104     man      no\n6 100    male     yes\n7 105 neither     yes\n\n\n\n\nSelecting using contains()\nSelect variables which contain character “g”:\n\nDAT |&gt; \n  select(contains('g'))\n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect variables which DO NOT contain character “g”:\n\nDAT |&gt; \n  select(-contains('g'))\n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\n\n\nSelecting using regular expressions\nSometimes you do not want to search for specific character strings. Instead, you might want to look for strings that contain particular character patterns. For example, typing out var1, var2, var3 could be annoying. You might prefer just grabbing variables that match the pattern \"var\".\nWe will use some regular expressions, or regex, to help us. For the regex, you we will need to specify some code for finding patterns. For example, \\\\d{4} will search for patterns with 4 digits, whereas the dot star .* will help with all patterns. In particular, . refers to any character (e.g,. digit, alpha character, or any other special character) and * means zero or more times, so this pattern will search for all files that start with 4 digits followed by anything in the name. A pattern will restrict the search to files containing that exact character string. Some example will be helpful.\n\nSelecting variables of all patterns using \".*\"\nSelect variables containing a regular expression, use matches():\n.* will grab all names because it means any character and any number of times\n\nDAT |&gt; \n  select(matches(\".*\"))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\n\n\nSelecting variables with digits using \"\\\\d\"\n\\\\d will grab all variables containing a digit:\n\nDAT |&gt; \n  mutate(var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) |&gt;\n  select(matches(\"\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\n\n\nSelecting variables that start and contain characters \"v.*\\\\d\"\nv.*\\\\d will grab all variables that start with v and then contain any characters which are followed by a digit:\n\nDAT |&gt;\n    mutate(var_1    = 1,\n           var_11   = 1,\n           var_3    = 1,\n           var1_var = 1\n         ) |&gt;\n  select(matches(\"v.*\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\n\n\nSelecting variables that end with a digit using \"\\\\d$\"\n\\\\d$ will grab all variables ending in a digit ($ means end):\n\nDAT |&gt; \n    mutate(var_1    = 1,\n           var_11   = 1,\n           var_3    = 1,\n           var1_var = 1\n           ) |&gt;\n  select(matches(\"\\\\d$\"))\n\n  var_1 var_11 var_3\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n7     1      1     1\n\n\n\n\n\nSelecting variables by negation\nYou can also negate all regular expression matches if you want to exclude:\n\nDAT |&gt;\n      mutate(var_1    = 1,\n             var_11   = 1,\n             var_3    = 1,\n             var1_var = 1\n             ) |&gt;\n  select(-matches(\"\\\\d$\"))\n\n   Id     Sex Age Renting var1_var\n1 100    male  25     yes        1\n2 101  female  33    &lt;NA&gt;        1\n3 102    Male  27     yes        1\n4 103    &lt;NA&gt;  40    &lt;NA&gt;        1\n5 104     man  44      no        1\n6 100    male  25     yes        1\n7 105 neither  40     yes        1\n\n\nNote: The functions will return lowercase and uppercase variable name matches because the default behavior is ignore.case = TRUE. Set to FALSE if you want to perform precise surgery on the variables.\n\n\n\nSelecting and Selecting Out Variables by Type\nSelect variables that are numeric:\n\nDAT |&gt;\n  select(where(is.numeric))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are NOT numeric:\n\nDAT |&gt; \n  select(-where(is.numeric))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are character:\n\nDAT |&gt; \n  select(where(is.character))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are NOT character:\n\nDAT |&gt;\n  select(-where(is.character))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are logical (TRUE to FALSE):\n\nDAT |&gt; \n  select(where(is.logical))\n\ndata frame with 0 columns and 7 rows\n\n\nSelect variables that are NOT logical (TRUE to FALSE):\n\nDAT |&gt; \n  select(-where(is.logical))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-a-constant-value",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-a-constant-value",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Creating/Mutating A Constant Value",
    "text": "Creating/Mutating A Constant Value\nLet’s create a new variable, new_var and set it equal to 1.\n\nUSArrests |&gt;\n  mutate(new_var1 = 1)\n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2        1\nAlaska           10.0     263       48 44.5        1\nArizona           8.1     294       80 31.0        1\nArkansas          8.8     190       50 19.5        1\nCalifornia        9.0     276       91 40.6        1\nColorado          7.9     204       78 38.7        1\nConnecticut       3.3     110       77 11.1        1\nDelaware          5.9     238       72 15.8        1\nFlorida          15.4     335       80 31.9        1\nGeorgia          17.4     211       60 25.8        1\nHawaii            5.3      46       83 20.2        1\nIdaho             2.6     120       54 14.2        1\nIllinois         10.4     249       83 24.0        1\nIndiana           7.2     113       65 21.0        1\nIowa              2.2      56       57 11.3        1\nKansas            6.0     115       66 18.0        1\nKentucky          9.7     109       52 16.3        1\nLouisiana        15.4     249       66 22.2        1\nMaine             2.1      83       51  7.8        1\nMaryland         11.3     300       67 27.8        1\nMassachusetts     4.4     149       85 16.3        1\nMichigan         12.1     255       74 35.1        1\nMinnesota         2.7      72       66 14.9        1\nMississippi      16.1     259       44 17.1        1\nMissouri          9.0     178       70 28.2        1\nMontana           6.0     109       53 16.4        1\nNebraska          4.3     102       62 16.5        1\nNevada           12.2     252       81 46.0        1\nNew Hampshire     2.1      57       56  9.5        1\nNew Jersey        7.4     159       89 18.8        1\nNew Mexico       11.4     285       70 32.1        1\nNew York         11.1     254       86 26.1        1\nNorth Carolina   13.0     337       45 16.1        1\nNorth Dakota      0.8      45       44  7.3        1\nOhio              7.3     120       75 21.4        1\nOklahoma          6.6     151       68 20.0        1\nOregon            4.9     159       67 29.3        1\nPennsylvania      6.3     106       72 14.9        1\nRhode Island      3.4     174       87  8.3        1\nSouth Carolina   14.4     279       48 22.5        1\nSouth Dakota      3.8      86       45 12.8        1\nTennessee        13.2     188       59 26.9        1\nTexas            12.7     201       80 25.5        1\nUtah              3.2     120       80 22.9        1\nVermont           2.2      48       32 11.2        1\nVirginia          8.5     156       63 20.7        1\nWashington        4.0     145       73 26.2        1\nWest Virginia     5.7      81       39  9.3        1\nWisconsin         2.6      53       66 10.8        1\nWyoming           6.8     161       60 15.6        1\n\n\nTo mutate more than one variable, you can add a new name-value pair as a new argument:\n\nUSArrests |&gt;\n  mutate(new_var1 = 1,\n         new_var2 = 9999\n         )\n\n               Murder Assault UrbanPop Rape new_var1 new_var2\nAlabama          13.2     236       58 21.2        1     9999\nAlaska           10.0     263       48 44.5        1     9999\nArizona           8.1     294       80 31.0        1     9999\nArkansas          8.8     190       50 19.5        1     9999\nCalifornia        9.0     276       91 40.6        1     9999\nColorado          7.9     204       78 38.7        1     9999\nConnecticut       3.3     110       77 11.1        1     9999\nDelaware          5.9     238       72 15.8        1     9999\nFlorida          15.4     335       80 31.9        1     9999\nGeorgia          17.4     211       60 25.8        1     9999\nHawaii            5.3      46       83 20.2        1     9999\nIdaho             2.6     120       54 14.2        1     9999\nIllinois         10.4     249       83 24.0        1     9999\nIndiana           7.2     113       65 21.0        1     9999\nIowa              2.2      56       57 11.3        1     9999\nKansas            6.0     115       66 18.0        1     9999\nKentucky          9.7     109       52 16.3        1     9999\nLouisiana        15.4     249       66 22.2        1     9999\nMaine             2.1      83       51  7.8        1     9999\nMaryland         11.3     300       67 27.8        1     9999\nMassachusetts     4.4     149       85 16.3        1     9999\nMichigan         12.1     255       74 35.1        1     9999\nMinnesota         2.7      72       66 14.9        1     9999\nMississippi      16.1     259       44 17.1        1     9999\nMissouri          9.0     178       70 28.2        1     9999\nMontana           6.0     109       53 16.4        1     9999\nNebraska          4.3     102       62 16.5        1     9999\nNevada           12.2     252       81 46.0        1     9999\nNew Hampshire     2.1      57       56  9.5        1     9999\nNew Jersey        7.4     159       89 18.8        1     9999\nNew Mexico       11.4     285       70 32.1        1     9999\nNew York         11.1     254       86 26.1        1     9999\nNorth Carolina   13.0     337       45 16.1        1     9999\nNorth Dakota      0.8      45       44  7.3        1     9999\nOhio              7.3     120       75 21.4        1     9999\nOklahoma          6.6     151       68 20.0        1     9999\nOregon            4.9     159       67 29.3        1     9999\nPennsylvania      6.3     106       72 14.9        1     9999\nRhode Island      3.4     174       87  8.3        1     9999\nSouth Carolina   14.4     279       48 22.5        1     9999\nSouth Dakota      3.8      86       45 12.8        1     9999\nTennessee        13.2     188       59 26.9        1     9999\nTexas            12.7     201       80 25.5        1     9999\nUtah              3.2     120       80 22.9        1     9999\nVermont           2.2      48       32 11.2        1     9999\nVirginia          8.5     156       63 20.7        1     9999\nWashington        4.0     145       73 26.2        1     9999\nWest Virginia     5.7      81       39  9.3        1     9999\nWisconsin         2.6      53       66 10.8        1     9999\nWyoming           6.8     161       60 15.6        1     9999\n\n\nOr you can add a new mutate() by piping:\n\nUSArrests |&gt;\n  mutate(new_var1 = 1) |&gt;  # add the variable \n  mutate(new_var1 = 9999)  # then add another variable \n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999\n\n\nWhatever your approach, keep the variable creation on separate lines. Don’t do this:\n\nUSArrests |&gt;\n  mutate(new_var1 = 1, new_var1 = 9999)   \n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999\n\n\nAlthough there is nothing technically incorrect with doing so, (1) this is harder to read, (2) the R community won’t like it, and importantly (3) it is less flexible when you want to temporarily comment out a line of your code as seen here.\n\nUSArrests |&gt;\n#  mutate(new_var1 = 1) |&gt;  # add the variable \n  mutate(new_var1 = 9999)  # then add another variable \n\n               Murder Assault UrbanPop Rape new_var1\nAlabama          13.2     236       58 21.2     9999\nAlaska           10.0     263       48 44.5     9999\nArizona           8.1     294       80 31.0     9999\nArkansas          8.8     190       50 19.5     9999\nCalifornia        9.0     276       91 40.6     9999\nColorado          7.9     204       78 38.7     9999\nConnecticut       3.3     110       77 11.1     9999\nDelaware          5.9     238       72 15.8     9999\nFlorida          15.4     335       80 31.9     9999\nGeorgia          17.4     211       60 25.8     9999\nHawaii            5.3      46       83 20.2     9999\nIdaho             2.6     120       54 14.2     9999\nIllinois         10.4     249       83 24.0     9999\nIndiana           7.2     113       65 21.0     9999\nIowa              2.2      56       57 11.3     9999\nKansas            6.0     115       66 18.0     9999\nKentucky          9.7     109       52 16.3     9999\nLouisiana        15.4     249       66 22.2     9999\nMaine             2.1      83       51  7.8     9999\nMaryland         11.3     300       67 27.8     9999\nMassachusetts     4.4     149       85 16.3     9999\nMichigan         12.1     255       74 35.1     9999\nMinnesota         2.7      72       66 14.9     9999\nMississippi      16.1     259       44 17.1     9999\nMissouri          9.0     178       70 28.2     9999\nMontana           6.0     109       53 16.4     9999\nNebraska          4.3     102       62 16.5     9999\nNevada           12.2     252       81 46.0     9999\nNew Hampshire     2.1      57       56  9.5     9999\nNew Jersey        7.4     159       89 18.8     9999\nNew Mexico       11.4     285       70 32.1     9999\nNew York         11.1     254       86 26.1     9999\nNorth Carolina   13.0     337       45 16.1     9999\nNorth Dakota      0.8      45       44  7.3     9999\nOhio              7.3     120       75 21.4     9999\nOklahoma          6.6     151       68 20.0     9999\nOregon            4.9     159       67 29.3     9999\nPennsylvania      6.3     106       72 14.9     9999\nRhode Island      3.4     174       87  8.3     9999\nSouth Carolina   14.4     279       48 22.5     9999\nSouth Dakota      3.8      86       45 12.8     9999\nTennessee        13.2     188       59 26.9     9999\nTexas            12.7     201       80 25.5     9999\nUtah              3.2     120       80 22.9     9999\nVermont           2.2      48       32 11.2     9999\nVirginia          8.5     156       63 20.7     9999\nWashington        4.0     145       73 26.2     9999\nWest Virginia     5.7      81       39  9.3     9999\nWisconsin         2.6      53       66 10.8     9999\nWyoming           6.8     161       60 15.6     9999"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-a-constant-character",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-a-constant-character",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Creating/Mutating A Constant Character",
    "text": "Creating/Mutating A Constant Character\n\nUSArrests |&gt;\n  mutate(new_var1 = \"Below Average\",\n         )\n\n               Murder Assault UrbanPop Rape      new_var1\nAlabama          13.2     236       58 21.2 Below Average\nAlaska           10.0     263       48 44.5 Below Average\nArizona           8.1     294       80 31.0 Below Average\nArkansas          8.8     190       50 19.5 Below Average\nCalifornia        9.0     276       91 40.6 Below Average\nColorado          7.9     204       78 38.7 Below Average\nConnecticut       3.3     110       77 11.1 Below Average\nDelaware          5.9     238       72 15.8 Below Average\nFlorida          15.4     335       80 31.9 Below Average\nGeorgia          17.4     211       60 25.8 Below Average\nHawaii            5.3      46       83 20.2 Below Average\nIdaho             2.6     120       54 14.2 Below Average\nIllinois         10.4     249       83 24.0 Below Average\nIndiana           7.2     113       65 21.0 Below Average\nIowa              2.2      56       57 11.3 Below Average\nKansas            6.0     115       66 18.0 Below Average\nKentucky          9.7     109       52 16.3 Below Average\nLouisiana        15.4     249       66 22.2 Below Average\nMaine             2.1      83       51  7.8 Below Average\nMaryland         11.3     300       67 27.8 Below Average\nMassachusetts     4.4     149       85 16.3 Below Average\nMichigan         12.1     255       74 35.1 Below Average\nMinnesota         2.7      72       66 14.9 Below Average\nMississippi      16.1     259       44 17.1 Below Average\nMissouri          9.0     178       70 28.2 Below Average\nMontana           6.0     109       53 16.4 Below Average\nNebraska          4.3     102       62 16.5 Below Average\nNevada           12.2     252       81 46.0 Below Average\nNew Hampshire     2.1      57       56  9.5 Below Average\nNew Jersey        7.4     159       89 18.8 Below Average\nNew Mexico       11.4     285       70 32.1 Below Average\nNew York         11.1     254       86 26.1 Below Average\nNorth Carolina   13.0     337       45 16.1 Below Average\nNorth Dakota      0.8      45       44  7.3 Below Average\nOhio              7.3     120       75 21.4 Below Average\nOklahoma          6.6     151       68 20.0 Below Average\nOregon            4.9     159       67 29.3 Below Average\nPennsylvania      6.3     106       72 14.9 Below Average\nRhode Island      3.4     174       87  8.3 Below Average\nSouth Carolina   14.4     279       48 22.5 Below Average\nSouth Dakota      3.8      86       45 12.8 Below Average\nTennessee        13.2     188       59 26.9 Below Average\nTexas            12.7     201       80 25.5 Below Average\nUtah              3.2     120       80 22.9 Below Average\nVermont           2.2      48       32 11.2 Below Average\nVirginia          8.5     156       63 20.7 Below Average\nWashington        4.0     145       73 26.2 Below Average\nWest Virginia     5.7      81       39  9.3 Below Average\nWisconsin         2.6      53       66 10.8 Below Average\nWyoming           6.8     161       60 15.6 Below Average"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-a-logical-object",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-a-logical-object",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Creating/Mutating A Logical Object",
    "text": "Creating/Mutating A Logical Object\nLogical objects are TRUE or FALSE. We can perform the logical test by asking whether Assault &gt; Murder. If the Assault value for a row is greater than the Murder value, TRUE will be returned, otherwise FALSE.\n\nUSArrests |&gt;\n  mutate(new_var = Assault &gt; Murder)\n\n               Murder Assault UrbanPop Rape new_var\nAlabama          13.2     236       58 21.2    TRUE\nAlaska           10.0     263       48 44.5    TRUE\nArizona           8.1     294       80 31.0    TRUE\nArkansas          8.8     190       50 19.5    TRUE\nCalifornia        9.0     276       91 40.6    TRUE\nColorado          7.9     204       78 38.7    TRUE\nConnecticut       3.3     110       77 11.1    TRUE\nDelaware          5.9     238       72 15.8    TRUE\nFlorida          15.4     335       80 31.9    TRUE\nGeorgia          17.4     211       60 25.8    TRUE\nHawaii            5.3      46       83 20.2    TRUE\nIdaho             2.6     120       54 14.2    TRUE\nIllinois         10.4     249       83 24.0    TRUE\nIndiana           7.2     113       65 21.0    TRUE\nIowa              2.2      56       57 11.3    TRUE\nKansas            6.0     115       66 18.0    TRUE\nKentucky          9.7     109       52 16.3    TRUE\nLouisiana        15.4     249       66 22.2    TRUE\nMaine             2.1      83       51  7.8    TRUE\nMaryland         11.3     300       67 27.8    TRUE\nMassachusetts     4.4     149       85 16.3    TRUE\nMichigan         12.1     255       74 35.1    TRUE\nMinnesota         2.7      72       66 14.9    TRUE\nMississippi      16.1     259       44 17.1    TRUE\nMissouri          9.0     178       70 28.2    TRUE\nMontana           6.0     109       53 16.4    TRUE\nNebraska          4.3     102       62 16.5    TRUE\nNevada           12.2     252       81 46.0    TRUE\nNew Hampshire     2.1      57       56  9.5    TRUE\nNew Jersey        7.4     159       89 18.8    TRUE\nNew Mexico       11.4     285       70 32.1    TRUE\nNew York         11.1     254       86 26.1    TRUE\nNorth Carolina   13.0     337       45 16.1    TRUE\nNorth Dakota      0.8      45       44  7.3    TRUE\nOhio              7.3     120       75 21.4    TRUE\nOklahoma          6.6     151       68 20.0    TRUE\nOregon            4.9     159       67 29.3    TRUE\nPennsylvania      6.3     106       72 14.9    TRUE\nRhode Island      3.4     174       87  8.3    TRUE\nSouth Carolina   14.4     279       48 22.5    TRUE\nSouth Dakota      3.8      86       45 12.8    TRUE\nTennessee        13.2     188       59 26.9    TRUE\nTexas            12.7     201       80 25.5    TRUE\nUtah              3.2     120       80 22.9    TRUE\nVermont           2.2      48       32 11.2    TRUE\nVirginia          8.5     156       63 20.7    TRUE\nWashington        4.0     145       73 26.2    TRUE\nWest Virginia     5.7      81       39  9.3    TRUE\nWisconsin         2.6      53       66 10.8    TRUE\nWyoming           6.8     161       60 15.6    TRUE\n\n\nWe see that all states (rows) have more assults than murders. No surprise."
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-based-on-function",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#creatingmutating-based-on-function",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Creating/Mutating Based on Function",
    "text": "Creating/Mutating Based on Function\nHere, the name value pair will contain a function. For example, let’s create a variable based on the mean() of a variable.\n\nUSArrests |&gt;\n  mutate(Mean_Assault = mean(Assault))\n\n               Murder Assault UrbanPop Rape Mean_Assault\nAlabama          13.2     236       58 21.2       170.76\nAlaska           10.0     263       48 44.5       170.76\nArizona           8.1     294       80 31.0       170.76\nArkansas          8.8     190       50 19.5       170.76\nCalifornia        9.0     276       91 40.6       170.76\nColorado          7.9     204       78 38.7       170.76\nConnecticut       3.3     110       77 11.1       170.76\nDelaware          5.9     238       72 15.8       170.76\nFlorida          15.4     335       80 31.9       170.76\nGeorgia          17.4     211       60 25.8       170.76\nHawaii            5.3      46       83 20.2       170.76\nIdaho             2.6     120       54 14.2       170.76\nIllinois         10.4     249       83 24.0       170.76\nIndiana           7.2     113       65 21.0       170.76\nIowa              2.2      56       57 11.3       170.76\nKansas            6.0     115       66 18.0       170.76\nKentucky          9.7     109       52 16.3       170.76\nLouisiana        15.4     249       66 22.2       170.76\nMaine             2.1      83       51  7.8       170.76\nMaryland         11.3     300       67 27.8       170.76\nMassachusetts     4.4     149       85 16.3       170.76\nMichigan         12.1     255       74 35.1       170.76\nMinnesota         2.7      72       66 14.9       170.76\nMississippi      16.1     259       44 17.1       170.76\nMissouri          9.0     178       70 28.2       170.76\nMontana           6.0     109       53 16.4       170.76\nNebraska          4.3     102       62 16.5       170.76\nNevada           12.2     252       81 46.0       170.76\nNew Hampshire     2.1      57       56  9.5       170.76\nNew Jersey        7.4     159       89 18.8       170.76\nNew Mexico       11.4     285       70 32.1       170.76\nNew York         11.1     254       86 26.1       170.76\nNorth Carolina   13.0     337       45 16.1       170.76\nNorth Dakota      0.8      45       44  7.3       170.76\nOhio              7.3     120       75 21.4       170.76\nOklahoma          6.6     151       68 20.0       170.76\nOregon            4.9     159       67 29.3       170.76\nPennsylvania      6.3     106       72 14.9       170.76\nRhode Island      3.4     174       87  8.3       170.76\nSouth Carolina   14.4     279       48 22.5       170.76\nSouth Dakota      3.8      86       45 12.8       170.76\nTennessee        13.2     188       59 26.9       170.76\nTexas            12.7     201       80 25.5       170.76\nUtah              3.2     120       80 22.9       170.76\nVermont           2.2      48       32 11.2       170.76\nVirginia          8.5     156       63 20.7       170.76\nWashington        4.0     145       73 26.2       170.76\nWest Virginia     5.7      81       39  9.3       170.76\nWisconsin         2.6      53       66 10.8       170.76\nWyoming           6.8     161       60 15.6       170.76\n\n\nNotice that the new column contains the mean for all rows.\nWe may also wish to categorize rows based on their relative Assault data. How about assault lower than the mean assault?\n\nUSArrests |&gt;\n  mutate(Lower_than_Mean_Assault = Assault &lt; mean(Assault))\n\n               Murder Assault UrbanPop Rape Lower_than_Mean_Assault\nAlabama          13.2     236       58 21.2                   FALSE\nAlaska           10.0     263       48 44.5                   FALSE\nArizona           8.1     294       80 31.0                   FALSE\nArkansas          8.8     190       50 19.5                   FALSE\nCalifornia        9.0     276       91 40.6                   FALSE\nColorado          7.9     204       78 38.7                   FALSE\nConnecticut       3.3     110       77 11.1                    TRUE\nDelaware          5.9     238       72 15.8                   FALSE\nFlorida          15.4     335       80 31.9                   FALSE\nGeorgia          17.4     211       60 25.8                   FALSE\nHawaii            5.3      46       83 20.2                    TRUE\nIdaho             2.6     120       54 14.2                    TRUE\nIllinois         10.4     249       83 24.0                   FALSE\nIndiana           7.2     113       65 21.0                    TRUE\nIowa              2.2      56       57 11.3                    TRUE\nKansas            6.0     115       66 18.0                    TRUE\nKentucky          9.7     109       52 16.3                    TRUE\nLouisiana        15.4     249       66 22.2                   FALSE\nMaine             2.1      83       51  7.8                    TRUE\nMaryland         11.3     300       67 27.8                   FALSE\nMassachusetts     4.4     149       85 16.3                    TRUE\nMichigan         12.1     255       74 35.1                   FALSE\nMinnesota         2.7      72       66 14.9                    TRUE\nMississippi      16.1     259       44 17.1                   FALSE\nMissouri          9.0     178       70 28.2                   FALSE\nMontana           6.0     109       53 16.4                    TRUE\nNebraska          4.3     102       62 16.5                    TRUE\nNevada           12.2     252       81 46.0                   FALSE\nNew Hampshire     2.1      57       56  9.5                    TRUE\nNew Jersey        7.4     159       89 18.8                    TRUE\nNew Mexico       11.4     285       70 32.1                   FALSE\nNew York         11.1     254       86 26.1                   FALSE\nNorth Carolina   13.0     337       45 16.1                   FALSE\nNorth Dakota      0.8      45       44  7.3                    TRUE\nOhio              7.3     120       75 21.4                    TRUE\nOklahoma          6.6     151       68 20.0                    TRUE\nOregon            4.9     159       67 29.3                    TRUE\nPennsylvania      6.3     106       72 14.9                    TRUE\nRhode Island      3.4     174       87  8.3                   FALSE\nSouth Carolina   14.4     279       48 22.5                   FALSE\nSouth Dakota      3.8      86       45 12.8                    TRUE\nTennessee        13.2     188       59 26.9                   FALSE\nTexas            12.7     201       80 25.5                   FALSE\nUtah              3.2     120       80 22.9                    TRUE\nVermont           2.2      48       32 11.2                    TRUE\nVirginia          8.5     156       63 20.7                    TRUE\nWashington        4.0     145       73 26.2                    TRUE\nWest Virginia     5.7      81       39  9.3                    TRUE\nWisconsin         2.6      53       66 10.8                    TRUE\nWyoming           6.8     161       60 15.6                    TRUE\n\n\nTRUE and False make terrible variable levels, however. Using ifelse(), we will specify conditions for categorization. For example, make rows that are below the mean take on a value, else/otherwise, make the rows a different value.\nExample:\nifelse(Assault &lt; Mean_Assault, \"Below\", \"Equal or Above\"))\nIf the Assault value is &lt; Mean_Assault, assign the row a value of \"Below\", else, assign \"Equal or Above\". Let’s use ifelse() to create a name-value pair\nRelative_Assult = ifelse(Assault &lt; Mean_Assault, \"Below\", \"Equal or Above\"))\n\nUSArrests |&gt;\n  mutate(Mean_Assault = mean(Assault), \n         Relative_Assult = ifelse(Assault &lt; Mean_Assault, \"Below\", \"Equal or Above\")\n         )\n\n               Murder Assault UrbanPop Rape Mean_Assault Relative_Assult\nAlabama          13.2     236       58 21.2       170.76  Equal or Above\nAlaska           10.0     263       48 44.5       170.76  Equal or Above\nArizona           8.1     294       80 31.0       170.76  Equal or Above\nArkansas          8.8     190       50 19.5       170.76  Equal or Above\nCalifornia        9.0     276       91 40.6       170.76  Equal or Above\nColorado          7.9     204       78 38.7       170.76  Equal or Above\nConnecticut       3.3     110       77 11.1       170.76           Below\nDelaware          5.9     238       72 15.8       170.76  Equal or Above\nFlorida          15.4     335       80 31.9       170.76  Equal or Above\nGeorgia          17.4     211       60 25.8       170.76  Equal or Above\nHawaii            5.3      46       83 20.2       170.76           Below\nIdaho             2.6     120       54 14.2       170.76           Below\nIllinois         10.4     249       83 24.0       170.76  Equal or Above\nIndiana           7.2     113       65 21.0       170.76           Below\nIowa              2.2      56       57 11.3       170.76           Below\nKansas            6.0     115       66 18.0       170.76           Below\nKentucky          9.7     109       52 16.3       170.76           Below\nLouisiana        15.4     249       66 22.2       170.76  Equal or Above\nMaine             2.1      83       51  7.8       170.76           Below\nMaryland         11.3     300       67 27.8       170.76  Equal or Above\nMassachusetts     4.4     149       85 16.3       170.76           Below\nMichigan         12.1     255       74 35.1       170.76  Equal or Above\nMinnesota         2.7      72       66 14.9       170.76           Below\nMississippi      16.1     259       44 17.1       170.76  Equal or Above\nMissouri          9.0     178       70 28.2       170.76  Equal or Above\nMontana           6.0     109       53 16.4       170.76           Below\nNebraska          4.3     102       62 16.5       170.76           Below\nNevada           12.2     252       81 46.0       170.76  Equal or Above\nNew Hampshire     2.1      57       56  9.5       170.76           Below\nNew Jersey        7.4     159       89 18.8       170.76           Below\nNew Mexico       11.4     285       70 32.1       170.76  Equal or Above\nNew York         11.1     254       86 26.1       170.76  Equal or Above\nNorth Carolina   13.0     337       45 16.1       170.76  Equal or Above\nNorth Dakota      0.8      45       44  7.3       170.76           Below\nOhio              7.3     120       75 21.4       170.76           Below\nOklahoma          6.6     151       68 20.0       170.76           Below\nOregon            4.9     159       67 29.3       170.76           Below\nPennsylvania      6.3     106       72 14.9       170.76           Below\nRhode Island      3.4     174       87  8.3       170.76  Equal or Above\nSouth Carolina   14.4     279       48 22.5       170.76  Equal or Above\nSouth Dakota      3.8      86       45 12.8       170.76           Below\nTennessee        13.2     188       59 26.9       170.76  Equal or Above\nTexas            12.7     201       80 25.5       170.76  Equal or Above\nUtah              3.2     120       80 22.9       170.76           Below\nVermont           2.2      48       32 11.2       170.76           Below\nVirginia          8.5     156       63 20.7       170.76           Below\nWashington        4.0     145       73 26.2       170.76           Below\nWest Virginia     5.7      81       39  9.3       170.76           Below\nWisconsin         2.6      53       66 10.8       170.76           Below\nWyoming           6.8     161       60 15.6       170.76           Below\n\n\nBu you could also combine the steps together:\n\nUSArrests |&gt;\n  mutate(Relative_Assult = ifelse(Assault &lt; mean(Assault), \"Below\", \"Equal or Above\"))\n\n               Murder Assault UrbanPop Rape Relative_Assult\nAlabama          13.2     236       58 21.2  Equal or Above\nAlaska           10.0     263       48 44.5  Equal or Above\nArizona           8.1     294       80 31.0  Equal or Above\nArkansas          8.8     190       50 19.5  Equal or Above\nCalifornia        9.0     276       91 40.6  Equal or Above\nColorado          7.9     204       78 38.7  Equal or Above\nConnecticut       3.3     110       77 11.1           Below\nDelaware          5.9     238       72 15.8  Equal or Above\nFlorida          15.4     335       80 31.9  Equal or Above\nGeorgia          17.4     211       60 25.8  Equal or Above\nHawaii            5.3      46       83 20.2           Below\nIdaho             2.6     120       54 14.2           Below\nIllinois         10.4     249       83 24.0  Equal or Above\nIndiana           7.2     113       65 21.0           Below\nIowa              2.2      56       57 11.3           Below\nKansas            6.0     115       66 18.0           Below\nKentucky          9.7     109       52 16.3           Below\nLouisiana        15.4     249       66 22.2  Equal or Above\nMaine             2.1      83       51  7.8           Below\nMaryland         11.3     300       67 27.8  Equal or Above\nMassachusetts     4.4     149       85 16.3           Below\nMichigan         12.1     255       74 35.1  Equal or Above\nMinnesota         2.7      72       66 14.9           Below\nMississippi      16.1     259       44 17.1  Equal or Above\nMissouri          9.0     178       70 28.2  Equal or Above\nMontana           6.0     109       53 16.4           Below\nNebraska          4.3     102       62 16.5           Below\nNevada           12.2     252       81 46.0  Equal or Above\nNew Hampshire     2.1      57       56  9.5           Below\nNew Jersey        7.4     159       89 18.8           Below\nNew Mexico       11.4     285       70 32.1  Equal or Above\nNew York         11.1     254       86 26.1  Equal or Above\nNorth Carolina   13.0     337       45 16.1  Equal or Above\nNorth Dakota      0.8      45       44  7.3           Below\nOhio              7.3     120       75 21.4           Below\nOklahoma          6.6     151       68 20.0           Below\nOregon            4.9     159       67 29.3           Below\nPennsylvania      6.3     106       72 14.9           Below\nRhode Island      3.4     174       87  8.3  Equal or Above\nSouth Carolina   14.4     279       48 22.5  Equal or Above\nSouth Dakota      3.8      86       45 12.8           Below\nTennessee        13.2     188       59 26.9  Equal or Above\nTexas            12.7     201       80 25.5  Equal or Above\nUtah              3.2     120       80 22.9           Below\nVermont           2.2      48       32 11.2           Below\nVirginia          8.5     156       63 20.7           Below\nWashington        4.0     145       73 26.2           Below\nWest Virginia     5.7      81       39  9.3           Below\nWisconsin         2.6      53       66 10.8           Below\nWyoming           6.8     161       60 15.6           Below"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#understanding-filtering-operators",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#understanding-filtering-operators",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Understanding Filtering Operators",
    "text": "Understanding Filtering Operators\nWe will filter data using filter() from {dplyr}\nfilter(.data, \n       ...\n       )\nParameters/Arguments:\n\n.data: a data frame\n...: expressions that return a logical value (TRUE or FALSE)\n\nNOTE:: Filtering cases using the dplyr::filter() verbs works by removing rows that do not match a specific criterion and then by returning the data frame that omits the mismatched condition. It keeps only rows that are TRUE (match) your specification.\nSome useful filtering operators and functions include: ==, &gt;, &gt;=, &, |, !, xor(), c(), is.na(), between(), near()."
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filtering-using-filter",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filtering-using-filter",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filtering Using filter()",
    "text": "Filtering Using filter()\nWe will work with different data frames because the the nature of their contents.\nWhat does the data frame look like again?\n\nDAT\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\nRow/Observations/Cases can be filtered to “include” only certain matched conditions or can be filtered to “exclude” by negating those matched conditions. If the column variable Sex is in the data frame and cases are 'male', 'men', 'female', 'women', 'neither', NA, etc., you can specify the column Sex variable and then the row matching condition(s).\n\nFiltering Matches to a Specific Character Value\nThe first argument in dplyr::filter() is a data frame, and the function all dplyr::filter(DAT, Sex == 'female') will filter the data frame named DAT to include rows for which the sex column equals 'female'. In other words, TRUE rows.\n\ndplyr::filter(DAT, \n              Sex == 'female'\n              )\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nSimilarly, the function call dplyr::filter(., Sex == 'male') can be read “filter the data frame to include rows for which the value of Sex == 'male' is TRUE”.\nMore flexibly, however, you could specify a vector containing acceptable strings using c(). dplyr::filter(., Sex %in% c('male')) filters the rows to include only those for which the value for sex is in the string vector which includes a single string,'male' whereas dplyr::filter(., Sex %in% c('male', 'Man')) filters the rows to include only those for which the value for Sex is in the string vector which includes 'male' and 'Man'. Cases containing 'Male', 'Men' (R is a case-sensitive language), or 'female', for example, will not be included in the returned data frame because they do not match values in the string vector.\n\n\nFiltering by a Relative Value\n\nUSArrests |&gt;\n  filter(Murder &gt; 10)\n\n               Murder Assault UrbanPop Rape\nAlabama          13.2     236       58 21.2\nFlorida          15.4     335       80 31.9\nGeorgia          17.4     211       60 25.8\nIllinois         10.4     249       83 24.0\nLouisiana        15.4     249       66 22.2\nMaryland         11.3     300       67 27.8\nMichigan         12.1     255       74 35.1\nMississippi      16.1     259       44 17.1\nNevada           12.2     252       81 46.0\nNew Mexico       11.4     285       70 32.1\nNew York         11.1     254       86 26.1\nNorth Carolina   13.0     337       45 16.1\nSouth Carolina   14.4     279       48 22.5\nTennessee        13.2     188       59 26.9\nTexas            12.7     201       80 25.5\n\n\nThose rows with Murder above 10 will be retained, others removed.\n\n\nFiltering by a Specific Value\n\nUSArrests |&gt;\n  filter(Murder == 12.1)\n\n         Murder Assault UrbanPop Rape\nMichigan   12.1     255       74 35.1\n\n\nThose rows with Murder == 12.1 will be retained.\nUsing a previous example with this data set, we can filter based on a character variable if we had one. Let’s add one.\n\nUSArrests |&gt;\n  mutate(Relative_Murder = ifelse(Murder &lt; mean(Murder), \"Below\", \"Equal or Above\")) |&gt;\n  filter(Relative_Murder == \"Below\")\n\n              Murder Assault UrbanPop Rape Relative_Murder\nConnecticut      3.3     110       77 11.1           Below\nDelaware         5.9     238       72 15.8           Below\nHawaii           5.3      46       83 20.2           Below\nIdaho            2.6     120       54 14.2           Below\nIndiana          7.2     113       65 21.0           Below\nIowa             2.2      56       57 11.3           Below\nKansas           6.0     115       66 18.0           Below\nMaine            2.1      83       51  7.8           Below\nMassachusetts    4.4     149       85 16.3           Below\nMinnesota        2.7      72       66 14.9           Below\nMontana          6.0     109       53 16.4           Below\nNebraska         4.3     102       62 16.5           Below\nNew Hampshire    2.1      57       56  9.5           Below\nNew Jersey       7.4     159       89 18.8           Below\nNorth Dakota     0.8      45       44  7.3           Below\nOhio             7.3     120       75 21.4           Below\nOklahoma         6.6     151       68 20.0           Below\nOregon           4.9     159       67 29.3           Below\nPennsylvania     6.3     106       72 14.9           Below\nRhode Island     3.4     174       87  8.3           Below\nSouth Dakota     3.8      86       45 12.8           Below\nUtah             3.2     120       80 22.9           Below\nVermont          2.2      48       32 11.2           Below\nWashington       4.0     145       73 26.2           Below\nWest Virginia    5.7      81       39  9.3           Below\nWisconsin        2.6      53       66 10.8           Below\nWyoming          6.8     161       60 15.6           Below\n\n\n\n\nFiltering Using on a Function\n\nUSArrests |&gt;\n  filter(Murder &gt; mean(Murder))\n\n               Murder Assault UrbanPop Rape\nAlabama          13.2     236       58 21.2\nAlaska           10.0     263       48 44.5\nArizona           8.1     294       80 31.0\nArkansas          8.8     190       50 19.5\nCalifornia        9.0     276       91 40.6\nColorado          7.9     204       78 38.7\nFlorida          15.4     335       80 31.9\nGeorgia          17.4     211       60 25.8\nIllinois         10.4     249       83 24.0\nKentucky          9.7     109       52 16.3\nLouisiana        15.4     249       66 22.2\nMaryland         11.3     300       67 27.8\nMichigan         12.1     255       74 35.1\nMississippi      16.1     259       44 17.1\nMissouri          9.0     178       70 28.2\nNevada           12.2     252       81 46.0\nNew Mexico       11.4     285       70 32.1\nNew York         11.1     254       86 26.1\nNorth Carolina   13.0     337       45 16.1\nSouth Carolina   14.4     279       48 22.5\nTennessee        13.2     188       59 26.9\nTexas            12.7     201       80 25.5\nVirginia          8.5     156       63 20.7"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-using-na.omit",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-using-na.omit",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter using na.omit()",
    "text": "Filter using na.omit()\n\nDAT |&gt;\n  na.omit()           # omit any rows with NAs \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n3 102    Male  27     yes\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-using-is.na-and-is.na",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-using-is.na-and-is.na",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter using is.na() and !is.na()",
    "text": "Filter using is.na() and !is.na()\n\nDAT |&gt;\n  filter(is.na(Sex))       # keep NAs by variable\n\n   Id  Sex Age Renting\n1 103 &lt;NA&gt;  40    &lt;NA&gt;\n\n\nBut your goal may likely be to keep everything that is not NA:\n\nDAT |&gt;\n  filter(!is.na(Sex))      # remove NAs by variable\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 104     man  44      no\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nAnd filter step-by-step for each variable using |&gt; and separate function calls:\n\nDAT |&gt;\n  filter(!is.na(Sex)) |&gt;\n  filter(!is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nSo why use separate lines of code if you can use & all in one line? One reason is that separate function calls written as separate lines of code make code inclusion/exclusion extremely easy.\nComment out what you don’t want using #:\n\nDAT |&gt;\n  #filter(., !is.na(Sex)) |&gt;\n  filter(!is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-using-complete.cases",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-using-complete.cases",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter using complete.cases()",
    "text": "Filter using complete.cases()\nThe complete.cases() function returns a logical vector for which TRUE reflects the row has complete information and no missing cases. Using complete.cases() along with filter(), you would retain all rows TRUE rows.\n\nDAT %&gt;%\n  dplyr::filter(complete.cases(.))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#removing-duplicate-rows-using-distinct",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#removing-duplicate-rows-using-distinct",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Removing duplicate rows using distinct()",
    "text": "Removing duplicate rows using distinct()\nWe will examine some other filtering methods that do not use filter() specifically but that which perform filtering operations.\n\ndplyr::distinct(): remove duplicate rows\ndplyr::distinct(., column): remove duplicate rows by specific column\nna.omit(): remove any row with NA’s (missing values)\n\nLet’s use the simple DAT data frame.\n\nDAT\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\nRemember that data frames are composed of rows and columns. As discussed previously we can subset in base R to illustrate a point.\nRow row 1, all columns:\n\nDAT[1,]\n\n   Id  Sex Age Renting\n1 100 male  25     yes\n\n\nRow row 6, all columns:\n\nDAT[6,]\n\n   Id  Sex Age Renting\n6 100 male  25     yes\n\n\nNotice that rows 1 and 6 are the same person (e.g., Id) and have exactly the same data for all variables. If we compare the two logically, we will confirm that all is TRUE.\n\nDAT[1,] == DAT[6,]\n\n    Id  Sex  Age Renting\n1 TRUE TRUE TRUE    TRUE\n\n\nYou clearly do not want duplicates of data. So let’s just remove any rows that are identical using distinct()\n\nRemoving Duplicates Across All Variables\n\nDAT |&gt;\n  distinct()       # Remove exact duplicates across all columns\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nIf you know each row is unique based on a variable in the data frame, you can also use distinct() to remove duplicates for a specific variable. Make sure that this variable specification is actually one that you would not want duplicates of.\n\n\nRemoving Duplicates Based on a Variable\n\nDAT |&gt;           \n  distinct(Id)     #  Remove duplicates by variable; passes unique values for data frame\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 105\n\n\nBut this function simply returns the unique values in Id. To retain the variables, set .keep_all = T. If you want to remove duplicates and assign the cleaned data frame to an object, you would likely want to keep all of your variables.\n\nDAT |&gt;             \n  distinct(Id, \n           .keep_all = T\n           ) #\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nNotice, however, this only removed the last instance or Id == 100. Which row to include is a judgment call. The first, the last, neither, the average? Is there a correct answer?"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-cases-using",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-cases-using",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter Cases using ==",
    "text": "Filter Cases using ==\nFilter rows for which the Sex variable is equal to the string 'female':\n\nDAT |&gt;\n  dplyr::filter(Sex == 'female')\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is not equal to the string 'female':\n\nDAT |&gt;\n  dplyr::filter(Sex != 'female')\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nFilter rows for which the Sex variable is equal to the string 'female' AND Age is greater than the numeric 27:\n\nDAT |&gt;\n  dplyr::filter(Sex == 'female' & Age &gt; 27) # this \"AND\" that\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is equal to the string 'female' OR Age is greater than the numeric 27:\n\nDAT |&gt;\n  dplyr::filter(Sex == 'female' | Age &gt; 27) # this \"OR\" that\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nA cleaner method involves separate lines of code. Although cleaner, this will not allow the “OR” option because the data frame that is returned from the first filter() is passed to the second filter() and all cases other than \"female\" have already been removed from the data frame.\n\nDAT |&gt;\n  dplyr::filter(Sex == 'female') |&gt;    # keep female (and add another pipe)\n  dplyr::filter(Age &gt;= 27)             # keep only those equal to or older than 27\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-and-or-or",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-and-or-or",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter by < and > or <= or >=",
    "text": "Filter by &lt; and &gt; or &lt;= or &gt;=\nKeep those less than:\n\nDAT |&gt; \n  dplyr::filter(Age &lt; 40)   \n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 102   Male  27     yes\n4 100   male  25     yes\n\n\nKeep older than:\n\nDAT |&gt; \n  dplyr::filter(Age &gt; 40)  \n\n   Id Sex Age Renting\n1 104 man  44      no\n\n\nKeep equal to or older than:\n\nDAT |&gt; \n  dplyr::filter(Age &gt;= 40)  \n\n   Id     Sex Age Renting\n1 103    &lt;NA&gt;  40    &lt;NA&gt;\n2 104     man  44      no\n3 105 neither  40     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-cases-by-conditional-x-or-y-using-operator",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-cases-by-conditional-x-or-y-using-operator",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter Cases by Conditional X or Y Using | Operator…",
    "text": "Filter Cases by Conditional X or Y Using | Operator…\nUsing the “OR” operator, |, cases can be included if “this” OR “that” condition.\nFilter numbers:\n\nDAT |&gt;\n  dplyr::filter(Age == 25 | Age == 40)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 100    male  25     yes\n4 105 neither  40     yes\n\n\nFilter characters:\n\nDAT |&gt;\n  dplyr::filter(Sex == 'male' | Sex == 'female')\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes\n\n\nAlthough dplyr::filter(sex %in% c('male', 'female')) would be easier.\nFilter rows of variables of both types:\n\nDAT |&gt;\n  dplyr::filter(Sex == 'male' | Age == 27)  \n\n   Id  Sex Age Renting\n1 100 male  25     yes\n2 102 Male  27     yes\n3 100 male  25     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-cases-between-values-with-between",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-cases-between-values-with-between",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter Cases Between Values with between()",
    "text": "Filter Cases Between Values with between()\nBetween ages 25 and 33:\n\nDAT |&gt;\n  dplyr::filter(between(Age, 27, 33))\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n2 102   Male  27     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter by range using the %in% operator (this is IN meaning in)",
    "text": "Filter by range using the %in% operator (this is IN meaning in)\nThough less flexible than using between(), %in% may be easier to remember:\n\nDAT |&gt;\n  dplyr::filter(Age %in% 20:43)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nOne’s age is in the range from 20 through 43.\nIf a vector object is already defined (e.g., my_levels = c('male', 'female')), you can use that for filtering also. Such approaches are useful when data manipulation involves reusing a reference as it simplifies coding and reduces errors because the specification is defined only once.\n\nmy_levels = c('male', 'female')\n\nDAT |&gt;\n  dplyr::filter(Sex %in% my_levels)\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-exclusion",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-exclusion",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter by exclusion",
    "text": "Filter by exclusion\nWhen inclusion of variables is inappropriate, exclusion of them may be useful. The ! operator means “NOT” in R so you can use that to accomplish the opposite of the statement. For example, dplyr::filter(., !sex %in% c('male', NA)) will “filter the data frame to include rows in the sex column for which the value is NOT in the vector”.\nExclude rows in the Sex variable that are NA or 'male':\n\nDAT |&gt;\n  dplyr::filter(!Sex %in% c('male', NA))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nExclude rows in the Sex variable that are Men or 'male':\n\nDAT |&gt;\n  dplyr::filter(!Sex %in% c('male', 'Men'))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 103    &lt;NA&gt;  40    &lt;NA&gt;\n4 104     man  44      no\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-conditional-x-and-y-using-operator",
    "href": "modules/08_manipulating_data_selecting_filtering_mutating.html#filter-by-conditional-x-and-y-using-operator",
    "title": "Selecting, Filtering, & Mutating",
    "section": "Filter by conditional X and Y using & operator…",
    "text": "Filter by conditional X and Y using & operator…\nBy range:\n\nDAT |&gt;\n  dplyr::filter(Id &gt;= 102 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 102    Male  27     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 105 neither  40     yes\n\n\n\nDAT |&gt;\n  dplyr::filter(Age &gt;= 20 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nNote: Age 20:43 won’t work. Can you figure out why?"
  },
  {
    "objectID": "modules/10_summarizing_data.html",
    "href": "modules/10_summarizing_data.html",
    "title": "Summarizing Data",
    "section": "",
    "text": "This module describes how to perform statistical transformations on data, including producing data summaries. In order to summarize data, we will again use {dplyr}. The way data are summarized will influence the way the data can be modeled as statistical models typically rely on understanding how predictor variables (independent) can account for variability in outcome variables (dependent). Eliminating variability in data by aggregating will affect the model you can use as well as the statistical inference draw from that statistical model. We will also discuss differences in grouping structure for dplyr::mutate() and dplyr::summarize() that will affect both variable computation and plot creation.\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\nHuber: Summaries\n\n\n\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. You will practice using the concepts by working on activities. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence.\n\n\n\n\nProvided in class:\nview_html(): for viewing data frames in html format\nYou can access this remotely from:\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/fods24/main/r/functions/view_html.R\")\n\nOr from your own project work space by loading functions in /r/functions.\n\n\n\n\n{dplyr} 1.1.4: for selecting, filtering, and mutating\n\n\n\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "modules/10_summarizing_data.html#supplementary-readings",
    "href": "modules/10_summarizing_data.html#supplementary-readings",
    "title": "Summarizing Data",
    "section": "",
    "text": "Huber: Summaries\n\n\n\nRead through the module. You can use the R console or open up an R Markdown (e.g., .Rmd) file to follow along interactively. If you instead prefer to simply read through the content so that you can understand the concepts without coding, that is fine too. You will practice using the concepts by working on activities. Reading the module will provide you with confidence working on those activities and prevent you from feeling lost while completing activities. Testing out some code may provide you more confidence."
  },
  {
    "objectID": "modules/10_summarizing_data.html#external-functions",
    "href": "modules/10_summarizing_data.html#external-functions",
    "title": "Summarizing Data",
    "section": "",
    "text": "Provided in class:\nview_html(): for viewing data frames in html format\nYou can access this remotely from:\n\nsource(\"https://raw.githubusercontent.com/slicesofdata/fods24/main/r/functions/view_html.R\")\n\nOr from your own project work space by loading functions in /r/functions."
  },
  {
    "objectID": "modules/10_summarizing_data.html#libraries",
    "href": "modules/10_summarizing_data.html#libraries",
    "title": "Summarizing Data",
    "section": "",
    "text": "{dplyr} 1.1.4: for selecting, filtering, and mutating"
  },
  {
    "objectID": "modules/10_summarizing_data.html#load-libraries",
    "href": "modules/10_summarizing_data.html#load-libraries",
    "title": "Summarizing Data",
    "section": "",
    "text": "library(dplyr)"
  },
  {
    "objectID": "modules/10_summarizing_data.html#summarizing-as-a-constant",
    "href": "modules/10_summarizing_data.html#summarizing-as-a-constant",
    "title": "Summarizing Data",
    "section": "Summarizing as a Constant",
    "text": "Summarizing as a Constant\nWhen piping code, the data frame will be inherited; the parameter and argument can be omitted. You will need to pass the expressions for the summary, however. Like mutate() The expression will require a variable name as well as a value or function.\nAlthough summarize() can create variables like mutate(), it does so by grouping the data in some way. We will cover using summarize() with group_by() to group data but for now, you can see grouping happens automatically, making summarize() a different function than mutate(). The functions serve different purposes. A good rule of thumb for remembering the differences is that mutate() is used to add column variables to a data frame to make it bigger and summarize() is used to reduce the data frame by summarizing the data within it.\nIf we assign a variable name a value, we see that the data frame that is returned is now reduced to a single row. Specifically, the default operation is that summarize() groups all rows of the data frame together.\n\nDATA |&gt;\n  summarize(my_new_var = 1)\n\n  my_new_var\n1          1\n\n\nClearly, this is a ridiculous summary of the data. Let’s do something that makes more sense."
  },
  {
    "objectID": "modules/10_summarizing_data.html#summarizing-with-a-function",
    "href": "modules/10_summarizing_data.html#summarizing-with-a-function",
    "title": "Summarizing Data",
    "section": "Summarizing with a Function",
    "text": "Summarizing with a Function\nYou will likely want to summarize the data in some way, for example, by obtaining the mean, sum, count, standard deviation, or some other statistic from the data. If we wanted to obtain the mean of some variable in the data frame, we would need to specify the variable that we want to summarize, the function for how to summarize that variable and then we would want to specify the variable name for the data frame to contain.\nGeneral case:\nsummarized_var = the_function(my_var)\nSpecific case:\nmean = mean(my_var)\nLet’s summarize the performance Score in the data frame. In the example below, we summarize data by creating a new variable which is set to represent some data summary technique. In essence, summarizing is for descriptive statistics. Using mean(), we can summarize the data by taking the mean of the Score variable.\n\nDATA |&gt;\n  summarize(bob = mean(Score))\n\n       bob\n1 76.54545\n\n\nWe see that the returned data frame contains only one row. By default, the data frame has been reduced to the mean across all rows. The column variable is named bob. Let’s make the variable in the returned data frame make more sense.\n\nDATA |&gt;\n  summarize(mean_score = mean(Score))\n\n  mean_score\n1   76.54545\n\n\nNotice what is returned is a single value reflecting the mean of all the data in the data frame. We could have obtained the same without using {dplyr}.\n\nmean(DATA$Score)        # $ notation\n\n[1] 76.54545\n\n\nHowever, we lose flexibility of easily adding new summary procedures using this approach. Instead, summarize() allows for multiple name-value pair functions."
  },
  {
    "objectID": "modules/10_summarizing_data.html#summarizing-with-multiple-functions",
    "href": "modules/10_summarizing_data.html#summarizing-with-multiple-functions",
    "title": "Summarizing Data",
    "section": "Summarizing with Multiple Functions",
    "text": "Summarizing with Multiple Functions\nLet’s create the mean and the standard deviation of Score using mean(). Because you will use mean() often, you should understand how it works, so let’s first look at its parameters and default arguments more carefully.\nmean(x, trim = 0, na.rm = FALSE, ...)\nBy default, the data are not trimmed and NA values are not removed. If NAs exist in your vector, the function will break unless you pass TRUE as the argument to it, na.rm = TRUE. The same is true for sd() for computing the standard deviation.\nLet’s summarize Score using both functions. We see that the data frame has one row and two columns reflecting the variables specified in the function.\n\nDATA |&gt;\n  summarise(mean = mean(Score, na.rm = T),\n            sd   = sd(Score, na.rm = T)\n            )\n\n      mean       sd\n1 76.54545 10.56753\n\n\nYou see the basic operation of summarize(). By default, variables are summarized using functions that aggregate the data across all rows. The resulting summary value is entered as column specified by the named we provided. Of course, however, we may not want to aggregate all of the data as a single group. Rather, we may wish to summarize by grouping data based on subgroups, factors, etc."
  },
  {
    "objectID": "modules/10_summarizing_data.html#data-aggregation-using-group_by",
    "href": "modules/10_summarizing_data.html#data-aggregation-using-group_by",
    "title": "Summarizing Data",
    "section": "Data aggregation using group_by()",
    "text": "Data aggregation using group_by()\nLet’s say we want to group the data by School and then summarize. The returned data frame now contains two columns, one for the grouping variable followed by a second for the specification in summarize(). Importantly, the grouping variables will always be organized in the data frame to the left of variables created in the summary.\n\nDATA |&gt;\n  group_by(School) |&gt;\n  summarize(Score = mean(Score))   # get the school level aggregated data\n\n# A tibble: 5 × 2\n  School Score\n  &lt;chr&gt;  &lt;dbl&gt;\n1 A       82.5\n2 B       79.5\n3 C       87  \n4 D       62.5\n5 E       66  \n\n\nLet’s say we try to determine mean performance for “all students” if we had the data aggregated as the school level and not the individual level. As a reminder, the mean across all rows in the data frame was rmean(DATA$Score, na.rm = T)`.\nIf we want to summarize the data frame that was summarized, we might assume that we can pipe the data to another add another summarize().\n\nDATA |&gt;\n  group_by(School) |&gt;                # group by school\n  summarize(Score = mean(Score)) |&gt;  # get the school level aggregated data\n  summarize(Score = mean(Score))     # then calculate average across all schools\n\n# A tibble: 1 × 1\n  Score\n  &lt;dbl&gt;\n1  75.5\n\n\nNote: If you noticed and wonder why the mean value returned here differs from rmean(DATA$Score, na.rm = T)`, make a mental note. We will address that later.\nLet’s say we try to determine average performance for “all students” if we had the data aggregated as the district level and not the individual level.\n\nDATA |&gt;\n  group_by(District) |&gt;                # group by district\n  summarize(Score = mean(Score)) |&gt;    # get the district level aggregated data\n  summarize(Score = mean(Score))       # then calculate average across all districts\n\n# A tibble: 1 × 1\n  Score\n  &lt;dbl&gt;\n1  77.4\n\n\nSo what’s the average performance for students? Well, that interpretation differs based on how values are treated. At the highest level, all students’ Scores are weighed equally. Each student contributes to the data in the same way. When aggregated by School, each school contributes to the calculation equally, even if the number of bodies per school differs. And finally, when data are aggregated at the District level, all districts are treated equally in the calculation independent on the number of schools in a district. Only with weighting means would you end up with the same average performance.\nMeasures of variability in the data, however, reveal something else. Schools differ in variability and schools within districts vary as well. Depending on the level of aggregation, you may never notice interesting patterns in data that lead to questions to investigate and later policies to change. For example, addressing a school that is left behind others or a district that is left behind others. Aggregation can also lead to inefficient allocations of resources. If one school in a district needs help rather than all schools in the district needing help, the cost may differ substantially.\n\nstd_error &lt;- function(x) { sd(na.omit(x)) / sqrt(length(na.omit(x))) }\n\nUse std_error() in summary:\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Var = var(Score),\n            SD  = sd(Score),\n            SEM = std_error(Score),\n            min = min(Score),\n            max = max(Score)\n  ) |&gt; mutate(range = max - min)\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 8\n# Groups:   School [5]\n  School District   Var    SD   SEM   min   max range\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      12.5 3.54   2.5     80    85     5\n2 B      West       0.5 0.707  0.5     79    80     1\n3 C      East      28   5.29   3.06    81    91    10\n4 D      North     12.5 3.54   2.5     60    65     5\n5 E      North      2   1.41   1       65    67     2"
  },
  {
    "objectID": "modules/10_summarizing_data.html#grouping-structure-of-group_by-and-mutate",
    "href": "modules/10_summarizing_data.html#grouping-structure-of-group_by-and-mutate",
    "title": "Summarizing Data",
    "section": "Grouping structure of group_by() and mutate()",
    "text": "Grouping structure of group_by() and mutate()\nLet’s mutate() the mean for Score after sub-setting with group_by().\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  mutate(Score = mean(na.omit(Score)))\n\n# A tibble: 11 × 4\n# Groups:   School, District [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim           82.5 A      West    \n 2 Sally         82.5 A      West    \n 3 June          79.5 B      West    \n 4 Mildred       79.5 B      West    \n 5 Tilford       87   C      East    \n 6 Beavis        87   C      East    \n 7 Herman        87   C      East    \n 8 Peppa         62.5 D      North   \n 9 Kay           62.5 D      North   \n10 Jake          66   E      North   \n11 Name Missing  66   E      North   \n\n\nThere are two things to watch when using this mutate() following group_by().\n\n1. A Score will be assigned to each row/case or Student in the data frame.\n\nWhen schools and districts are grouped, each student in the same school will have the same assigned average value. All rows are maintained, none dropped.\n\n2. The returned tibble takes on a new structure.\n\nLooking at the feedback displayed in the console, you see the following report preceding the data.\n\n\nA tibble: 11 × 3\n# Groups:   School, District [5]\nYou also see this structure using glimpse().\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  mutate(Score = mean(na.omit(Score))) |&gt;\n  glimpse()\n\nRows: 11\nColumns: 4\nGroups: School, District [5]\n$ Student  &lt;chr&gt; \"Jim\", \"Sally\", \"June\", \"Mildred\", \"Tilford\", \"Beavis\", \"Herm…\n$ Score    &lt;dbl&gt; 82.5, 82.5, 79.5, 79.5, 87.0, 87.0, 87.0, 62.5, 62.5, 66.0, 6…\n$ School   &lt;chr&gt; \"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"E\", \"E\"\n$ District &lt;chr&gt; \"West\", \"West\", \"West\", \"West\", \"East\", \"East\", \"East\", \"Nort…\n\n\nRows: 11\nColumns: 3\nGroups: School, District [5]\nWhat does the [5] mean? Well, before we answer this, let’s use summarize()."
  },
  {
    "objectID": "modules/10_summarizing_data.html#grouping-structure-of-group_by-and-summarize",
    "href": "modules/10_summarizing_data.html#grouping-structure-of-group_by-and-summarize",
    "title": "Summarizing Data",
    "section": "Grouping structure of group_by() and summarize()",
    "text": "Grouping structure of group_by() and summarize()\nLet’s summarize() the mean for Score after sub-setting with group_by().\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nThere are two things to watch when using this summarize() following group_by().\n1. A Score average is assigned to each row/case or School in this aggregated data frame.\nWhen schools and districts are grouped, each school will have its own average value. Rows from the data frame are dropped as are columns that are not passed to group_by(). In this case, School, District, and the new variable, Score are returned.\n2. The returned tibble takes on a new structure.\nThe feedback in the console is a little more detailed here.\n`summarise()` has grouped output by 'School'. You can override using the `.groups` argument.\n# A tibble: 5 × 3\n# Groups:   School [5]\nYou see reference to overriding the grouping using .groups. According to the tidyverse documentation for grouping, this parameter “controls the grouping structure of the output. The historical behaviour of removing the right hand side grouping variable corresponds to .groups = \"drop_last\" without a message or .groups = NULL with a message (the default)”.\nYou have most likely paid little attention to this message. By default summarize() keeps the first grouping variable passed to group_by() in the returned tibble. This is why you see School referenced and not District or both variables. So, do you want your data frame to contain groups or no groups? Stated differently, do you just want that data summarized by your grouping variables and have a simple nxm data frame or do you want something more complex?\nTo see the structure better, let’s first look a the structure of DATA and then more closely at the summarized version.\n\nstr(DATA)\n\n'data.frame':   11 obs. of  4 variables:\n $ Student : chr  \"Jim\" \"Sally\" \"June\" \"Mildred\" ...\n $ Score   : num  80 85 79 80 81 91 89 60 65 67 ...\n $ School  : chr  \"A\" \"A\" \"B\" \"B\" ...\n $ District: chr  \"West\" \"West\" \"West\" \"West\" ...\n\n\nLet’s assign the summarized data frame to an object for inspection.\n\nDATA_SUM &lt;- \n  DATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\nFor DATA_SUM, the structure is different. In particular, you see reference to (S3: grouped_df/tbl_df/tbl/data.frame). This tells you that the data frame is not a simple nxm but contains groups. You could think of this as 3 nxm data frames organized together. For more details, see the dplyr documentation.\n\nstr(DATA_SUM)\n\ngropd_df [5 × 3] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ School  : chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n $ District: chr [1:5] \"West\" \"West\" \"East\" \"North\" ...\n $ Score   : num [1:5] 82.5 79.5 87 62.5 66\n - attr(*, \"groups\")= tibble [5 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ School: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ .rows : list&lt;int&gt; [1:5] \n  .. ..$ : int 1\n  .. ..$ : int 2\n  .. ..$ : int 3\n  .. ..$ : int 4\n  .. ..$ : int 5\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\n\ngroup_by() and summarize() with .groups\nWhen you group data using group_by() and then summarize(), the summary variables (e.g., mean) will result in a single row for each level of a single grouping variable. If there are more than one grouping variable, the additional grouping variable will be introduced to the data frame as a second column. The total number of rows in the data frame will be equal to the number of levels of group 1 x number of levels of group 2 if an only if each levels of group 1 has a corresponding level for group 2,\nfor example:\nsex   age    mean\nmen   young  x\nmen   old    x\nwomen young  x\nwomen old    x\nIf there is no pairing of levels in the data (e.g., no men who are old), that row will be omitted from the returned data frame.\nfor example:\nsex   age    mean\nmen   young  x\nwomen young  x\nwomen old    x\nrather than:\nsex   age    mean\nmen   young  x\nmen   old    NA\nwomen young  x\nwomen old    x\nYou really need to query ?dplyr::summarize to understand .groups, which controls the grouping of the returned data frame. This is also experimental to summarize(), so it might not be available in the future.\nParameters/Arguments:\nThere are four argument options:\n\n\"drop_last\": dropping the last level of grouping. This was the only supported option before version 1.0.0.\n\"drop\": All levels of grouping are dropped.\n\"keep\": Same grouping structure as .data.\n\"rowwise\": Each row is its own group.\n\nLet’s work through them individually and see how they work.\n\n.groups = \"drop_last\":\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"drop_last\"\n            )\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou will see that the grouping for District is not in the grouping structure because it was the last grouping.\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School   District   Score\n\n\n.groups = \"drop\":\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"drop\"\n            )\n\n# A tibble: 5 × 3\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou will see that all groups are dropped from the grouping structure.\n# A tibble: 5 × 3\n  School District Score\n\n\n.groups = \"keep\":\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"keep\"\n            )\n\n# A tibble: 5 × 3\n# Groups:   School, District [5]\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou will see that all groups are kept in the grouping structure.\n# A tibble: 5 × 3\n# Groups:   School, District [5]\n  School District Score\n\n\n.groups = \"rowwise\":\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"rowwise\"\n            )\n\n# A tibble: 5 × 3\n# Rowwise:  School, District\n  School District Score\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou will see that there are groups but they are not based on group_by().\n# A tibble: 5 × 3\n# Rowwise:  School, District\n  School District Score\nThe grouping structure always matters for subsequent computations. But with \"rowwise\" you will see this clearly. Following from above, let’s say we wanted to compute the mean across all of the Schools in the data frame returned by group_by() then summarize(). We add mutate(mean = mean(Score)) on a new line of our piped code block.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"rowwise\"\n            ) |&gt;\n  mutate(mean = mean(Score))\n\n# A tibble: 5 × 4\n# Rowwise:  School, District\n  School District Score  mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      82.5  82.5\n2 B      West      79.5  79.5\n3 C      East      87    87  \n4 D      North     62.5  62.5\n5 E      North     66    66  \n\n\nThe mean column does not contain a single mean replicated for each row in the data frame. Rather the grouping was per row, so each row has its one mean. The mean of a single value is, of course, itself.\n\n\nRevisiting \".groups = drop_last\":\nReturning to the default .groups structure, which is \"drop_last\", we can add the same mutate() to see what happens.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"drop_last\"\n            ) |&gt;\n  mutate(mean = mean(Score))\n\n# A tibble: 5 × 4\n# Groups:   School [5]\n  School District Score  mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      82.5  82.5\n2 B      West      79.5  79.5\n3 C      East      87    87  \n4 D      North     62.5  62.5\n5 E      North     66    66  \n\n\nThe mean column still has different values but they are replicated on rows with the same School group. This is because the data are grouped that way.\n\n\nRevisiting .groups = \"drop\":\nLet’s again add the same mutate() to see what happens.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"drop\"\n            ) |&gt;\n  mutate(mean = mean(Score))\n\n# A tibble: 5 × 4\n  School District Score  mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      82.5  75.5\n2 B      West      79.5  75.5\n3 C      East      87    75.5\n4 D      North     62.5  75.5\n5 E      North     66    75.5\n\n\n\n\nConsider ungroup():\n.groups = \"drop\" in effect works the same as does ungroup(). The grouping structure is broken and all subsequent operations are based on the ungrouped data frame.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),\n            .groups = \"drop_last\"\n            ) |&gt;\n  ungroup() |&gt;\n  mutate(mean = mean(Score))\n\n# A tibble: 5 × 4\n  School District Score  mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      82.5  75.5\n2 B      West      79.5  75.5\n3 C      East      87    75.5\n4 D      North     62.5  75.5\n5 E      North     66    75.5\n\n\nKeep in mind that functions work as they are programmed to work. Functions do not work like you think they work. You must understand the function and check our work to ensure your calculations are what you intend them to be.\n\n\nThe order of operations matters\nTo illustrate further, consider you want to calculate some summary statistics. You set out to obtain the mean and the standard deviation for your data. Those computations will be performed according to the grouping structure.\nWhen you compute standard deviation and the mean of Score, you assign the mean to Score because you want your plot to contain a clean name rather than one like Score_Mean that you will have to address in the plot.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score_sd = sd(Score),   # get sd \n            Score = mean(Score)     # get mean, assign to same name\n            ) \n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 4\n# Groups:   School [5]\n  School District Score_sd Score\n  &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 A      West        3.54   82.5\n2 B      West        0.707  79.5\n3 C      East        5.29   87  \n4 D      North       3.54   62.5\n5 E      North       1.41   66  \n\n\nBoth variables use the same data because the standard deviation assigns the value to a different variable name Score_sd. The mean() is not based on some changed variable.\nThe output is different from the one returned when the mean is computed before the standard deviation and in particular when the mean is assigned to Score. In this case, the standard deviation is based on this new Score variable. Because the standard deviation is a measure of variability, and Score does not vary based on the grouping structure, NA is returned.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score),   # get mean, assign to same name\n            Score_sd = sd(Score)   # get sd         \n            )\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 4\n# Groups:   School [5]\n  School District Score Score_sd\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 A      West      82.5       NA\n2 B      West      79.5       NA\n3 C      East      87         NA\n4 D      North     62.5       NA\n5 E      North     66         NA\n\n\nIf you really wanted the standard deviation of all the means, consider ungrouping and then compute the standard deviation or use .groups =  \"drop\" in summarize(). Realize, however, this latter functionality is experimental and may not work sometime later. You are likely better off using ungroup().\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Score = mean(Score)) |&gt;  # get mean, assign to same name\n  ungroup() |&gt;\n  mutate(sd = sd(Score))\n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 4\n  School District Score    sd\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 A      West      82.5  10.7\n2 B      West      79.5  10.7\n3 C      East      87    10.7\n4 D      North     62.5  10.7\n5 E      North     66    10.7"
  },
  {
    "objectID": "modules/10_summarizing_data.html#new-variable-columns",
    "href": "modules/10_summarizing_data.html#new-variable-columns",
    "title": "Summarizing Data",
    "section": "New Variable Columns",
    "text": "New Variable Columns\ngroup_by() is not designed to create new variables but rather create groups. The function, however, does not require variables in a data frame in order to group based on their levels or differences in values.\n\ngroup_by() using a function\nHeretofore, we have grouped by column variables in a data frame. But you can also group in other ways, for example, by a variable calculated by a function. For example, if you wanted to group by standard deviations, you could calculated the standard deviation (Score-mean(Score)) / sd(Score) for each student and then cut() that variable into groups. cut will take a numeric vector variable and turn it into a factor variable of n groups as determined by what you pass to breaks. There is also an argument to make the factor ordered if you wish, ordered_result = TRUE but the default behavior does not order the factor. You can also change the level labels if you inspect the function.\n\nDATA |&gt;\n  group_by(z_factor = cut( \n    x = ((Score - mean(Score)) / sd(Score) ), \n    breaks = 5, \n    ordered_result = T\n    )\n  )\n\n# A tibble: 11 × 5\n# Groups:   z_factor [4]\n   Student      Score School District z_factor       \n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;ord&gt;          \n 1 Jim             80 A      West     (0.194,0.781]  \n 2 Sally           85 A      West     (0.781,1.37]   \n 3 June            79 B      West     (0.194,0.781]  \n 4 Mildred         80 B      West     (0.194,0.781]  \n 5 Tilford         81 C      East     (0.194,0.781]  \n 6 Beavis          91 C      East     (0.781,1.37]   \n 7 Herman          89 C      East     (0.781,1.37]   \n 8 Peppa           60 D      North    (-1.57,-0.979] \n 9 Kay             65 D      North    (-1.57,-0.979] \n10 Jake            67 E      North    (-0.979,-0.392]\n11 Name Missing    65 E      North    (-1.57,-0.979] \n\n\nYou can see that there are 4 different levels of the grouping variable. The tibble is grouped of course too.\nIf you struggle with remembering the formula for a z score, scale() will to the same thing.\n\nDATA |&gt;\n  mutate(z = (Score - mean(Score))/sd(Score),\n         scale = scale(Score)\n         )\n\n        Student Score School District          z      scale\n1           Jim    80      A     West  0.3269018  0.3269018\n2         Sally    85      A     West  0.8000492  0.8000492\n3          June    79      B     West  0.2322724  0.2322724\n4       Mildred    80      B     West  0.3269018  0.3269018\n5       Tilford    81      C     East  0.4215313  0.4215313\n6        Beavis    91      C     East  1.3678261  1.3678261\n7        Herman    89      C     East  1.1785671  1.1785671\n8         Peppa    60      D    North -1.5656877 -1.5656877\n9           Kay    65      D    North -1.0925403 -1.0925403\n10         Jake    67      E    North -0.9032814 -0.9032814\n11 Name Missing    65      E    North -1.0925403 -1.0925403\n\n\nIf you want n groups based on specific breaks, then pass a vector of those break units. For example, if we want levels to correspond to some meaningful standard-deviation cuts. For example, if you wanted to group those with z scores ranging from infinitely negative to -2, -2 to -1, - to 1, 1 to 2, and 2 to infinitely large, you could specify the breaks. If there are no values in those ranges, then there won’t be any data for those breaks.\n\nDATA |&gt;\n  group_by(z_factor = cut( scale(Score), \n                          breaks = c(-Inf, -2, -1, 1, 2, Inf),\n                          ordered_result = T\n                          ), \n           ) |&gt;\n  ungroup() \n\n# A tibble: 11 × 5\n   Student      Score School District z_factor\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;ord&gt;   \n 1 Jim             80 A      West     (-1,1]  \n 2 Sally           85 A      West     (-1,1]  \n 3 June            79 B      West     (-1,1]  \n 4 Mildred         80 B      West     (-1,1]  \n 5 Tilford         81 C      East     (-1,1]  \n 6 Beavis          91 C      East     (1,2]   \n 7 Herman          89 C      East     (1,2]   \n 8 Peppa           60 D      North    (-2,-1] \n 9 Kay             65 D      North    (-2,-1] \n10 Jake            67 E      North    (-1,1]  \n11 Name Missing    65 E      North    (-2,-1] \n\n\nYou can also just group by the function without using cut() if you wish to group by those with identical values on the variable. In this case, using count() or tally() reveals there are only two instances with the same score.\n\nDATA |&gt;\n  group_by(z_factor = ((Score - mean(Score)) / sd(Score) )) |&gt;\n  count(sort = TRUE)     # tally(sort = TRUE)\n\n# A tibble: 9 × 2\n# Groups:   z_factor [9]\n  z_factor     n\n     &lt;dbl&gt; &lt;int&gt;\n1   -1.09      2\n2    0.327     2\n3   -1.57      1\n4   -0.903     1\n5    0.232     1\n6    0.422     1\n7    0.800     1\n8    1.18      1\n9    1.37      1"
  },
  {
    "objectID": "modules/10_summarizing_data.html#adddrop-grouping-variable-columns",
    "href": "modules/10_summarizing_data.html#adddrop-grouping-variable-columns",
    "title": "Summarizing Data",
    "section": "Add/drop Grouping Variable Columns",
    "text": "Add/drop Grouping Variable Columns\nBy default, group_by() on a data frame that is already grouped (see earlier on grouped data frame), the existing grouping structure will be replaced by new grouping structure.\nLet’s get an example. Please note that this example assigned the tibble to an object but whether you assign or not, the grouped structure exists. So functions that follow the group_by() keep that structure.\n\n(school_grouped &lt;- \n  DATA |&gt;\n  group_by(School) \n)\n\n# A tibble: 11 × 4\n# Groups:   School [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nNow group by a new column:\n\nschool_grouped |&gt;\n  group_by(District)\n\n# A tibble: 11 × 4\n# Groups:   District [3]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nYou will see the grouping structure has changed.\n# A tibble: 11 × 4\n# Groups:   District [3]\n\nRetain Grouping\nIf you want to retain the existing group, you would need to use .add = TRUE.\n\nschool_grouped |&gt;\n  group_by(District, .add = TRUE)\n\n# A tibble: 11 × 4\n# Groups:   School, District [5]\n   Student      Score School District\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1 Jim             80 A      West    \n 2 Sally           85 A      West    \n 3 June            79 B      West    \n 4 Mildred         80 B      West    \n 5 Tilford         81 C      East    \n 6 Beavis          91 C      East    \n 7 Herman          89 C      East    \n 8 Peppa           60 D      North   \n 9 Kay             65 D      North   \n10 Jake            67 E      North   \n11 Name Missing    65 E      North   \n\n\nNotice in the console, that both School and District are included in the groups.\n# A tibble: 11 × 4\n# Groups:   School, District [5]"
  },
  {
    "objectID": "modules/10_summarizing_data.html#why-care-about-grouping-structure",
    "href": "modules/10_summarizing_data.html#why-care-about-grouping-structure",
    "title": "Summarizing Data",
    "section": "Why Care About Grouping Structure",
    "text": "Why Care About Grouping Structure\nWell, the functions you apply to a grouped tibble will sometimes lead to calculations that are not what you intend. We provided some examples earlier but given the importance of the issue, we may benefit from another example.\nLet’s say you want to compute the average for each school and add that school average for each student. This would tell you how the student differs from their school performance. Then you want to obtain the mean of all the schools and see how the school differs from all the schools.\nYou code it out:\n\nDATA |&gt;\n  # group \n  group_by(School) |&gt;\n  # calculate the mean of Score for each School\n  mutate(School_Mean = mean(Score)) |&gt;\n  # calculate the mean of all values (think Grand Mean from stats)\n  mutate(Mean_of_all = mean(School_Mean)) |&gt;\n  # calculate the school performance relative to all\n  mutate(School_Performance = factor(\n    case_when(\n      School_Mean &lt; Mean_of_all ~ \"Below Average\",\n      School_Mean == Mean_of_all ~ \"Average\",\n      School_Mean &gt; Mean_of_all ~ \"Above Average\"\n      ), ordered = T)\n  )\n\n# A tibble: 11 × 7\n# Groups:   School [5]\n   Student      Score School District School_Mean Mean_of_all School_Performance\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;ord&gt;             \n 1 Jim             80 A      West            82.5        82.5 Average           \n 2 Sally           85 A      West            82.5        82.5 Average           \n 3 June            79 B      West            79.5        79.5 Average           \n 4 Mildred         80 B      West            79.5        79.5 Average           \n 5 Tilford         81 C      East            87          87   Average           \n 6 Beavis          91 C      East            87          87   Average           \n 7 Herman          89 C      East            87          87   Average           \n 8 Peppa           60 D      North           62.5        62.5 Average           \n 9 Kay             65 D      North           62.5        62.5 Average           \n10 Jake            67 E      North           66          66   Average           \n11 Name Missing    65 E      North           66          66   Average           \n\n\nPerfect. OK, let’s plot it. Oh but first let me inspect the data. Um, why is School_Performance the same for all Students? Schools are not performing the same so they cannot all be average. Check your case_when() for errors because that where the new variable was created. Then you spend 40 days and 40 nights trying to fix your code. No matter what you do with case_when(), you cannot fix the problem. So you try to create 42 data frames to solve your problem. Even grandma knows that is a ridiculous strategy. She suggests you read the documentation for all of the functions you used because one time her pot-luck cake flopped and she inspected the expiration date for all of her ingredients and found the baking soda was old.\nYou discover that the grouping structure is retained on all operations until that grouping structure is removed or replaced."
  },
  {
    "objectID": "modules/10_summarizing_data.html#variable-loss-with-summarize",
    "href": "modules/10_summarizing_data.html#variable-loss-with-summarize",
    "title": "Summarizing Data",
    "section": "Variable loss with summarize()",
    "text": "Variable loss with summarize()\nBecause summarize() returns a tibble based on the grouping structure, you will lose all variables that are not in the grouping structure. By design, it no longer allows you to return a data frame with duplicated rows based on the variables passed to group_by().\nReturning to the school data, what this means, is that you cannot retain the School if you group by the District in order to obtain averages by district.\n\nDATA |&gt;\n  group_by(District) |&gt;\n  summarize(Mean = mean(Score))\n\n# A tibble: 3 × 2\n  District  Mean\n  &lt;chr&gt;    &lt;dbl&gt;\n1 East      87  \n2 North     64.2\n3 West      81  \n\n\nIf you try to add School to group_by(), then you will only obtain the averages by schools within districts.\n\nDATA |&gt;\n  group_by(School, District) |&gt;\n  summarize(Mean = mean(Score)) \n\n`summarise()` has grouped output by 'School'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   School [5]\n  School District  Mean\n  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 A      West      82.5\n2 B      West      79.5\n3 C      East      87  \n4 D      North     62.5\n5 E      North     66  \n\n\nYou can try to summarize based on a variable without assign it to a function but that is no longer allowed with summarize(). The following code block will throw an error.\nDATA |&gt;\n  group_by(District) |&gt;\n  summarize(Mean = mean(Score),\n          School               # add school \n          )"
  },
  {
    "objectID": "modules/10_summarizing_data.html#an-alternative-to-summarize-reframe",
    "href": "modules/10_summarizing_data.html#an-alternative-to-summarize-reframe",
    "title": "Summarizing Data",
    "section": "An alternative to summarize(): reframe()",
    "text": "An alternative to summarize(): reframe()\nInstead, you can use reframe(), which allows for previous functionality of summarize() that is now deprecated.\n\nDATA |&gt;\n  group_by(District) |&gt;\n  reframe(Mean = mean(Score),\n          School,\n          Student\n          )\n\n# A tibble: 11 × 4\n   District  Mean School Student     \n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;       \n 1 East      87   C      Tilford     \n 2 East      87   C      Beavis      \n 3 East      87   C      Herman      \n 4 North     64.2 D      Peppa       \n 5 North     64.2 D      Kay         \n 6 North     64.2 E      Jake        \n 7 North     64.2 E      Name Missing\n 8 West      81   A      Jim         \n 9 West      81   A      Sally       \n10 West      81   B      June        \n11 West      81   B      Mildred     \n\n\nRemember that the operations in summarize(), mutate(), and reframe() all depend on the grouping structure. If you wanted to add variables, you would need to group a different way and you would need to add all variables into summarize() every step of the way.\n\nDATA |&gt;\n  group_by(District) |&gt;\n  reframe(District_Mean = mean(Score),\n          School, \n          Student,\n          Score\n          ) |&gt;\n  ungroup() |&gt;\n  group_by(School) %&gt;%\n  reframe(School_Mean = mean(Score),\n          School, \n          Student,\n          Score,\n          District_Mean\n          ) |&gt;\n  ungroup()\n\n# A tibble: 11 × 5\n   School School_Mean Student      Score District_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n 1 A             82.5 Jim             80          81  \n 2 A             82.5 Sally           85          81  \n 3 B             79.5 June            79          81  \n 4 B             79.5 Mildred         80          81  \n 5 C             87   Tilford         81          87  \n 6 C             87   Beavis          91          87  \n 7 C             87   Herman          89          87  \n 8 D             62.5 Peppa           60          64.2\n 9 D             62.5 Kay             65          64.2\n10 E             66   Jake            67          64.2\n11 E             66   Name Missing    65          64.2"
  },
  {
    "objectID": "modules/10_summarizing_data.html#retaining-distinct-data-after-mutate-using-distinct",
    "href": "modules/10_summarizing_data.html#retaining-distinct-data-after-mutate-using-distinct",
    "title": "Summarizing Data",
    "section": "Retaining distinct data after mutate() using distinct()",
    "text": "Retaining distinct data after mutate() using distinct()\nThis is just too tedious. Your better option is mutate() as all variables will be added to the full data frame. All variables are neatly and logically appended to the right hand side of the data frame.\n\nDATA |&gt;\n  group_by(District) |&gt;\n  mutate(District_Mean = mean(Score)) |&gt;\n  group_by(School) |&gt;\n  mutate(School_Mean = mean(Score))\n\n# A tibble: 11 × 6\n# Groups:   School [5]\n   Student      Score School District District_Mean School_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;\n 1 Jim             80 A      West              81          82.5\n 2 Sally           85 A      West              81          82.5\n 3 June            79 B      West              81          79.5\n 4 Mildred         80 B      West              81          79.5\n 5 Tilford         81 C      East              87          87  \n 6 Beavis          91 C      East              87          87  \n 7 Herman          89 C      East              87          87  \n 8 Peppa           60 D      North             64.2        62.5\n 9 Kay             65 D      North             64.2        62.5\n10 Jake            67 E      North             64.2        66  \n11 Name Missing    65 E      North             64.2        66  \n\n\nAlso, when you use a new group_by(), it will replace previous grouping structure by default. The following two code blocks return the same data frame.\nDATA |&gt;\n  group_by(District) |&gt;\n  mutate(District_Mean = mean(Score)) |&gt;\n  group_by(School) |&gt;\n  mutate(School_Mean = mean(Score))\nWith ungroup():\nDATA |&gt;\n  group_by(District) |&gt;\n  mutate(District_Mean = mean(Score)) |&gt;\n  ungroup() |&gt;                            # ungroup\n  group_by(School) |&gt;\n  mutate(School_Mean = mean(Score))\nIf you wish those variables to remain, you have a couple of options. The first would be to use mutate().\nNotice, however, that if you want to extract the summaries from the large data frame as you would have had you used summarize(), you cannot just select() your column of interest because the repetitions will exist for each row in the data frame.\n\nDATA |&gt;\n  group_by(District) |&gt;\n  mutate(District_Mean = mean(Score)) |&gt;\n  select(c(\"School\", \"District_Mean\"))    # if passing a vector, use any_of() or all_of())\n\nAdding missing grouping variables: `District`\n\n\n# A tibble: 11 × 3\n# Groups:   District [3]\n   District School District_Mean\n   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n 1 West     A               81  \n 2 West     A               81  \n 3 West     B               81  \n 4 West     B               81  \n 5 East     C               87  \n 6 East     C               87  \n 7 East     C               87  \n 8 North    D               64.2\n 9 North    D               64.2\n10 North    E               64.2\n11 North    E               64.2\n\n\nYou can obtain the rows that are distinct() (unique) and then pick() the ones to keep.\n\nDATA |&gt;\n  group_by(District) |&gt;\n  mutate(District_Mean = mean(Score)) |&gt;\n  distinct(pick(c(\"District\", \"District_Mean\")))\n\n# A tibble: 3 × 2\n# Groups:   District [3]\n  District District_Mean\n  &lt;chr&gt;            &lt;dbl&gt;\n1 West              81  \n2 East              87  \n3 North             64.2\n\n\nBut you will need to ungroup() before distinct() because, as we have mentioned before, all subsequent functions other than group_by() will maintain the previous grouping structure by default.\n\nDATA |&gt;\n  group_by(School) |&gt;\n  mutate(School_Mean = mean(Score)) |&gt;\n  ungroup()\n\n# A tibble: 11 × 5\n   Student      Score School District School_Mean\n   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n 1 Jim             80 A      West            82.5\n 2 Sally           85 A      West            82.5\n 3 June            79 B      West            79.5\n 4 Mildred         80 B      West            79.5\n 5 Tilford         81 C      East            87  \n 6 Beavis          91 C      East            87  \n 7 Herman          89 C      East            87  \n 8 Peppa           60 D      North           62.5\n 9 Kay             65 D      North           62.5\n10 Jake            67 E      North           66  \n11 Name Missing    65 E      North           66"
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html",
    "href": "modules/12_manipulating_data_pivoting.html",
    "title": "Transforming Data Frames: Pivoting",
    "section": "",
    "text": "In this module, we will address converting data frames from wide to long and from long to wide, especially in service of arranging data frames to be tidy. The functions for making tidy data frames used here are from {tidyr}, specifically pivot_longer() and pivot_wider().\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\nData Transformation\nHuber: Transforming Data"
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#readings-and-preparation",
    "href": "modules/12_manipulating_data_pivoting.html#readings-and-preparation",
    "title": "Transforming Data Frames: Pivoting",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#supplementary-readings-optional",
    "href": "modules/12_manipulating_data_pivoting.html#supplementary-readings-optional",
    "title": "Transforming Data Frames: Pivoting",
    "section": "",
    "text": "Data Transformation\nHuber: Transforming Data"
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#loading-libraries",
    "href": "modules/12_manipulating_data_pivoting.html#loading-libraries",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Loading Libraries",
    "text": "Loading Libraries\nWe will work with a few different libraries for data manipulation. Let’s load them into our work space using library().\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyselect)"
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#wide-format-data",
    "href": "modules/12_manipulating_data_pivoting.html#wide-format-data",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Wide Format Data",
    "text": "Wide Format Data\nWide-format data files are likely most familiar to you as they represent the type of data you may see in spreadsheets. In this example,e individuals have values for three different days with days as columns and individuals as rows.\n\n\n\n\n\n\n\n\n\nSome disadvantages associated with this representation is that unless there is documentation, you would be unsure what the numeric values represent and the three days represent levels of a day variable which is not part of the data file."
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#long-format-data",
    "href": "modules/12_manipulating_data_pivoting.html#long-format-data",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Long Format Data",
    "text": "Long Format Data\nThe same data can be presented in long-format, for which days are aligned in a column along with a variable name, temp.\n\n\n\n\n\n\n\n\n\nSome disadvantages of long-format files is that they are long and difficult to search through and they are limited in their ability to represent a merged version of multiple data sets all of which contain different numbers of rows. By contrast, wide-format files can accommodate multiple columns because each column could easily represent an observation and rows could represent unique cases."
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#tidy-data",
    "href": "modules/12_manipulating_data_pivoting.html#tidy-data",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Tidy Data",
    "text": "Tidy Data\nCharacteristics of tidy data:\n\nEach variable is its own column\nEach observation is its own row.\nEach value has its own cell\n\nThe goal of restructing data will be to create tidy data for with each variable is represented as a column and observations across rows."
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#inspectingtaking-inventory-of-the-data-structure",
    "href": "modules/12_manipulating_data_pivoting.html#inspectingtaking-inventory-of-the-data-structure",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Inspecting/Taking Inventory of the Data Structure",
    "text": "Inspecting/Taking Inventory of the Data Structure\nWe first need to inspect the data frame structure. Although you can see this from the output above, another way to view the structure of data frames is by using dplyr::glimpse() or base R str().\n\nEXAMPLE |&gt;\n  glimpse()\n\nRows: 4\nColumns: 7\n$ name   &lt;chr&gt; \"Bill\", \"Sally\", \"Jim\", \"Sue\"\n$ `2023` &lt;dbl&gt; 175, 120, 150, 115\n$ `2024` &lt;dbl&gt; 170, 135, 150, 120\n$ task_A &lt;dbl&gt; 10, 10, 11, NA\n$ task_B &lt;dbl&gt; 12, 15, 24, NA\n$ tsk1   &lt;dbl&gt; 10, 10, 11, NA\n$ tsk2   &lt;dbl&gt; 12, 15, 24, NA"
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#inspectingtaking-inventory-of-the-data-structure-1",
    "href": "modules/12_manipulating_data_pivoting.html#inspectingtaking-inventory-of-the-data-structure-1",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Inspecting/Taking Inventory of the Data Structure",
    "text": "Inspecting/Taking Inventory of the Data Structure\nWe see some variable are character vectors and some are double (numeric) vectors. But what are the variables and what information do the variables represent? Let’s say that you are informed that there are actually 5 variables in this data set, even though there are 7 column vectors.\nname: the name of the individual year: the years of data measurement collection weight: the weight in pounds at the time (year) of measurement task: the task type (though represented as both \"task_\" and \"tsk\") score: the measurement score on the tasks\nNote: Having ideal documentation about the data file is important for being able to restructure it appropriately. Always create some documentation so that your future self and others know that the data actually represent.\nOnly the name variable is currently a column. We don’t have variables named year, weight, task, nor score. The measurement times of the repeated measurements (e.g., the numeric years) are currently stored as separate columns. The values of these columns represent the weights of individuals at two points in time. Some of this information would be unclear unless you had the documentation of what the variables were and how they were stored. This is why having good documentation, or requesting such documentation, is important.\nIn order to make the data tidy, we need to pivot the two year columns so that they are in arranged as a separate column containing. Take notice that stacking the two column vector would result in a vector that is twice as long. The result is a longer but narrower data frame. Other times, you may need to take a longer data frame and make it a shorter but wider data frame. The verb used to describe this type of transformation is pivot."
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#pivoting-using-tidyrpivot_longer",
    "href": "modules/12_manipulating_data_pivoting.html#pivoting-using-tidyrpivot_longer",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Pivoting using tidyr::pivot_longer()",
    "text": "Pivoting using tidyr::pivot_longer()\nAfter establishing what the data frame is and how you need to transform it, we can consider the steps involved to pass the necessary arguments.\nEXAMPLE |&gt;\n  pivot_longer(\n    cols =      Step 1, select the columns to pivot/move\n    names_to =  Step 2, specify the name of the column to move those columns \n    values_to = Step 3, specify the name of the values from those columns \n  )\nOur Pivoting Goal:\nStep 1: cols to pivot from wide to long\nStep 2: names_to: because they are years, make a years variable under which the dates are placed\nStep 3: values_to: because these are weights, make a weight variable under which the individuals weights for years are placed\n\nIdentifying the columns to pivot\nAs mentioned earlier, you can specify cols by their names in a variety of ways depending on your goals.\n\nSpecifying column position\nWe can specify columns by position in a variety of ways. Options that are commented out are provided for demonstration. You can test them out if you wish.\n\nEXAMPLE |&gt; \n  pivot_longer(\n    cols = 2:3,            # by column position \n    # cols = c(2:3),       # by column position using c()\n    # cols = -1,           # by removing a position, or several -c(1, pos, pos)\n    # cols = !1,           # by NOT position\n    names_to = \"year\", \n    values_to = \"weight\"\n  )\n\n# A tibble: 8 × 7\n  name  task_A task_B  tsk1  tsk2 year  weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Bill      10     12    10    12 2023     175\n2 Bill      10     12    10    12 2024     170\n3 Sally     10     15    10    15 2023     120\n4 Sally     10     15    10    15 2024     135\n5 Jim       11     24    11    24 2023     150\n6 Jim       11     24    11    24 2024     150\n7 Sue       NA     NA    NA    NA 2023     115\n8 Sue       NA     NA    NA    NA 2024     120\n\n\n\n\nSpecifying characters\nVariables that contain certain characters can be selected for pivoting using functions from {tidyselect} like contains(), starts_with(), ends_with(), and matches(). We will now work through some examples. These functions load as part of {dplyr} as well.\n\nSpecifying characters using contains()\nIf we select column names that contains() the characters \"task\", we will select only the full spelling of the task; \"tsk\" columns will be skipped.\n\nEXAMPLE |&gt; \n  pivot_longer(\n    cols = contains(\"task\"),\n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 7\n  name  `2023` `2024`  tsk1  tsk2 task   score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Bill     175    170    10    12 task_A    10\n2 Bill     175    170    10    12 task_B    12\n3 Sally    120    135    10    15 task_A    10\n4 Sally    120    135    10    15 task_B    15\n5 Jim      150    150    11    24 task_A    11\n6 Jim      150    150    11    24 task_B    24\n7 Sue      115    120    NA    NA task_A    NA\n8 Sue      115    120    NA    NA task_B    NA\n\n\nWe can now see that there are two new column variables in the returned data frame: task and score.\nSome variables are not included in the pivot but nevertheless get included in the process. The task variables spelled differently and have a number suffix are replicated across rows but are not created as a new variable. Similarly, the weights for years are replicated across rows for each task but they are not addressed in the pivoting. Variable names are not perfect right now but they will be cleaned up better in examples of advanced pivoting.\nAs another example, we can select variables containing the underscore, \"_\". Because task_A and task_B are the only variables containing underscores, the outcome will be the same.\n\nEXAMPLE |&gt; \n  pivot_longer(\n    cols = contains(\"_\"),\n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 7\n  name  `2023` `2024`  tsk1  tsk2 task   score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Bill     175    170    10    12 task_A    10\n2 Bill     175    170    10    12 task_B    12\n3 Sally    120    135    10    15 task_A    10\n4 Sally    120    135    10    15 task_B    15\n5 Jim      150    150    11    24 task_A    11\n6 Jim      150    150    11    24 task_B    24\n7 Sue      115    120    NA    NA task_A    NA\n8 Sue      115    120    NA    NA task_B    NA\n\n\n\n\nSpecifying characters using starts_with()\nWe can also select variables for the pivot that start or end with certain characters. Notice that task_A, task_B, tsk_1, and tsk_2 all begin with the same letter. If we use that letter, the data frame will pivot on all 4 of those columns and use them to create a single column called task. Such an approach is very useful if the task variants represent different tasks. In this case, the letter and number suffix variables are redundant.\n\nEXAMPLE |&gt; \n  pivot_longer(\n    cols = starts_with(\"t\"),\n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 16 × 5\n   name  `2023` `2024` task   score\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n 1 Bill     175    170 task_A    10\n 2 Bill     175    170 task_B    12\n 3 Bill     175    170 tsk1      10\n 4 Bill     175    170 tsk2      12\n 5 Sally    120    135 task_A    10\n 6 Sally    120    135 task_B    15\n 7 Sally    120    135 tsk1      10\n 8 Sally    120    135 tsk2      15\n 9 Jim      150    150 task_A    11\n10 Jim      150    150 task_B    24\n11 Jim      150    150 tsk1      11\n12 Jim      150    150 tsk2      24\n13 Sue      115    120 task_A    NA\n14 Sue      115    120 task_B    NA\n15 Sue      115    120 tsk1      NA\n16 Sue      115    120 tsk2      NA\n\n\nThe logic for using ends_with() works the same way as starts_with(), so examples are not provided.\n\n\n\nSpecifying pattern matches\nThe matches() function is excellent for matching patterns by regular expression. When you cannot type literal characters for grabbing columns, you can think about patterns. We see for example that some variables end in letters and some end in numbers. We can certainly use ends_with() and specify the numbers to grab tsk1 and tsk2 but if there are numerous variables, doing so involves more work. Moreover, if you are dealing with data sets that can change from time to time, the numbers might change. Hard coding the numbers will create errors, for example, when your data frame no longer contains a variable named tsk1.\nIn such instances, matching patterns is a wonderful solution. Let’s use matches() to select columns that end in digits. The regular expression pattern \\\\d+ stands for one or more of any digit.\nSo what happens if we use cols = matches(\"\\\\d+\")?\n\nEXAMPLE |&gt; \n  pivot_longer(\n    cols = matches(\"\\\\d+\"),   # by looking for variables pattern of digits\n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 16 × 5\n   name  task_A task_B task  score\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 Bill      10     12 2023    175\n 2 Bill      10     12 2024    170\n 3 Bill      10     12 tsk1     10\n 4 Bill      10     12 tsk2     12\n 5 Sally     10     15 2023    120\n 6 Sally     10     15 2024    135\n 7 Sally     10     15 tsk1     10\n 8 Sally     10     15 tsk2     15\n 9 Jim       11     24 2023    150\n10 Jim       11     24 2024    150\n11 Jim       11     24 tsk1     11\n12 Jim       11     24 tsk2     24\n13 Sue       NA     NA 2023    115\n14 Sue       NA     NA 2024    120\n15 Sue       NA     NA tsk1     NA\n16 Sue       NA     NA tsk2     NA\n\n\nWell, that kind of worked but the year data that are also included in task because those variables also contained numbers matched by the pattern.\nSure, you could just remove the numbers from the data frame and pivot:\n\nEXAMPLE |&gt;\n  select(-c(2 ,3)) |&gt;\n  pivot_longer(\n    cols = matches(\"\\\\d+\"),\n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 5\n  name  task_A task_B task  score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Bill      10     12 tsk1     10\n2 Bill      10     12 tsk2     12\n3 Sally     10     15 tsk1     10\n4 Sally     10     15 tsk2     15\n5 Jim       11     24 tsk1     11\n6 Jim       11     24 tsk2     24\n7 Sue       NA     NA tsk1     NA\n8 Sue       NA     NA tsk2     NA\n\n\nThe problem here is that the year data is removed. If you don’t need them, then that’s fine but if you do, you need a better solution. Moreover, sometimes you don’t know when you will need a variable so keeping them in the data set is likely a better solution. Let’s figure out how.\n\n\nSpecifying pattern matches\nWe see that the variables we want also begin with characters. We might decide to approach the problem by looking for matches to character patterns followed by digit patterns. The following two regular expressions will search for different patterns need to solve the problem.\n\n[a-zA-Z]+: match one or more characters\n\\\\d+: match one or more digits\n\nThe ordering of the patterns will find variable names that begin with characters followed by numbers.\nAn example matching letters and then digits:\n\nmatches(\"[a-zA-Z]+\\\\d+\")\n\nThis pattern would match variables that also contain special characters (e.g., \"_\", \"-\", \"&\", \"$\", etc.) between the letter and digits as well as characters after the numbers too. If your variables are more complex, you might need some additional patterns but for this example, the pattern should select what we want, which is to the tsk1 and tsk2 variables only.\n\nEXAMPLE |&gt; \n  pivot_longer(\n    cols = matches(\"[a-zA-Z]+\\\\d+\"),   # by looking for variables pattern of digits\n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 7\n  name  `2023` `2024` task_A task_B task  score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Bill     175    170     10     12 tsk1     10\n2 Bill     175    170     10     12 tsk2     12\n3 Sally    120    135     10     15 tsk1     10\n4 Sally    120    135     10     15 tsk2     15\n5 Jim      150    150     11     24 tsk1     11\n6 Jim      150    150     11     24 tsk2     24\n7 Sue      115    120     NA     NA tsk1     NA\n8 Sue      115    120     NA     NA tsk2     NA\n\n\nGreat! We now see that only tsk1 and tsk2 are selected for pivoting, and are dumped into a new variable named task and the values from them are placed in a new variable named score. Again, the values of task are messy but we will address dealing with that issue in advanced pivoting techniques.\n\n\nRegular Expression Anchors\nThere are special characters in for regular expressions that will achieve the same as starts_with() and ends_with().\n\n\nMatching Beginning Characters using the Caret ^\nTo see how ^ works, let’s add another variable that contains characters and then numbers but neither begins with characters nor ends to digits.\n\nEXAMPLE |&gt; \n  mutate(\"23abc24z\" = 1) |&gt;\n  pivot_longer(\n    cols = matches(\"^[a-zA-Z]+\\\\d+\"),   \n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 8\n  name  `2023` `2024` task_A task_B `23abc24z` task  score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Bill     175    170     10     12          1 tsk1     10\n2 Bill     175    170     10     12          1 tsk2     12\n3 Sally    120    135     10     15          1 tsk1     10\n4 Sally    120    135     10     15          1 tsk2     15\n5 Jim      150    150     11     24          1 tsk1     11\n6 Jim      150    150     11     24          1 tsk2     24\n7 Sue      115    120     NA     NA          1 tsk1     NA\n8 Sue      115    120     NA     NA          1 tsk2     NA\n\n\nYou see that variable 23abc24z is not included in the pivot. As a result, the variable remains as a column in the data frame. However, it will be included if the matching is not constrained to starting with characters as seen here.\n\nEXAMPLE |&gt; \n  mutate(\"23abc24z\" = 1) |&gt;\n  pivot_longer(\n    cols = matches(\"[a-zA-Z]+\\\\d+\"),   \n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 12 × 7\n   name  `2023` `2024` task_A task_B task     score\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1 Bill     175    170     10     12 tsk1        10\n 2 Bill     175    170     10     12 tsk2        12\n 3 Bill     175    170     10     12 23abc24z     1\n 4 Sally    120    135     10     15 tsk1        10\n 5 Sally    120    135     10     15 tsk2        15\n 6 Sally    120    135     10     15 23abc24z     1\n 7 Jim      150    150     11     24 tsk1        11\n 8 Jim      150    150     11     24 tsk2        24\n 9 Jim      150    150     11     24 23abc24z     1\n10 Sue      115    120     NA     NA tsk1        NA\n11 Sue      115    120     NA     NA tsk2        NA\n12 Sue      115    120     NA     NA 23abc24z     1\n\n\n\n\nMatching Ending Characters using the dollar $\nTo test $ for ending patterns, let’s add the same variable.\n\nEXAMPLE |&gt; \n  mutate(\"23abc24z\" = 1) |&gt;\n  pivot_longer(\n    cols = matches(\"[a-zA-Z]+\\\\d+$\"),   \n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 8\n  name  `2023` `2024` task_A task_B `23abc24z` task  score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Bill     175    170     10     12          1 tsk1     10\n2 Bill     175    170     10     12          1 tsk2     12\n3 Sally    120    135     10     15          1 tsk1     10\n4 Sally    120    135     10     15          1 tsk2     15\n5 Jim      150    150     11     24          1 tsk1     11\n6 Jim      150    150     11     24          1 tsk2     24\n7 Sue      115    120     NA     NA          1 tsk1     NA\n8 Sue      115    120     NA     NA          1 tsk2     NA\n\n\nAgain, you see that variable 23abc24z is not included in the pivot. But it will be included if the matching is not constrained to starting with characters as seen here.\n\nEXAMPLE |&gt; \n  mutate(\"23abc24z\" = 1) |&gt;\n  pivot_longer(\n    cols = matches(\"[a-zA-Z]+\\\\d+\"),   \n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 12 × 7\n   name  `2023` `2024` task_A task_B task     score\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1 Bill     175    170     10     12 tsk1        10\n 2 Bill     175    170     10     12 tsk2        12\n 3 Bill     175    170     10     12 23abc24z     1\n 4 Sally    120    135     10     15 tsk1        10\n 5 Sally    120    135     10     15 tsk2        15\n 6 Sally    120    135     10     15 23abc24z     1\n 7 Jim      150    150     11     24 tsk1        11\n 8 Jim      150    150     11     24 tsk2        24\n 9 Jim      150    150     11     24 23abc24z     1\n10 Sue      115    120     NA     NA tsk1        NA\n11 Sue      115    120     NA     NA tsk2        NA\n12 Sue      115    120     NA     NA 23abc24z     1\n\n\n\n\nMatching Beginning and Ending Characters\nUsing the two anchors together ^...$ is useful to test whether or not a string fully matches the pattern. We can also add the same variable as before to examine the impact.\n\nEXAMPLE |&gt; \n  mutate(\"23abc24z\" = 1) |&gt;\n  pivot_longer(\n    cols = matches(\"^[a-zA-Z]+\\\\d+$\"),   \n    names_to = \"task\", \n    values_to = \"score\"\n  )\n\n# A tibble: 8 × 8\n  name  `2023` `2024` task_A task_B `23abc24z` task  score\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Bill     175    170     10     12          1 tsk1     10\n2 Bill     175    170     10     12          1 tsk2     12\n3 Sally    120    135     10     15          1 tsk1     10\n4 Sally    120    135     10     15          1 tsk2     15\n5 Jim      150    150     11     24          1 tsk1     11\n6 Jim      150    150     11     24          1 tsk2     24\n7 Sue      115    120     NA     NA          1 tsk1     NA\n8 Sue      115    120     NA     NA          1 tsk2     NA\n\n\nAgain, 23abc24zis not included because of the strict pattern match."
  },
  {
    "objectID": "modules/12_manipulating_data_pivoting.html#pivoting-using-tidyrpivot_wider",
    "href": "modules/12_manipulating_data_pivoting.html#pivoting-using-tidyrpivot_wider",
    "title": "Transforming Data Frames: Pivoting",
    "section": "Pivoting using tidyr::pivot_wider()",
    "text": "Pivoting using tidyr::pivot_wider()\nThe help documentation describes that the function ‘“widens” data, increasing the number of columns and decreasing the number of rows’.\npivot_wider(\n  data,\n  ...,\n  id_cols = NULL,\n  id_expand = FALSE,\n  names_from = name,\n  names_prefix = \"\",\n  names_sep = \"_\",\n  names_glue = NULL,\n  names_sort = FALSE,\n  names_vary = \"fastest\",\n  names_expand = FALSE,\n  names_repair = \"check_unique\",\n  values_from = value,\n  values_fill = NULL,\n  values_fn = NULL,\n  unused_fn = NULL\n)\nKey Parameters/Arguments:\n\ndata: a data frame to pivot (if piped, does not need to be passed)\nid_cols: columns to pivot into longer format\nnames_from, values_from: a pair of arguments describing which column (or columns) to get the name of the output column (names_from), and which column (or columns) to get the cell values from (values_from)\n\n\nLONG |&gt;\n  pivot_wider(names_from = task, \n              values_from = score\n              )\n\n# A tibble: 4 × 7\n  name  `2023` `2024` task_A task_B  tsk1  tsk2\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Bill     175    170     10     12    10    12\n2 Sally    120    135     10     15    10    15\n3 Jim      150    150     11     24    11    24\n4 Sue      115    120     NA     NA    NA    NA\n\n\nAdding names_prefix = \"vocab_\" will append ‘vocab’ to the variable name, which reminds us that the task was a vocabulary task.\n\nLONG |&gt;\n  pivot_wider(names_from = task, \n              values_from = score,\n              names_prefix = \"vocab_\"\n              )\n\n# A tibble: 4 × 7\n  name  `2023` `2024` task_A task_B vocab_tsk1 vocab_tsk2\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Bill     175    170     10     12         10         12\n2 Sally    120    135     10     15         10         15\n3 Jim      150    150     11     24         11         24\n4 Sue      115    120     NA     NA         NA         NA\n\n\n#Because we provided the special character `.value` sentinel in the `names_to` argument, we do not have to specify a `values_to` argument and the value column will be derived from the existing column (HRmin, HRmax). In order to do that, we have to specify the `names_sep` argument in the function and specify how we want to split up the column names."
  },
  {
    "objectID": "modules/14_joining_relational_data.html",
    "href": "modules/14_joining_relational_data.html",
    "title": "Joining Relational Data",
    "section": "",
    "text": "In this module, we will cover how to join data frames that are related in some way. For example, perhaps you have multiple data frames containing data from the same participants and you need to combine them all so that you can summarize, visualize, or model the data. Students familiar with SQL (Structured Query Language) should have some experience with joining relational data. The joining or merging process is often a large component of data science projects, especially those that involve collaborators cleaning separate components that need to be merged together.\nYou can run SQL code within an R Markdown code block but there are other libraries like {sqldf} that allow you to include SQL to perform data queries.\nFor those who wish to dig deeper into learning SQL, there are tutorials here.\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\nJoining Data\n\n\n\n\n\n{here} 1.0.1: for file path management\n{dplyr} 1.1.4: for joining data frames\n\nMore generally:\n\n{tidyverse} 2.0.0: the tidyverse ecosystem\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "modules/14_joining_relational_data.html#readings-and-preparation",
    "href": "modules/14_joining_relational_data.html#readings-and-preparation",
    "title": "Joining Relational Data",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/14_joining_relational_data.html#libraries",
    "href": "modules/14_joining_relational_data.html#libraries",
    "title": "Joining Relational Data",
    "section": "",
    "text": "{here} 1.0.1: for file path management\n{dplyr} 1.1.4: for joining data frames\n\nMore generally:\n\n{tidyverse} 2.0.0: the tidyverse ecosystem\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "",
    "text": "We will explore some ways to examine relationships among variables. The focus will be on using Pearson’s r correlation to examine linear relationships and presenting a correlation matrix as a table. We will also visualize variable relationships in the form of scatterplots, faceted scatterplots, and generalized pairs plots.\n\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises.\n\n\n\n\n{here} 1.0.1: for file path management\n{dplyr} 1.1.4: for data frame manipulation\n{tidyr} 1.3.0: for data frame transformation\n{correlation} 0.8.4: for correlations; from {easystats} ecosystem\n{ggplot2} 3.4.4: for data visualization\n{GGally} 1.3.0: for generalized pairs plots\n\nOther: - {insight} 0.19.7: for model post processing"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#readings-and-preparation",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#readings-and-preparation",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "",
    "text": "Before Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#task",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#task",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Task",
    "text": "Task"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#libraries",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#libraries",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "",
    "text": "{here} 1.0.1: for file path management\n{dplyr} 1.1.4: for data frame manipulation\n{tidyr} 1.3.0: for data frame transformation\n{correlation} 0.8.4: for correlations; from {easystats} ecosystem\n{ggplot2} 3.4.4: for data visualization\n{GGally} 1.3.0: for generalized pairs plots\n\nOther: - {insight} 0.19.7: for model post processing"
  },
  {
    "objectID": "modules/18_linear_models.html",
    "href": "modules/18_linear_models.html",
    "title": "Linear Models",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/18_linear_models.html#readings-and-preparation",
    "href": "modules/18_linear_models.html#readings-and-preparation",
    "title": "Linear Models",
    "section": "Readings and Preparation",
    "text": "Readings and Preparation\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. I will assume that you attend class with some level of basic understanding of concepts and working of functions. The goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems. This cannot happen if you just read the content without interacting with it, however reading is absolutely essential to being successful during class time. Work through some examples so that you have a good idea of your level of understanding and confidence.\nClass: In class, some functions and concepts will be introduced and we will practice implementing code through exercises."
  },
  {
    "objectID": "modules/18_linear_models.html#libraries",
    "href": "modules/18_linear_models.html#libraries",
    "title": "Linear Models",
    "section": "Libraries",
    "text": "Libraries\n\n{here} 1.0.1: for file path management"
  },
  {
    "objectID": "modules/index.html",
    "href": "modules/index.html",
    "title": "Modules",
    "section": "",
    "text": "This course introduces students to R, a programming language for statistical computing and graphics. Students will learn how to clean, manipulate, transform, join, and tidy data sets to prepare for statistical modeling. Supervised (e.g., regression) and unsupervised (e.g., clustering) approaches will be applied to understand simple and complex relationships between cognitive and non-cognitive variables (e.g., biology, aging, education, socioeconomic, health, etc.). Students will apply their skills to wrangle, explore, and model relevant data sets for a hands-on project for local scholars, offices, organizations, or industry participants. Data sets and relevant readings will change depending on semester."
  },
  {
    "objectID": "modules/index.html#module-structure",
    "href": "modules/index.html#module-structure",
    "title": "Modules",
    "section": "Module structure",
    "text": "Module structure\nIn general, modules will contain readings, additional resources, and weekly assignments.\nThe modules will be updated across the semester as needed. There are more modules on this course site because some modules provide other useful information. The names of the modules listed in the syllabus, however, do match the names in the module listing."
  },
  {
    "objectID": "project/01_project_team_roles.html",
    "href": "project/01_project_team_roles.html",
    "title": "Team membership and roles",
    "section": "",
    "text": "Project roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating the team meeting time and location to me;\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data story line;\nFormatting, text, images, inline code (R code embedded in text if relevant), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (making sure teammates are pushing work to remote repo);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/01_project_team_roles.html#team-roles",
    "href": "project/01_project_team_roles.html#team-roles",
    "title": "Team membership and roles",
    "section": "",
    "text": "Project roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating the team meeting time and location to me;\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data story line;\nFormatting, text, images, inline code (R code embedded in text if relevant), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (making sure teammates are pushing work to remote repo);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/03_project_final.html",
    "href": "project/03_project_final.html",
    "title": "Final Presentation",
    "section": "",
    "text": "Overview\nThe final written report for the project will be delivered to me and to your liaison. I can provide a color-printed copy for you to distribute to the liaison. If the liaison is remote a color version of the pdf is appropriate.\n\n\nElements to Focus On\nFor the final presentation, you should focus on presenting a description of the problem, the data set used, data summaries, model interpretation, and visualization to help tell a story about your findings. You should make sure to address the key elements outlined in the project proposal and discussed with your liaison.\n\n\nPresentation Medium\nYou can use any slide-presentation tool you wish. You will just need to provide me with:\n\na printed version of the slide deck for class time and\nan electronic pdf of the slide deck before or after the presentation.\n\n\n\nStakeholders\nIdentify the stakeholders for your project. For example, include you liaison, liaison’s institution, course professor, your college, etc. for whom the final work will be submitted.\n\n\nEvaluation and Generalized Rubric\nMore detail will be added here similar to the Midterm Presentation.\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organization, models, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly worklogs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaison’s will also participate in evaluating all teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points.\n\n\nPresentation Tips\nSee tips for Midterm Presentation."
  },
  {
    "objectID": "project/05_project_tasks.html",
    "href": "project/05_project_tasks.html",
    "title": "Project Tasks",
    "section": "",
    "text": "Overview\nIn order to complete the project, there are different components that can be easily broken up and delegated among team members. During weekly team meetings, team members can discuss accomplishments and progress, and check off tasks. Provided many of you have never taken on such tasks and thought about how to break tasks into smaller bite-sized pieces, a general framework maybe be helpful for you.\n\n\nLarge-Scale Tasks\nSome tasks have to be performed in a sequential order but others can be integrated throughout other tasks. For example, describing the motivation of the project, explaining the data and variables used, describing how you prepared the data, presenting findings, etc. are all part of the Report Drafting process. Components can be, and should be, worked on in piecemeal so that they are all not delayed until the end.\n\nReview the project proposal details in /docs\nReview the CHAMP documents in /docs to understand the structure of the data and identify relevant variables\nSchedule to meet with liaison to discuss project in order to formulate a game plan; ask about variables of interest\nOutline the project plan and develop a timeline (consider how timeline maps onto course topics)\nRead data, clean and prepare data for summaries, visualizations, and models\nMerge data parts from team members\nIntegrate team member sub-goal code files\nFinalize report\n\nReport drafting. This tasks can get integrated within the other tasks. For example, delegating tasks, setting deadlines for rough drafts, etc.). Relevant references in /refs can be disseminated, read, and used to prepare the theoretical and conceptual motivation for the project.\n\n\nSmaller-Scale Tasks: A Suggested Process for working with Cognitive Tasks/Survey Questions\nTeams will be working with the symmetry span task, the go/no-go task, and other demographic and response variables. Some variables (viz., tasks or survey) will need to be parceled out and transformed (pivoted) in order to work with in a manageable way. Other response variables may contain only a single question and may require recoding (e.g., response options to numbers) but would not require transformation in the form of pivoting. When there are multiple response options (data columns) as there are with the cognitive tasks, a recommendation is the break the task into pieces.\nA recommended sub-goal process is described below\nA. Break full data into task/survey data\n\nImport master data file\nSelect variables of interest for that Task/Survey\nWrite out wide &lt;task&gt;_wide.Rds data file containing ids and variables for that task\n\nB. Clean the task/survey data\n\nTransform Data: Pivot wide to long\nWrite out long &lt;task&gt;_long.Rds data file\nClean, create, etc. relevant variables (not aggregated)\n\nC. Aggregate/Summarize task/survey data\n\nWrite out long task_long_clean.Rds data file\nAggregate/Summarize Data: Create participant level relevant data (e.g., average accuracy, average response time, etc.)\nWrite out long &lt;task&gt;_long_agg.Rds data file\n\nD. Prepare aggregated task/survey data for statistical description\n\nIf doing correlation with other variables, sometimes need to transform the data frame. If so:\nPivot long to wide\nWrite out long &lt;task&gt;_wide_agg.Rds data file\n\nE. Produce Data Summaries: Descriptive Statistics\nF. Generate any relevant visualizations * using either data that are aggregated or are not aggregated\nG. Modeling: Test relevant prediction(s)"
  },
  {
    "objectID": "resources/tools.html#websites",
    "href": "resources/tools.html#websites",
    "title": "Tools for Foundations of Data Science",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/"
  },
  {
    "objectID": "resources/tools.html#books",
    "href": "resources/tools.html#books",
    "title": "Tools for Foundations of Data Science",
    "section": "Books",
    "text": "Books\n\nLots of alternative books https://www.bigbookofr.com/data-visualization.html"
  },
  {
    "objectID": "slides/023_git.html#version-control",
    "href": "slides/023_git.html#version-control",
    "title": "Git and GitHub",
    "section": "Version Control",
    "text": "Version Control\n\n\nWhat is version control?\n\nProject backup\nSee specific changes inside files\nUndo changes (time machine)\n\nVersion Control Summary Video"
  },
  {
    "objectID": "slides/023_git.html#version-control-git-workflow-basics",
    "href": "slides/023_git.html#version-control-git-workflow-basics",
    "title": "Git and GitHub",
    "section": "Version Control: Git Workflow Basics",
    "text": "Version Control: Git Workflow Basics\nThere are three main parts to Git Workflow:\n\n\nVersion control for files (not empty directories)\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)\nVersion Control Workflow Basics"
  },
  {
    "objectID": "slides/023_git.html#connecting-git-to-github-the-rstudio-terminal",
    "href": "slides/023_git.html#connecting-git-to-github-the-rstudio-terminal",
    "title": "Git and GitHub",
    "section": "Connecting Git to GitHub: The RStudio Terminal",
    "text": "Connecting Git to GitHub: The RStudio Terminal\n\n\nConfigure Git and GitHub in RStudio Terminal\nCreate token\nSet token\nCan use the RStudio Gui (clunky though)"
  },
  {
    "objectID": "slides/023_git.html#configuring-git-and-github-with-usethis",
    "href": "slides/023_git.html#configuring-git-and-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Configuring Git and GitHub with {usethis}",
    "text": "Configuring Git and GitHub with {usethis}\n\nusethis::use_git_config(user.name = \"janegit\", \n                        user.email = \"jane_git@gitrdone.com\"\n                        )"
  },
  {
    "objectID": "slides/023_git.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "href": "slides/023_git.html#creating-a-personal-access-token-pat-for-github-with-usethis",
    "title": "Git and GitHub",
    "section": "Creating a Personal Access Token (PAT) for GitHub with {usethis}",
    "text": "Creating a Personal Access Token (PAT) for GitHub with {usethis}\n\n\nusethis::create_github_token()\nCreate token and copy to your clipboard"
  },
  {
    "objectID": "slides/023_git.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "href": "slides/023_git.html#setting-your-git-credentials-using-pat-with-gitcreds",
    "title": "Git and GitHub",
    "section": "Setting your Git Credentials (using PAT) with {gitcreds}",
    "text": "Setting your Git Credentials (using PAT) with {gitcreds}\n\n\ngitcreds::gitcreds_set()\nChoose option to either set or replace\nAt ? Enter new password or token, paste PAT to set\ngh::gh_whoami() to check if set"
  },
  {
    "objectID": "slides/023_git.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "slides/023_git.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Git and GitHub",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\n\nMake a change to a file\nCheck status of project for changes\nStage change\nCommit all changes\nPush changes\nCommit a specific change\nPull changes down from repo (downloads and integrates changes)\nFetch downloads new data (does not change your working copy)"
  },
  {
    "objectID": "slides/023_git.html#checking-the-status-of-local-file-changes",
    "href": "slides/023_git.html#checking-the-status-of-local-file-changes",
    "title": "Git and GitHub",
    "section": "Checking the status of local file changes",
    "text": "Checking the status of local file changes\nAt the Terminal in RStudio\n\n$ git status"
  },
  {
    "objectID": "slides/023_git.html#staging-changes-adding-changes",
    "href": "slides/023_git.html#staging-changes-adding-changes",
    "title": "Git and GitHub",
    "section": "Staging Changes (Adding Changes)",
    "text": "Staging Changes (Adding Changes)\n\n\nStaging and Committing\n\nUntracked vs. tracked files\nTo have tracked by Git, you need to add"
  },
  {
    "objectID": "slides/023_git.html#staging-a-specific-change",
    "href": "slides/023_git.html#staging-a-specific-change",
    "title": "Git and GitHub",
    "section": "Staging a Specific Change",
    "text": "Staging a Specific Change\n\n\n$ git add &lt;file&gt;... such that &lt;file&gt; refers to the file name\nfile might be in a directory, e.g., r/\n$ git add r/yourname.R\nTab to auto-complete, e.g., git add r/you{TAB}"
  },
  {
    "objectID": "slides/023_git.html#staging-all-changes",
    "href": "slides/023_git.html#staging-all-changes",
    "title": "Git and GitHub",
    "section": "Staging All Changes",
    "text": "Staging All Changes\n\n$ git add ."
  },
  {
    "objectID": "slides/023_git.html#committing-the-changes",
    "href": "slides/023_git.html#committing-the-changes",
    "title": "Git and GitHub",
    "section": "Committing the Change(s)",
    "text": "Committing the Change(s)\n\n\ngit commit is used to commit the changes\nadd -m to tell git you want a message (e.g., \"my message here\")\n\n$ git commit -m \"added my first .R file\""
  },
  {
    "objectID": "slides/023_git.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "href": "slides/023_git.html#push-publish-the-changes-from-your-branch-to-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Push (publish) the change(s) from your branch to the remote repository",
    "text": "Push (publish) the change(s) from your branch to the remote repository\n\n\n$ git push\nPushing changes"
  },
  {
    "objectID": "slides/023_git.html#pulls-changes-from-the-remote-repository",
    "href": "slides/023_git.html#pulls-changes-from-the-remote-repository",
    "title": "Git and GitHub",
    "section": "Pulls change(s) from the remote repository",
    "text": "Pulls change(s) from the remote repository\n\n\n$ git pull\nIf you make changes that other will need, let them know to pull"
  },
  {
    "objectID": "slides/023_git.html#fetch-changes",
    "href": "slides/023_git.html#fetch-changes",
    "title": "Git and GitHub",
    "section": "Fetch changes",
    "text": "Fetch changes"
  },
  {
    "objectID": "slides/023_git.html#video-tutorials",
    "href": "slides/023_git.html#video-tutorials",
    "title": "Git and GitHub",
    "section": "Video Tutorials",
    "text": "Video Tutorials\n\n\nGitKraken Git Client examples\nfor more, see: this video"
  },
  {
    "objectID": "slides/023_git.html#videos-of-many-things-you-can-do",
    "href": "slides/023_git.html#videos-of-many-things-you-can-do",
    "title": "Git and GitHub",
    "section": "Videos of many things you can do",
    "text": "Videos of many things you can do\nIf interested, see gittower YouTube"
  },
  {
    "objectID": "slides/03_functions_slides.html#some-object-types",
    "href": "slides/03_functions_slides.html#some-object-types",
    "title": "Functions, Parameters, and Arguments",
    "section": "Some Object Types",
    "text": "Some Object Types\n\n\nnumeric objects: representing numeric information (e.g., one’s age)\ncharacter objects: representing character information (e.g., one’s name or race)\nvector objects: representing more than one numeric object (e.g., ages of participants)\ndata frame objects: containing vectors of data (e.g., column variables and row instances of data)\nfunction objects: that accept one object and return an other object (e.g., the mean of numeric vector)"
  },
  {
    "objectID": "slides/03_functions_slides.html#object-assignment",
    "href": "slides/03_functions_slides.html#object-assignment",
    "title": "Functions, Parameters, and Arguments",
    "section": "Object Assignment",
    "text": "Object Assignment\n\n\nObjects need names\nObtained through assignment\n\nname is assigned an object; or\nobject is set to name\n\nAssignment operator &lt;-\n\nex: age &lt;- 22\nex: age &lt;- as.numeric(c(\"22\", \"25\", \"19\"))"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-objects",
    "href": "slides/03_functions_slides.html#function-objects",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Objects",
    "text": "Function Objects\n\nFunctions are special objects which contain statements for carrying out operations\n\nc() or Hmisc::Cs(): to combine elements into a vector\nmean(): to compute the mean of a numeric vector\nsource(): for reading/executing R code\ndplyr::mutate(): for creating variables in data frames\nrio::import() or readr::read_csv(): for reading data files\nreadRDS(): for reading compressed data files"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-characteristics",
    "href": "slides/03_functions_slides.html#function-characteristics",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Characteristics",
    "text": "Function Characteristics\n5 terms concepts to know:\n\n\nname (created by assignment operator &lt;-)\ndefinition (code statements or instructions for its usage)\narguments (optional variables that specify the function’s operation)\nfunction call (e.g., execution of a function)\nreturned object (value returned from the executed function)"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-statements-without-parameterargument",
    "href": "slides/03_functions_slides.html#function-statements-without-parameterargument",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Statements without Parameter/Argument",
    "text": "Function Statements without Parameter/Argument\n\n\nmy_function &lt;- function() {\n\n    statements/instructions to do something\n\n    \n    return(result of instructions)\n\n}"
  },
  {
    "objectID": "slides/03_functions_slides.html#function-example-with-parameterargument",
    "href": "slides/03_functions_slides.html#function-example-with-parameterargument",
    "title": "Functions, Parameters, and Arguments",
    "section": "Function Example with Parameter/Argument",
    "text": "Function Example with Parameter/Argument\n\n\n\nget_years_since_birth &lt;- function(dob) {\n  if (!hasArg(dob)) {\n      message(\"Error: dob missing/no argument provided\")\n    } \n  else {\n    # make string a data\n    dob = lubridate::as_date(dob) \n    # obtain the difference in time in days\n    diff = difftime(time1 = Sys.Date(), time2 = dob, units = \"days\")\n    # create age based on days in year\n    age = as.numeric(diff / 365.25)\n    # return the age in years, truncated \n    return(trunc(age))\n  }\n}"
  },
  {
    "objectID": "slides/03_functions_slides.html#functions-in-libraries",
    "href": "slides/03_functions_slides.html#functions-in-libraries",
    "title": "Functions, Parameters, and Arguments",
    "section": "Functions in Libraries",
    "text": "Functions in Libraries\n\n\n{dplyr}: for wrangling data frames\n{ggplot2}: for plotting data\n{tidyverse}: for loading all libraries in the tidyverse ecosystem\n{easystats}: for loading all libraries in the easystats ecosystem"
  },
  {
    "objectID": "slides/03_functions_slides.html#loadingimporting-functions-from-libraries",
    "href": "slides/03_functions_slides.html#loadingimporting-functions-from-libraries",
    "title": "Functions, Parameters, and Arguments",
    "section": "Loading/Importing Functions from Libraries",
    "text": "Loading/Importing Functions from Libraries\n\n\nLoading all functions:\n\nlibrary(dplyr)\n\nLoading order matters: Function of the same name will overwrite others"
  },
  {
    "objectID": "slides/03_functions_slides.html#calling-functions-from-libraries",
    "href": "slides/03_functions_slides.html#calling-functions-from-libraries",
    "title": "Functions, Parameters, and Arguments",
    "section": "Calling Functions from Libraries",
    "text": "Calling Functions from Libraries\n\n\nIf loaded:\n\nmutate() (from {dplyr})\n\nIf not loaded:\n\neeptools::age_calc(): for calculating age based on a date\n:: calls ensures choice (duplicate function names in different libraries)"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#knowing-file-delimiters",
    "href": "slides/05_importing_and_exporting_slides.html#knowing-file-delimiters",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Knowing File Delimiters",
    "text": "Knowing File Delimiters\nname, age, sex, location, marital_stat \nSally, 28, Female, Michigan, Married"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#knowing-file-delimiters-1",
    "href": "slides/05_importing_and_exporting_slides.html#knowing-file-delimiters-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Knowing File Delimiters",
    "text": "Knowing File Delimiters\nname, age, sex, location, marital_stat \nSally, 28, Female, Michigan, Married\n\n\nname; age; sex; location; marital_stat \nSally; 28; Female; Michigan; Married\n\n\ndata are stored in files as text\ndelimiters: characters that separate text strings\ncommas, semicolons, tabs, special characters, etc.\ndelimiters help you parse data into meaningful pieces"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#knowing-file-extensions",
    "href": "slides/05_importing_and_exporting_slides.html#knowing-file-extensions",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Knowing File Extensions",
    "text": "Knowing File Extensions\nFile extensions often tell you something about how the delimiter and the format of the contents/data inside the file.\n\n\n.csv: comma-separated value files\n.Rds: compressed R data frame files\n.tsv: tab-separated value files\n.sav: SPSS data files\n.xlsx: Excel Workbook files\n… and others"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#knowing-the-libraries-for-file-types",
    "href": "slides/05_importing_and_exporting_slides.html#knowing-the-libraries-for-file-types",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Knowing the Libraries for File Types",
    "text": "Knowing the Libraries for File Types\nDifferent libraries have options for opening\n\n\n.csv/.tsv with base R or {readr}\n.Rds with base R or even {readr}\n.sav with {foreign} or {haven}\n.xlsx with {readxl}\n{vroom} will try to guess, see vroom::vroom()"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#importing-with-readrread_csv",
    "href": "slides/05_importing_and_exporting_slides.html#importing-with-readrread_csv",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Importing with readr::read_csv()",
    "text": "Importing with readr::read_csv()\n\nreadr::read_csv(file = &lt;the_file_path&gt;,\n                col_names = TRUE\n                )\n\n\nKey parameters: file & col_names\nBy default, column/variable names are assumed to exist: col_names = TRUE"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#importing-with-readrread_csv-1",
    "href": "slides/05_importing_and_exporting_slides.html#importing-with-readrread_csv-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Importing with readr::read_csv()",
    "text": "Importing with readr::read_csv()\n\nreadr::read_csv(file = &lt;the_file_path&gt;,\n                col_names = FALSE\n                )\n\n\nIf no column/variable names: col_names = FALSE"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#importing-with-readrds",
    "href": "slides/05_importing_and_exporting_slides.html#importing-with-readrds",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Importing with readRDS()",
    "text": "Importing with readRDS()\n\nreadRDS(file = &lt;the_file_path&gt;, \n        refhook = NULL\n        )\n\nKey parameter: file"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#importing-with-readrds-1",
    "href": "slides/05_importing_and_exporting_slides.html#importing-with-readrds-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Importing with readRDS()",
    "text": "Importing with readRDS()\nPassing the file path to file:\n\nreadRDS(file = here::here(\"data\", \"file_name.Rds\"))"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#importing-to-an-object",
    "href": "slides/05_importing_and_exporting_slides.html#importing-to-an-object",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Importing to an Object",
    "text": "Importing to an Object\n\n\nRemember to assign the imported data\n&lt;data_frame_name&gt; &lt;- readRDS(...)\n&lt;data_frame_name&gt; &lt;- readr::read_csv(...)"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#exporting-with-saverds",
    "href": "slides/05_importing_and_exporting_slides.html#exporting-with-saverds",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Exporting with saveRDS()",
    "text": "Exporting with saveRDS()\n\nsaveRDS(object = &lt;data_frame_object&gt;, \n        file = &lt;the_file_path&gt;, \n        ascii = FALSE, \n        version = NULL,\n        compress = TRUE, \n        refhook = NULL\n        )\n\n\nKey parameters: object & file"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#exporting-with-saverds-1",
    "href": "slides/05_importing_and_exporting_slides.html#exporting-with-saverds-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Exporting with saveRDS()",
    "text": "Exporting with saveRDS()\nPassing the data frame to object and the file path to file:\n\nsaveRDS(object = &lt;data_frame_object&gt;, \n        file = here::here(\"data\", \"file_name.Rds\")\n        )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#exporting-with-saverds-2",
    "href": "slides/05_importing_and_exporting_slides.html#exporting-with-saverds-2",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Exporting with saveRDS()",
    "text": "Exporting with saveRDS()\nAs long you pass arguments are passed in the same order as their intended parameters, you don’t need parameter specification.\n\nsaveRDS(&lt;data_frame_object&gt;, \n        here::here(\"data\", \"file_name.Rds\")\n        )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#viewing-data-frames",
    "href": "slides/05_importing_and_exporting_slides.html#viewing-data-frames",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Viewing Data Frames",
    "text": "Viewing Data Frames\n\n\nhead()/tail(): top/bottom rows of data frame\nView(): view in tab, from base R or tibble::view()\n* view_html(): view in Viewer, external function (will take longer)\ndim():\nstr(): the data structure (variables/columns), from base R\n* dplyr::glimpse(): better str() alternative"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#taking-inventory-of-variable-names",
    "href": "slides/05_importing_and_exporting_slides.html#taking-inventory-of-variable-names",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Taking Inventory of Variable Names",
    "text": "Taking Inventory of Variable Names\n\n\nAre variable names in a standard format (e.g., all lowercase)?\nAre _ used for readability (avoid camelCase)?\nAre variable names coherent?\nMake a list of what needs fixing/cleaning"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#taking-inventory-of-variable-data-types",
    "href": "slides/05_importing_and_exporting_slides.html#taking-inventory-of-variable-data-types",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Taking Inventory of Variable Data Types",
    "text": "Taking Inventory of Variable Data Types\n\n\nAre numeric variables numeric?\nAre factor variables factors?\nAre ordered factors ordered?\nDo extra characters, spaces, etc. need to be removed?\nMake a list of what needs fixing/cleaning"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#inspecting-taking-inventory-assessing-variable-types-using-glimpse",
    "href": "slides/05_importing_and_exporting_slides.html#inspecting-taking-inventory-assessing-variable-types-using-glimpse",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Inspecting Taking Inventory: Assessing Variable Types Using glimpse()",
    "text": "Inspecting Taking Inventory: Assessing Variable Types Using glimpse()\n&lt;DATA_FRAME&gt; |&gt; glimpse()"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#standardizingcleaning-variable-names",
    "href": "slides/05_importing_and_exporting_slides.html#standardizingcleaning-variable-names",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Standardizing/Cleaning Variable Names",
    "text": "Standardizing/Cleaning Variable Names"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#assessing-variable-names-using-names",
    "href": "slides/05_importing_and_exporting_slides.html#assessing-variable-names-using-names",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Assessing Variable Names Using names()",
    "text": "Assessing Variable Names Using names()\nnames(&lt;data_frame&gt;)\n\n[1] \"name\"  \"age\"  \"sex\"  \"location\"  \"marital_stat\""
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variables-using-names",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variables-using-names",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variables Using names()",
    "text": "Renaming Variables Using names()\nnames(&lt;data_frame&gt;)\n\n[1] \"name\"  \"age\"  \"sex\"  \"location\"  \"marital_stat\" \n\n\nBecause names(&lt;data_frame&gt;) contains a vector of variable names, we can assign a vector of different names to the object.\nnames(&lt;data_frame&gt;) &lt;- c(\"first_name\", \"age\", \"sex\", \"location\", \"marital_status\")"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variables-popular-options",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variables-popular-options",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variables: Popular Options",
    "text": "Renaming Variables: Popular Options\nTo make the names lower case we can fix them with tolower() and assign them back.\nnames(&lt;data_frame&gt;)\n\n[1] \"Name\"  \"AGE\"  \"sEx\"  \"LocatioN\"  \"marital_stat\" \n\n\nnames(&lt;data_frame&gt;) &lt;- tolower(names(&lt;data_frame&gt;))\nor used dplyr::rename_with(...) and along with tolower()"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variables-using-dplyrrename_with",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variables-using-dplyrrename_with",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variables Using dplyr::rename_with()",
    "text": "Renaming Variables Using dplyr::rename_with()\nrename_with(.data,\n            .fn, \n            .cols\n            )\n\nOffers greater control, more complex:\n\n.data: the data frame containing the variables\n.fn: the function for renaming\n.cols: the columns to rename"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-all-variables-using-everything",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-all-variables-using-everything",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming All Variables Using everything()",
    "text": "Renaming All Variables Using everything()\nrename_with(.data = &lt;data_frame&gt;,    \n            .fn = tolower,           # apply to lower too\n            .cols = everything()     # everything(), all variables\n            )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variables-using-dplyrrename_with-and",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variables-using-dplyrrename_with-and",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variables Using dplyr::rename_with() and |>",
    "text": "Renaming Variables Using dplyr::rename_with() and |&gt;\nAssuming piping using |&gt; or %&gt;%, .data is omitted because it’s inherited from the piping procedure.\n&lt;DATA_FRAME&gt; |&gt; \n     rename_with(.fn = tolower,           \n                 .cols = everything()\n                 )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-all-variables-using-everything-1",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-all-variables-using-everything-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming All Variables Using everything()",
    "text": "Renaming All Variables Using everything()\nrename_with(.data = &lt;data_frame&gt;,    \n            .fn = tolower,           # apply to lower too\n            .cols = everything()     # everything(), all variables\n            )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variable-by-position-in-vector",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variable-by-position-in-vector",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variable by Position in Vector",
    "text": "Renaming Variable by Position in Vector\nrename_with(.data = &lt;data_frame&gt;,    \n            .fn = tolower,           # apply to lower too\n            .cols = 1:5              # columns 1 through 5\n            )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variables-by-characters-starts_with",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variables-by-characters-starts_with",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variables by Characters starts_with()",
    "text": "Renaming Variables by Characters starts_with()\nrename_with(.data = &lt;data_frame&gt;,    \n            .fn = tolower,            # apply to lower too\n            .cols = starts_with(\"w\")  # columns 1 through 5\n            )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#replacingremoving-characters-using-gsub",
    "href": "slides/05_importing_and_exporting_slides.html#replacingremoving-characters-using-gsub",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Replacing/Removing Characters Using gsub()",
    "text": "Replacing/Removing Characters Using gsub()\nParameters/Arguments:\n\npattern: character string (or regular expression) to find (needle)\nx, text: a character vector w/in which the pattern exists (haystack)\nreplacement: a character replacement for pattern matches\n… others"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#replacingremoving-characters-using-gsub-1",
    "href": "slides/05_importing_and_exporting_slides.html#replacingremoving-characters-using-gsub-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Replacing/Removing Characters Using gsub()",
    "text": "Replacing/Removing Characters Using gsub()\nReplace spaces with nothing\n\ngsub(pattern = \" \",                         # a space character                \n     replacement = \"\",                      # empty string            \n     x = c(\"Bill    \", \"Sally \", \"  Joe\"),  # the vector to match               \n     ignore.case = FALSE, \n     perl = FALSE,\n     fixed = FALSE, \n     useBytes = FALSE\n     )\n\n[1] \"Bill\"  \"Sally\" \"Joe\""
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#replacingremoving-characters-cont.",
    "href": "slides/05_importing_and_exporting_slides.html#replacingremoving-characters-cont.",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Replacing/Removing Characters (Cont.)",
    "text": "Replacing/Removing Characters (Cont.)\nFor more complicated string repair, use {stringr} but will will address later.\nstringr::str_replace_all()\n\nstringr::str_replace_all(\n  string = c(\"B-i-l-l    \", \"S-all-y \", \"  $Joe\"), \n  pattern = \"[\\\\$\\\\s-]\",\n  replacement = \"\"\n  )\n\n[1] \"Bill\"  \"Sally\" \"Joe\"  \n\n\n\n\n\nDo characters response values need to be recoded into numbers?\nDo number response values to be recoded to characters/factors?"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#taking-inventory-assessing-values",
    "href": "slides/05_importing_and_exporting_slides.html#taking-inventory-assessing-values",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Taking Inventory: Assessing Values",
    "text": "Taking Inventory: Assessing Values\n\n\nDo extra characters, spaces, etc. need to be removed?\nDo characters response values need to be recoded into numbers?\nDo number response values to be recoded to characters/factors?"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#renaming-variables",
    "href": "slides/05_importing_and_exporting_slides.html#renaming-variables",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Renaming Variables",
    "text": "Renaming Variables\n\n\ndplyr::rename() and dplyr::rename_with():"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position",
    "href": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Relocating/Moving Variable Position",
    "text": "Relocating/Moving Variable Position\nWe can use dplyr::relocate() to move variable positions in the data frame"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position-using-relocate",
    "href": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position-using-relocate",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Relocating/Moving Variable Position Using relocate()",
    "text": "Relocating/Moving Variable Position Using relocate()\nParameters/Arguments”\n\n.data: a data frame\n...: columns to move\n.before, .after: Destination of columns selected by …. Supplying neither will move columns to the left-hand side; specifying both is an error"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position-using-relocate-1",
    "href": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position-using-relocate-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Relocating/Moving Variable Position Using relocate()",
    "text": "Relocating/Moving Variable Position Using relocate()\nAssuming you are piping using |&gt; or %&gt;%:\n&lt;DATA_FRAME&gt; |&gt; \n     relocate(...)"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position-using-relocate-2",
    "href": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variable-position-using-relocate-2",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Relocating/Moving Variable Position Using relocate()",
    "text": "Relocating/Moving Variable Position Using relocate()\n\n\nrelocate(d, .before = a): move relative to another variable\nrelocate(a, .after = c)\nrelocate(a, b, .after = c): move more than one\nrelocate(d, .before = 1): move relative to a variable position"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variables-by-vector",
    "href": "slides/05_importing_and_exporting_slides.html#relocatingmoving-variables-by-vector",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Relocating/Moving Variables By Vector",
    "text": "Relocating/Moving Variables By Vector\n\n\nrelocate(c(b, a), .before = c)\nrelocate(c(\"b\", \"a\"), .before = c): when character vector"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#functions-for-changing-variable-type",
    "href": "slides/05_importing_and_exporting_slides.html#functions-for-changing-variable-type",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Functions for Changing Variable Type",
    "text": "Functions for Changing Variable Type\n\n\nas.numeric(), as.character(), etc.\nas.factor() or forcats::as_factor()\nforcats::as_ordered(): for ordered factor\nforcats::fct_lump(): for other category\ncar::Recode(): for recoding values (e.g., 1='male', 'male'=1, etc.)"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect",
    "href": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Selecting Data for Subsets Using dplyr::select()",
    "text": "Selecting Data for Subsets Using dplyr::select()\nselect(.data,\n       ...\n       )\n\nOffers greater control, more complex:\n\n.data: the data frame containing the variables\n...: the variable names, vector of names, etc."
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect-1",
    "href": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Selecting Data for Subsets Using dplyr::select()",
    "text": "Selecting Data for Subsets Using dplyr::select()\n\n\nby name, select(a, b, c, d)\nfor a sequence, select(a:d)\ndplyr::starts_with(): beginning characters\ndplyr::ends_with(): ending characters\ndplyr::contains(): containing characters/regex"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect-2",
    "href": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect-2",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Selecting Data for Subsets Using dplyr::select()",
    "text": "Selecting Data for Subsets Using dplyr::select()\n&lt;DATA_FRAME&gt; |&gt;\n  select(c, d)"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect-3",
    "href": "slides/05_importing_and_exporting_slides.html#selecting-data-for-subsets-using-dplyrselect-3",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Selecting Data for Subsets Using dplyr::select()",
    "text": "Selecting Data for Subsets Using dplyr::select()\n&lt;DATA_FRAME&gt; |&gt;\n  select(starts_with(\"rt_\"))"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#removing-spaces-using-mutate-gsub",
    "href": "slides/05_importing_and_exporting_slides.html#removing-spaces-using-mutate-gsub",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Removing Spaces Using mutate() + gsub()",
    "text": "Removing Spaces Using mutate() + gsub()\n\n&lt;data_frame&gt; |&gt;  \n   mutate(variable_name = gsub(\" \", \"\", variable_name))`"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#removing-spaces-using-mutate-gsub-1",
    "href": "slides/05_importing_and_exporting_slides.html#removing-spaces-using-mutate-gsub-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Removing Spaces Using mutate() + gsub()",
    "text": "Removing Spaces Using mutate() + gsub()\nSpecify .data if not piping:\nmutate(.data = &lt;data_frame&gt;,\n       variable_name = gsub(\" \", \"\", variable_name)\n       )"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#removing-spaces-using-mutate-gsub-2",
    "href": "slides/05_importing_and_exporting_slides.html#removing-spaces-using-mutate-gsub-2",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Removing Spaces Using mutate() + gsub()",
    "text": "Removing Spaces Using mutate() + gsub()\nWhen piping the data frame, .data is inherited:\n&lt;data_frame&gt; |&gt;  \n   mutate(variable_name = gsub(\" \", \"\", variable_name))`"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#pipe-pipe-pipe",
    "href": "slides/05_importing_and_exporting_slides.html#pipe-pipe-pipe",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Pipe, Pipe, Pipe",
    "text": "Pipe, Pipe, Pipe\n&lt;data_frame&gt; |&gt;         # pipe data frame to...\n   # rename the variables...\n   rename_with(...) |&gt;  # pipe modifed data frame to...\n   \n   # change the contents of the varbiable\n   mutate(...)          # pipe modified-modified data frame to... \n   \n   # move the location of variable(s)\n   relocate(...)"
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#pipe-pipe-pipe-and-assign",
    "href": "slides/05_importing_and_exporting_slides.html#pipe-pipe-pipe-and-assign",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Pipe, Pipe, Pipe, and Assign",
    "text": "Pipe, Pipe, Pipe, and Assign\nOnce you are sure the code works as planned, assign."
  },
  {
    "objectID": "slides/05_importing_and_exporting_slides.html#pipe-pipe-pipe-and-assign-1",
    "href": "slides/05_importing_and_exporting_slides.html#pipe-pipe-pipe-and-assign-1",
    "title": "Importing, Exporting, and Inspecting Data",
    "section": "Pipe, Pipe, Pipe, and Assign",
    "text": "Pipe, Pipe, Pipe, and Assign\nOnce you are sure the code works as planned, assign.\n&lt;data_frame&gt; &lt;-        # reassign the data frame with new content\n   &lt;data_frame&gt; |&gt;     # pipe data frame to...\n\n   # rename the variables...\n   rename_with(...) |&gt; # pipe modifed data frame to...\n   \n   # change the contents of the varbiable\n   mutate(...) |&gt;      # pipe modified-modified data frame to... \n   \n   # move the location of variable(s)\n   relocate(...)"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#step-1",
    "href": "slides/07_wrangling_data_slides.html#step-1",
    "title": "Wrangling Data",
    "section": "Step 1",
    "text": "Step 1\n\nSplit slides up with level 2 headers: ## Heading 2\nAdd some markdown + text and/or some R/Python code"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#some-r-code",
    "href": "slides/07_wrangling_data_slides.html#some-r-code",
    "title": "Wrangling Data",
    "section": "Some R Code",
    "text": "Some R Code\n\n2 + 2\n\n[1] 4\n\n# comment"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#slide-title",
    "href": "slides/07_wrangling_data_slides.html#slide-title",
    "title": "Wrangling Data",
    "section": "Slide Title",
    "text": "Slide Title\n\none\ntwo"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#make-this-slide-red",
    "href": "slides/07_wrangling_data_slides.html#make-this-slide-red",
    "title": "Wrangling Data",
    "section": "Make this slide Red",
    "text": "Make this slide Red"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#making-a-slide-incremental",
    "href": "slides/07_wrangling_data_slides.html#making-a-slide-incremental",
    "title": "Wrangling Data",
    "section": "Making a Slide Incremental",
    "text": "Making a Slide Incremental\nSay you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.\n\nThen add some content…\n\n\nThen some more content"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#omit-this-slide-visibility-hidden",
    "href": "slides/07_wrangling_data_slides.html#omit-this-slide-visibility-hidden",
    "title": "Wrangling Data",
    "section": "Omit This Slide {visibility = “hidden”}",
    "text": "Omit This Slide {visibility = “hidden”}"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#add-links",
    "href": "slides/07_wrangling_data_slides.html#add-links",
    "title": "Wrangling Data",
    "section": "Add links",
    "text": "Add links\n\ncmc\n\n\n\nFirst item\nSecond item"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#fragments",
    "href": "slides/07_wrangling_data_slides.html#fragments",
    "title": "Wrangling Data",
    "section": "Fragments",
    "text": "Fragments\n\nFade in\n\n\nFade out\n\n\nHighlight red\n\n\nFade in, then out"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#fragments-nesting",
    "href": "slides/07_wrangling_data_slides.html#fragments-nesting",
    "title": "Wrangling Data",
    "section": "Fragments, nesting",
    "text": "Fragments, nesting\n\n\n\nFade in &gt; Turn red &gt; Semi fade out"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#fragments-spans",
    "href": "slides/07_wrangling_data_slides.html#fragments-spans",
    "title": "Wrangling Data",
    "section": "Fragments, spans",
    "text": "Fragments, spans\nThis is an important sentence!\nMind the gap when riding the rail!"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#column-layout",
    "href": "slides/07_wrangling_data_slides.html#column-layout",
    "title": "Wrangling Data",
    "section": "Column layout",
    "text": "Column layout\n\n\ncontents…s\n\ncontents…"
  },
  {
    "objectID": "slides/07_wrangling_data_slides.html#output-location",
    "href": "slides/07_wrangling_data_slides.html#output-location",
    "title": "Wrangling Data",
    "section": "Output Location",
    "text": "Output Location\n\n\nlibrary(ggplot2)\n\nmtcars |&gt; \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\")"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#libraries",
    "href": "slides/09_summarizing_data_advanced_slides.html#libraries",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Libraries",
    "text": "Libraries\n\n{tibble}, {dplyr}"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#create-a-data-frame",
    "href": "slides/09_summarizing_data_advanced_slides.html#create-a-data-frame",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Create a Data Frame",
    "text": "Create a Data Frame\n\nDATA &lt;- tribble(\n  ~id, ~group, ~x, ~y,\n  1, \"a\", 11, 30,\n  2, \"a\", 21, 20,\n  3, \"a\", 13, 33,\n  4, \"b\", 51, NA,\n  5, \"b\", 44, 20,\n  6, \"b\", NA, 19\n)"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#variable-2-metrics",
    "href": "slides/09_summarizing_data_advanced_slides.html#variable-2-metrics",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "1 Variable, 2 Metrics",
    "text": "1 Variable, 2 Metrics\n\nDATA |&gt;\n  summarize(x = mean(x, na.rm = TRUE),\n            x_median = median(x, na.rm = TRUE)\n            )\n\n# A tibble: 1 × 2\n      x x_median\n  &lt;dbl&gt;    &lt;dbl&gt;\n1    28       28\n\n\n\nWarning: The mean and median of x are the same. The median() is computed based on the new value of x that is assigned by the first line in summarize() (e.g., x = mean(x, na.rm = TRUE)). You would want to use a new variable name."
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#variable-2-metrics-cont.",
    "href": "slides/09_summarizing_data_advanced_slides.html#variable-2-metrics-cont.",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "1 Variable, 2 Metrics (Cont.)",
    "text": "1 Variable, 2 Metrics (Cont.)\nAssigning to names other than x:\n\nDATA |&gt;\n  summarize(mean = mean(x, na.rm = TRUE),\n            median = median(x, na.rm = TRUE)\n            )\n\n# A tibble: 1 × 2\n   mean median\n  &lt;dbl&gt;  &lt;dbl&gt;\n1    28     21\n\n\nNOTE: The mean and median of x differ."
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#variables-1-metric",
    "href": "slides/09_summarizing_data_advanced_slides.html#variables-1-metric",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "2 Variables, 1 Metric",
    "text": "2 Variables, 1 Metric\n\nDATA |&gt;\n  summarize(x_mean = mean(x, na.rm = TRUE),\n            y_mean = mean(y, na.rm = TRUE),\n            )\n\n# A tibble: 1 × 2\n  x_mean y_mean\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     28   24.4"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#variables-2-metrics",
    "href": "slides/09_summarizing_data_advanced_slides.html#variables-2-metrics",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "2 Variables, 2 Metrics",
    "text": "2 Variables, 2 Metrics\n\nDATA |&gt;\n  summarize(x_mean = mean(x, na.rm = TRUE),\n            y_mean = mean(y, na.rm = TRUE),\n            x_median = median(x, na.rm = TRUE),\n            y_median = median(y, na.rm = TRUE)\n            )\n\n# A tibble: 1 × 4\n  x_mean y_mean x_median y_median\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     28   24.4       21       20"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#variables-2-metrics-with-grouping",
    "href": "slides/09_summarizing_data_advanced_slides.html#variables-2-metrics-with-grouping",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "2 Variables, 2 Metrics with Grouping",
    "text": "2 Variables, 2 Metrics with Grouping\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(x_mean = mean(x, na.rm = TRUE),\n            y_mean = mean(x, na.rm = TRUE),\n            x_median = median(x, na.rm = TRUE),\n            y_median = median(x, na.rm = TRUE)\n            )\n\n# A tibble: 2 × 5\n  group x_mean y_mean x_median y_median\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 a       15     15       13       13  \n2 b       47.5   47.5     47.5     47.5"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#summarizing-across-with-dplyracross",
    "href": "slides/09_summarizing_data_advanced_slides.html#summarizing-across-with-dplyracross",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Summarizing Across with dplyr::across()",
    "text": "Summarizing Across with dplyr::across()\nacross() is used when you want to iterate a function or set of functions across a multiple variables. The function will require you to pass arguments for the columns you want to summarize, the function(s) specifying how to summarize, and the names of the new output variables.\nacross(.cols, \n       .fns, ..., \n       .names = NULL, \n       .unpack = FALSE\n       )"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-parametersarguments",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-parametersarguments",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Parameters/Arguments",
    "text": "dplyr::across(): Parameters/Arguments\n\n\n.cols: the columns to perform a function upon\n.fns: the function(s) to apply to the column in .cols\n.names: a glue specification that describes how to name the output columns; use {.col} to stand for the selected column name, and {.fn} for the function being applied; defaults to \"{col}_{fn}\""
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Passing Arguments (Cont.)",
    "text": "dplyr::across(): Passing Arguments (Cont.)\n\n\n.cols = c(x, y)\n.fns = ~mean(x, na.rm = TRUE)\n.names = NULL (default argument)"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-1",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-1",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Passing Arguments (Cont.)",
    "text": "dplyr::across(): Passing Arguments (Cont.)\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = ~mean(.x, na.rm = TRUE)\n                   )\n            )\n\n# A tibble: 2 × 3\n  group     x     y\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-2",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-2",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Passing Arguments (Cont.)",
    "text": "dplyr::across(): Passing Arguments (Cont.)\nPassing an argument to .names, .names = \"{col}_{fn}\":\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = ~mean(.x, na.rm = TRUE),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-3",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-3",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Passing Arguments (Cont.)",
    "text": "dplyr::across(): Passing Arguments (Cont.)\nOr using a quoted vector for .cols: .cols = c(\"x\", \"y\")\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(\"x\", \"y\"), \n                   .fns = ~mean(.x, na.rm = TRUE),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-4",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-4",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Passing Arguments (Cont.)",
    "text": "dplyr::across(): Passing Arguments (Cont.)\nOr passing a quoted vector to .cols:\n\n\nmust use all_of() or any_of() for variable selection\n.cols = all_of(summarize_these)\n.cols = summarize_these will produce a warning"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-5",
    "href": "slides/09_summarizing_data_advanced_slides.html#dplyracross-passing-arguments-cont.-5",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "dplyr::across(): Passing Arguments (Cont.)",
    "text": "dplyr::across(): Passing Arguments (Cont.)\n\nsummarize_these &lt;- c(\"x\", \"y\")  # create the vector to pass\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = any_of(summarize_these), \n                   .fns = ~mean(.x, na.rm = TRUE),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5\n\n\n\nDefining a vector of variables can be a helpful solution when you have multiple summary tables for which you use the same variables."
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#annoyances-with-across",
    "href": "slides/09_summarizing_data_advanced_slides.html#annoyances-with-across",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Annoyances with across()",
    "text": "Annoyances with across()\n\n\nMore complicated\nAlthough {col} is useful (e.g., x and y), {fn} results in a numeric value which is not diagnostic of the function"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-of-functions-to-.fns",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-of-functions-to-.fns",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List of Functions to .fns",
    "text": "Passing a List of Functions to .fns\n\n\n.cols = c(x, y)\n.fns = list(~mean(x, na.rm = TRUE))"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-of-functions-to-.fns-cont.",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-of-functions-to-.fns-cont.",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List of Functions to .fns (Cont.)",
    "text": "Passing a List of Functions to .fns (Cont.)\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = list(~mean(.x, na.rm = TRUE)),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group   x_1   y_1\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 a      15    27.7\n2 b      47.5  19.5"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-of-functions-to-.fns-cont.-1",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-of-functions-to-.fns-cont.-1",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List of Functions to .fns (Cont.)",
    "text": "Passing a List of Functions to .fns (Cont.)\nThe ~ is use as a lambda-like operator that results in iterating the function over all instances of x. In this case, list(~mean(x, na.rm = TRUE), the x is not referring to the x column in the data frame but instead the values in all variables passed to .cols. In this case, the x would be both x and y, in that order."
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#same-annoyances",
    "href": "slides/09_summarizing_data_advanced_slides.html#same-annoyances",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Same Annoyances",
    "text": "Same Annoyances\n\n\nMore complicated (requires remembering the function, in the list, and the ~)\nAlthough {col} is useful (e.g., x and y), {fn} results in a numeric value which is not diagnostic of the function"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#giving-the-list-elements-names",
    "href": "slides/09_summarizing_data_advanced_slides.html#giving-the-list-elements-names",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Giving the List Elements Names",
    "text": "Giving the List Elements Names\n\n\n.cols = c(x, y)\n.fns = list(some_name = ~mean(x, na.rm = TRUE))"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#giving-the-list-elements-names-cont.",
    "href": "slides/09_summarizing_data_advanced_slides.html#giving-the-list-elements-names-cont.",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Giving the List Elements Names (Cont.)",
    "text": "Giving the List Elements Names (Cont.)\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = list(some_name = ~mean(.x, na.rm = TRUE)),\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 3\n  group x_some_name y_some_name\n  &lt;chr&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 a            15          27.7\n2 b            47.5        19.5"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#annoyances",
    "href": "slides/09_summarizing_data_advanced_slides.html#annoyances",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Annoyances",
    "text": "Annoyances\n\nStill complicated (requires remembering the function, in the list, and the ~)"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List Object to .fns",
    "text": "Passing a List Object to .fns\n\n\ncreate summary_funcs list of function(s)\n.fns = summary_funcs"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns-cont.",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns-cont.",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List Object to .fns (Cont.)",
    "text": "Passing a List Object to .fns (Cont.)\nCreate a list containing ~mean(.x, na.rm = TRUE)) used in previous example:\n\nsummary_funcs &lt;- list(\n  mean = ~mean(.x, na.rm = TRUE)  \n  )"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns-cont.-1",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns-cont.-1",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List Object to .fns (Cont.)",
    "text": "Passing a List Object to .fns (Cont.)\nThen pass to .fns, .fns = summary_funcs:\n\nDATA |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            ) \n\n# A tibble: 1 × 2\n  x_mean y_mean\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     28   24.4"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns-cont.-2",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-a-list-object-to-.fns-cont.-2",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing a List Object to .fns (Cont.)",
    "text": "Passing a List Object to .fns (Cont.)\nPair with .cols = summarize_these to summarize the variables in summarize_these using the function(s) in summary_funcs:\nDATA |&gt;\n  summarize(across(.cols = summarize_these,\n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            )"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#annoyancesbenefits",
    "href": "slides/09_summarizing_data_advanced_slides.html#annoyancesbenefits",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Annoyances/Benefits",
    "text": "Annoyances/Benefits\n\n\nRequires creating other objects\nSimplifies the code\nDoes not require remembering the functions, the list, and ~ after created once"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#adding-more-functions-as-list-elements",
    "href": "slides/09_summarizing_data_advanced_slides.html#adding-more-functions-as-list-elements",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Adding More Functions as List Elements",
    "text": "Adding More Functions as List Elements\nAdd functions to the list to accomplish more\n\nsummary_funcs &lt;- list(\n  mean = ~mean(.x, na.rm = TRUE),\n  median = ~median(.x, na.rm = TRUE),\n  sd = ~sd(.x, na.rm = TRUE),\n  n = ~length(na.omit(.x))  # no na.rm parameter in length()\n  )"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-the-list-object-to-.fns-grouping",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-the-list-object-to-.fns-grouping",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing the List Object to .fns: Grouping",
    "text": "Passing the List Object to .fns: Grouping\n\n\ngroup_by(group)\n\n.fns = summary_funcs"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#passing-the-list-object-to-.fns-grouping-cont.",
    "href": "slides/09_summarizing_data_advanced_slides.html#passing-the-list-object-to-.fns-grouping-cont.",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Passing the List Object to .fns: Grouping (Cont.)",
    "text": "Passing the List Object to .fns: Grouping (Cont.)\n\nDATA |&gt;\n  group_by(group) |&gt;\n  summarize(across(.cols = c(x, y), \n                   .fns = summary_funcs,\n                   .names = \"{col}_{fn}\"\n                   )\n            )\n\n# A tibble: 2 × 9\n  group x_mean x_median  x_sd   x_n y_mean y_median  y_sd   y_n\n  &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 a       15       13    5.29     3   27.7     30   6.81      3\n2 b       47.5     47.5  4.95     2   19.5     19.5 0.707     2"
  },
  {
    "objectID": "slides/09_summarizing_data_advanced_slides.html#annoyancesbenefits-1",
    "href": "slides/09_summarizing_data_advanced_slides.html#annoyancesbenefits-1",
    "title": "Summarizing Data: Advanced Techniques",
    "section": "Annoyances/Benefits",
    "text": "Annoyances/Benefits\n\n\nCreating and remembering the list object name\nSolution: Add an .R script to your functions directory and make a code snippet for the object name."
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#step-1",
    "href": "slides/sample_quarto_presentation.html#step-1",
    "title": "Sample Presentation",
    "section": "Step 1",
    "text": "Step 1\n\nSplit slides up with level 2 headers: ## Heading 2\nAdd some markdown + text and/or some R/Python code"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#some-r-code",
    "href": "slides/sample_quarto_presentation.html#some-r-code",
    "title": "Sample Presentation",
    "section": "Some R Code",
    "text": "Some R Code\n\n2 + 2\n\n[1] 4\n\n# comment"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#slide-title",
    "href": "slides/sample_quarto_presentation.html#slide-title",
    "title": "Sample Presentation",
    "section": "Slide Title",
    "text": "Slide Title\n\none\ntwo"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#make-this-slide-red",
    "href": "slides/sample_quarto_presentation.html#make-this-slide-red",
    "title": "Sample Presentation",
    "section": "Make this slide Red",
    "text": "Make this slide Red"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#making-a-slide-incremental",
    "href": "slides/sample_quarto_presentation.html#making-a-slide-incremental",
    "title": "Sample Presentation",
    "section": "Making a Slide Incremental",
    "text": "Making a Slide Incremental\nSay you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.\n\nThen add some content…\n\n\nThen some more content"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#omit-this-slide-visibility-hidden",
    "href": "slides/sample_quarto_presentation.html#omit-this-slide-visibility-hidden",
    "title": "Sample Presentation",
    "section": "Omit This Slide {visibility = “hidden”}",
    "text": "Omit This Slide {visibility = “hidden”}"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#add-links",
    "href": "slides/sample_quarto_presentation.html#add-links",
    "title": "Sample Presentation",
    "section": "Add links",
    "text": "Add links\n\ncmc\n\n\n\nFirst item\nSecond item"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#fragments",
    "href": "slides/sample_quarto_presentation.html#fragments",
    "title": "Sample Presentation",
    "section": "Fragments",
    "text": "Fragments\n\nFade in\n\n\nFade out\n\n\nHighlight red\n\n\nFade in, then out"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#fragments-nesting",
    "href": "slides/sample_quarto_presentation.html#fragments-nesting",
    "title": "Sample Presentation",
    "section": "Fragments, nesting",
    "text": "Fragments, nesting\n\n\n\nFade in &gt; Turn red &gt; Semi fade out"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#fragments-spans",
    "href": "slides/sample_quarto_presentation.html#fragments-spans",
    "title": "Sample Presentation",
    "section": "Fragments, spans",
    "text": "Fragments, spans\nThis is an important sentence!\nMind the gap when riding the rail!"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#column-layout",
    "href": "slides/sample_quarto_presentation.html#column-layout",
    "title": "Sample Presentation",
    "section": "Column layout",
    "text": "Column layout\n\n\ncontents…s\n\ncontents…"
  },
  {
    "objectID": "slides/sample_quarto_presentation.html#output-location",
    "href": "slides/sample_quarto_presentation.html#output-location",
    "title": "Sample Presentation",
    "section": "Output Location",
    "text": "Output Location\n\n\nlibrary(ggplot2)\n\nmtcars |&gt; \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\")"
  },
  {
    "objectID": "modules/13_visualizing_data.html#some-helpful-functions",
    "href": "modules/13_visualizing_data.html#some-helpful-functions",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Some Helpful Functions",
    "text": "Some Helpful Functions\n\nggplot(): for initializing a plot object\naes(): for specifying aesthetics of a plot (e.g., x, y, size, color, etc.)\ngeom_bar(): for bar geometry of a plot using either x or y\ngeom_col(): for bar geometry of a plot using x and y\ngeom_point(): for point geometry of a plot\ngeom_line(): for line geometry of a plot\ngeom_histogram(): for a distribution geometry of a plot\nggtitle() or labs(): for adding a title\ngeom_text(): for editing text\nylab() and xlab(): for axis labeling\ncoord_flip(): for flipping the x and y coordinates\n\ntheme_minimal(): a particular theme application\ntheme_set(): for setting a theme"
  },
  {
    "objectID": "modules/13_visualizing_data.html#mapping-a-new-variable",
    "href": "modules/13_visualizing_data.html#mapping-a-new-variable",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Mapping a new variable…",
    "text": "Mapping a new variable…\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(color = D))"
  },
  {
    "objectID": "modules/13_visualizing_data.html#mapping-an-existing-variable",
    "href": "modules/13_visualizing_data.html#mapping-an-existing-variable",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Mapping an existing variable…",
    "text": "Mapping an existing variable…\nMapping color to A:\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(color = A))\n\n\n\n\nOr mapping color to B:\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(color = B))\n\n\n\n\nYou may have noticed that when mapped variables are numeric, the aesthetics are applied continuously and when they are categorical, they are applied discretely. Here is a good example of mapping variable A not as itself but by changing it to a factor() or a character vector.\nWe can convert the vector to a factor using as.factor():\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(color = as.factor(A)))\n\n\n\n\nWe see the same plot if we convert the variable to a character using as.character():\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_point(mapping = aes(color = as.character(A)))\n\n\n\n\nNote: The label is very messy. You would be better off changing the variable to a factor in the data frame."
  },
  {
    "objectID": "modules/13_visualizing_data.html#geom_histogram",
    "href": "modules/13_visualizing_data.html#geom_histogram",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "geom_histogram()",
    "text": "geom_histogram()\n\nmtcars |&gt;\n  ggplot(mapping = aes(x = mpg)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n# or less popular\nmtcars |&gt;\n  ggplot(mapping = aes(y = mpg)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "modules/13_visualizing_data.html#geom_density",
    "href": "modules/13_visualizing_data.html#geom_density",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "geom_density()",
    "text": "geom_density()\nWhen you need a smoothed version of the histogram, geom_density() will produce a kernel density plot. In this case, we also add fill = cyl to fill the densities by color.\n\nmtcars |&gt;\n  ggplot(mapping = aes(x = mpg)) +\n  geom_density(mapping = aes(fill = cyl), \n               alpha = .5\n               )\n\nWarning: The following aesthetics were dropped during statistical transformation: fill\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nWait, huh? But this does not fill the densities with a color corresponding to cyl. Does it need to be a different type?\n\nmtcars |&gt;\n  ggplot(mapping = aes(x = mpg)) +\n  geom_density(mapping = aes(fill = as.factor(cyl)),\n               alpha = .5\n               )\n\n\n\n\nOK better, except for cleaning up the legend."
  },
  {
    "objectID": "modules/13_visualizing_data.html#geom_bar",
    "href": "modules/13_visualizing_data.html#geom_bar",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "geom_bar()",
    "text": "geom_bar()\nThere are times you want bar plots.\nTrying out geom_bar(), we need an either an x or a y aesthetic mapping but not both. When passing a variable to x, the bar will be vertical and when passing the variable to y, the bar will be horizontal. Because the mapping is inherited from ggplot(), you’ll throw an error like the following because both x and y will be inherited:\nError in f(): ! stat_count() can only have an x or y aesthetic.\nWe can change the mapping in the base ggplot() layer, which will plot bars corresponding to the unique levels of the variable passed to x at a height relative to the frequency of occurrence of those unique levels. To see what might be plotted from A, see DATA$A 1, 2, 3, 4.\nChecking ?geom_bar, you will notice that geom_bar() has a default stat = \"count\". This means that the default bar plot will plot the \"count\", or frequency of elements in a vector variable. When the count or frequency of a value is 1, the bar height will be 1 on the y axis and if an element appears 5 times in the vector, the bar height will be 5. For a horizontal bar, the bar length, rather than height, will be 5. Looking at DATA$A 1, 2, 3, 4, what might you expect the bar to look like?\n\n# setting y\nDATA |&gt;\n  ggplot(mapping = aes(y = A)) +\n  geom_bar()\n\n\n\n\nIf the aesthetics are mapped and inherited, you can still create a plot that accounts for both x and y variables. Passing stat = \"identity\" to geom_bar() will produce a bar plot that presents the value of y in the data frame (its identity) for each value of x.\nWhen passing, pay attention to which variables are inherited by both x and y as they will likely produce very different plots.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B\n                       )\n         ) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B\n                       )\n         ) +\n  geom_bar(stat = \"identity\")\n\n\n\n\nBy default, the scale for x and y are continuous (see above). If you don’t like the fact that bars take positions for which there are no labels and that labels are where no bars are, convert B it to a factor.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = as.factor(B), \n                       y = A)\n         ) +\n  geom_bar(stat = \"identity\")"
  },
  {
    "objectID": "modules/13_visualizing_data.html#geom_col",
    "href": "modules/13_visualizing_data.html#geom_col",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "geom_col()",
    "text": "geom_col()\ngeom_bar(stat = \"identity\") is actually the same as another plot. A column plot using geom_col(). We need both x and y variables and when specified, the columns will plotted for each unique level of x at a height corresponding to the value of y. One way to think about geom_col() is that it plots columns at the same location as the points in geom_point().\n\nDATA |&gt;\n  select(A, B)\n\n  A B\n1 1 2\n2 2 5\n3 3 3\n4 4 8\n\n\nSo when we pass A and B to geom_col():\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = B)\n         ) +\n  geom_col()\n\n\n\n\nWe get our bars or columns.\nIf your x axis (or y axis) is categorical/discrete rather than continuous.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = D, \n                       y = A)\n         ) + \n  geom_col()\n\n\n\n\nOr swapping A and D:\n\nDATA |&gt;\n  ggplot(mapping = aes(x = A, \n                       y = D)\n         ) + \n  geom_col()"
  },
  {
    "objectID": "modules/13_visualizing_data.html#adding-layers-that-inherit-aesthetics",
    "href": "modules/13_visualizing_data.html#adding-layers-that-inherit-aesthetics",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Adding layers that inherit aesthetics",
    "text": "Adding layers that inherit aesthetics\nWhen aesthetics are mapped to the initialized ggplot() object, the x and y variables therein carry through to the geometries. This is not a problem when the geometries are using similar information as with geom_point(), geom_line(), and even geom_col().\n\nmap &lt;- DATA |&gt;\n  ggplot(mapping = aes(x = A, y = C))\n\nmap + \n  geom_point() +\n  geom_line() +\n  geom_col()\n\n\n\n\nBut because geom_bar() takes only x or y, there will be a problem. Test it on your own."
  },
  {
    "objectID": "modules/13_visualizing_data.html#adding-layers-that-do-not-that-inherit-aesthetics",
    "href": "modules/13_visualizing_data.html#adding-layers-that-do-not-that-inherit-aesthetics",
    "title": "Visualizing Data: {ggplot} and the grammar of graphics",
    "section": "Adding layers that do not that inherit aesthetics",
    "text": "Adding layers that do not that inherit aesthetics\nWhen aesthetics are not inherited by the initial object, they can be set or mapped in their own geometry. This example does not even pass data = DATA. If it did and each geometry used DATA, then that doesn’t need passing. Only omitted characteristics need mapping.\n\nmap &lt;- ggplot()   \n\n\nmap + \n  geom_point(data = DATA, \n             mapping = aes(A, C)) +\n  geom_col(data = DATA, \n           mapping = aes(A, B),\n           fill = \"green\") +\n  geom_line(data = DATA, \n            mapping = aes(A, B), \n            linetype = \"dashed\",\n            color = \"red\", \n            size = 1, \n            alpha = .5\n            )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nBy specifying DATA and aes(A, B), all geometries using DATA with x = A and y = B will inherit them. Otherwise, pass the necessary arguments to the geometries.\n\nmap &lt;- DATA |&gt;\n  ggplot(mapping = aes(A, B))\n\nmap + \n  geom_col(fill = \"green\") +           # set all columns to blue\n  geom_line(mapping = aes(y = C),      # a new mapping y = C for the line data\n            linetype = \"dashed\") +     # set the linetype\n            \n  geom_point(mapping = aes(color = B,  # map color to A (inherited as y)  \n                           size = A),  # map size to B (inherited as x)\n            alpha = .5                 # set alpha transparency\n            ) +\n  theme_classic()\n\n\n\n\nNow, this plot is certainly not the best and it certainly needs work. But the coding of the plot illustrates the flexibility of ggplot for adding plot geometry layers to a single plot, utilizing aesthetics inherited from an initialized object, mapping new aesthetics not inherited, setting aesthetic constants, and mapping variables to aesthetics."
  },
  {
    "objectID": "modules/14_joining_relational_data.html#full-join",
    "href": "modules/14_joining_relational_data.html#full-join",
    "title": "Joining Relational Data",
    "section": "Full Join",
    "text": "Full Join\nWhen you want to completely join two data frames, a full join would join the two data frames so that the data frame would combine all rows from both data frames by some unique value including NA where there are no matches.\nWe can join data frames A and B by matching the two using the row values of id. When there are NA\nA where ‘id’ doesn’t match in either A or B."
  },
  {
    "objectID": "modules/14_joining_relational_data.html#supplementary-readings-optional",
    "href": "modules/14_joining_relational_data.html#supplementary-readings-optional",
    "title": "Joining Relational Data",
    "section": "",
    "text": "Joining Data"
  },
  {
    "objectID": "modules/14_joining_relational_data.html#writing-a-function",
    "href": "modules/14_joining_relational_data.html#writing-a-function",
    "title": "Joining Relational Data",
    "section": "Writing a Function",
    "text": "Writing a Function\nYou can also write a function to help you. Here, we can make a function to take a list of data frames and cycles through them to return a data frame based on full_join().\n\nfull_join_data_frames_in_list &lt;- function(list, by) {\n  if (missing(by)) {\n    message(\"Please specify the 'by' parameter for merging.\")\n    return(NULL)\n  } else {\n    joined &lt;- Reduce(function(x, y) dplyr::full_join(x, y, by = by), list)\n    return(joined)\n  }\n}\n\nPut the data frames in a list:\n\nABC_list &lt;- list(A, B, C)\n\nPass the list to the list parameter and supply the by argument as a string.\n\nfull_join_data_frames_in_list(list = ABC_list,\n                              by = \"id\"\n                              )\n\n# A tibble: 6 × 6\n     id height weight city        age name \n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;\n1  1111     60    128 Claremont    22 Sally\n2  2211     NA    120 Dallas       25 Jane \n3  9811     60    149 Akron        38 &lt;NA&gt; \n4  3000     65    140 &lt;NA&gt;         NA &lt;NA&gt; \n5  3050     NA     NA &lt;NA&gt;         50 &lt;NA&gt; \n6    NA     NA     NA &lt;NA&gt;         NA Kelly"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#hi-1",
    "href": "slides/11_visualizing_data_slides.html#hi-1",
    "title": "Visualizing Data",
    "section": "Hi",
    "text": "Hi\n\nljlasjf\naljasf"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#r-libraries",
    "href": "slides/11_visualizing_data_slides.html#r-libraries",
    "title": "Data Visualization",
    "section": "R Libraries",
    "text": "R Libraries\n\n\n{dplyr} for arranging data frames\nThe Grammar of Graphics: {ggplot}\nLibraries leveraging {ggplot2}; + others"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#components-of-ggplot2",
    "href": "slides/11_visualizing_data_slides.html#components-of-ggplot2",
    "title": "Data Visualization",
    "section": "5 components of {ggplot2}",
    "text": "5 components of {ggplot2}\n\n\nLayer containing geometric elements and data\nScales that map values in the data space to values in aesthetic space\nCoordinate System for mapping coordinates to the graphic plane\nFacet for arranging the data into a grid\nTheme (e.g., like font, background, grids, axes, etc.)"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#section",
    "href": "slides/11_visualizing_data_slides.html#section",
    "title": "Data Visualization",
    "section": "",
    "text": "ljljasf\nlljasfd"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#hi",
    "href": "slides/11_visualizing_data_slides.html#hi",
    "title": "Data Visualization",
    "section": "Hi",
    "text": "Hi\n\nljlasjf\naljasf"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#data",
    "href": "slides/11_visualizing_data_slides.html#data",
    "title": "Data Visualization",
    "section": "Data",
    "text": "Data\n\nDATA &lt;- data.frame(\n var1 = c(1, 2, 3, 4), \n var2 = c(2, 5, 3, 8), \n var3 = c(10, 15, 32, 28), \n group = c(\"A\", \"A\", \"B\", \"B\")\n)"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#initialize-the-plot-object",
    "href": "slides/11_visualizing_data_slides.html#initialize-the-plot-object",
    "title": "Data Visualization",
    "section": "Initialize the Plot Object",
    "text": "Initialize the Plot Object\n\nDATA |&gt;\n  ggplot()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#mapping-data-and-aesthetics",
    "href": "slides/11_visualizing_data_slides.html#mapping-data-and-aesthetics",
    "title": "Data Visualization",
    "section": "Mapping Data and Aesthetics",
    "text": "Mapping Data and Aesthetics\n\n\nneed at least an x or y\nsome geoms need both (e.g., geom_point(), geom_col(), etc.)"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#plot-geometries",
    "href": "slides/11_visualizing_data_slides.html#plot-geometries",
    "title": "Data Visualization",
    "section": "Plot Geometries",
    "text": "Plot Geometries\n\n\nx or y: geom_histogram(), geom_density(), geom_bar(), etc.\nx & y:geom_point(), geom_col(), geom_line(), etc."
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-plot-geometries",
    "href": "slides/11_visualizing_data_slides.html#adding-plot-geometries",
    "title": "Data Visualization",
    "section": "Adding Plot Geometries",
    "text": "Adding Plot Geometries\n\n\nadd to object using + (don’t |&gt;)"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_histogram",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_histogram",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_histogram()",
    "text": "Adding a Geometry: geom_histogram()\ngeom_histogram(\n  mapping = NULL,\n  data = NULL,\n  stat = \"bin\",\n  position = \"identity\",\n  ...\n  )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_point",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_point",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_point()",
    "text": "Adding a Geometry: geom_point()\ngeom_point(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...\n  )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_col()",
    "text": "Adding a Geometry: geom_col()\ngeom_col(\n  mapping = NULL,\n  data = NULL,\n  position = \"stack\",\n  ...\n  )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-more-geometries",
    "href": "slides/11_visualizing_data_slides.html#adding-more-geometries",
    "title": "Data Visualization",
    "section": "Adding More Geometries",
    "text": "Adding More Geometries\n\n\nadd a layer using +\nspecify the data\nmap the aesthetics"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-more-geometries-1",
    "href": "slides/11_visualizing_data_slides.html#adding-more-geometries-1",
    "title": "Data Visualization",
    "section": "Adding More Geometries",
    "text": "Adding More Geometries\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2\n                       )\n         ) +\n  geom_point(mapping = aes(x = var1, \n                           y = var2\n                           ),   \n             data = NULL, \n             stat = \"identity\", \n             position = \"identity\", \n             size = 1.5\n             )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-theme",
    "href": "slides/11_visualizing_data_slides.html#adding-a-theme",
    "title": "Data Visualization",
    "section": "Adding a Theme",
    "text": "Adding a Theme\n\n\na plot is in a theme by default\nto change a theme, add a theme layer"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-theme-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-theme-1",
    "title": "Data Visualization",
    "section": "Adding a Theme",
    "text": "Adding a Theme\nDATA2 |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2)\n         ) +\n  geom_point() +\n  facet_wrap(facets = vars(group1)) +\n  # change the theme\n  theme_minimal()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-facet",
    "href": "slides/11_visualizing_data_slides.html#adding-a-facet",
    "title": "Data Visualization",
    "section": "Adding a Facet",
    "text": "Adding a Facet\n\n\na plot is in a facet by default\nto change the facet, add a facet layer\nfacet_wrap() or facet_grid()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#data-1",
    "href": "slides/11_visualizing_data_slides.html#data-1",
    "title": "Data Visualization",
    "section": "Data",
    "text": "Data\n\nDATA\n\n  var1 var2 var3 group\n1    1    2   10     A\n2    2    5   15     A\n3    3    3   32     B\n4    4    8   28     B"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#mapping-data-and-aesthetics-cont.",
    "href": "slides/11_visualizing_data_slides.html#mapping-data-and-aesthetics-cont.",
    "title": "Data Visualization",
    "section": "Mapping Data and Aesthetics (Cont.)",
    "text": "Mapping Data and Aesthetics (Cont.)\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1))"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#mapping",
    "href": "slides/11_visualizing_data_slides.html#mapping",
    "title": "Data Visualization",
    "section": "Mapping",
    "text": "Mapping\n\n\nspecified by arguments to aes()\nat least an x or y (e.g., geom_histogram())\nsome geoms need both (e.g., geom_point(), geom_col(), etc.)"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#setting-vs.-mapping",
    "href": "slides/11_visualizing_data_slides.html#setting-vs.-mapping",
    "title": "Data Visualization",
    "section": "Setting vs. Mapping",
    "text": "Setting vs. Mapping\n\n\nmapping: specified by arguments to aes()\nsetting: specified by arguments in the geom_*(); outside of aes()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#setting-an-aesthetic-color",
    "href": "slides/11_visualizing_data_slides.html#setting-an-aesthetic-color",
    "title": "Data Visualization",
    "section": "Setting an Aesthetic: Color",
    "text": "Setting an Aesthetic: Color\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1,\n                       y = var2\n                       )\n         ) +\n  geom_point(color = \"red\")"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#mapping-an-aesthetic-color",
    "href": "slides/11_visualizing_data_slides.html#mapping-an-aesthetic-color",
    "title": "Data Visualization",
    "section": "Mapping an Aesthetic: Color",
    "text": "Mapping an Aesthetic: Color\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2\n                       )\n         ) +\n  geom_point(mapping = aes(color = group))"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#errors-with-mapping-and-setting",
    "href": "slides/11_visualizing_data_slides.html#errors-with-mapping-and-setting",
    "title": "Data Visualization",
    "section": "Errors with Mapping and Setting",
    "text": "Errors with Mapping and Setting\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2\n                       )\n         ) +\n  geom_point(mapping = aes(color = \"green\"))"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-cont.",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-cont.",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_col() (Cont.)",
    "text": "Adding a Geometry: geom_col() (Cont.)\n\nDATA |&gt;\n  ggplot(mapping = aes(x = group, \n                       y = var2\n                       )\n         ) +\n  geom_col()\n\n\nNotice anything odd?"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-cont.-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-cont.-1",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_col() (Cont.)",
    "text": "Adding a Geometry: geom_col() (Cont.)\nSet aesthetics to make more apparent.\n\nDATA |&gt;\n  ggplot(mapping = aes(x = group, \n                       y = var2\n                       )\n         ) +\n  geom_col(fill = \"yellow\", color = \"blue\")"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#remember-the-data",
    "href": "slides/11_visualizing_data_slides.html#remember-the-data",
    "title": "Data Visualization",
    "section": "Remember the Data?",
    "text": "Remember the Data?\n\nDATA\n\n  var1 var2 var3 group\n1    1    2   10     A\n2    2    5   15     A\n3    3    3   32     B\n4    4    8   28     B\n\n\n\n\nall plots have some statistical transformation\ncould be \"identity\" (what you see is what you get)\ncould be based on a statistic (e.g., count, sum, mean, etc.)"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-cont.-2",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-cont.-2",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_col() (Cont.)",
    "text": "Adding a Geometry: geom_col() (Cont.)\n\nDATA |&gt;\n  # aggregate across the groups, then summarize\n  group_by(group) |&gt;\n  summarize(var2 = mean(var2, na.rm = TRUE)) |&gt;\n  # then plot\n  ggplot(mapping = aes(x = group, \n                       y = var2)\n         ) +\n  geom_col()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#change-the-data-frame",
    "href": "slides/11_visualizing_data_slides.html#change-the-data-frame",
    "title": "Data Visualization",
    "section": "Change the Data Frame",
    "text": "Change the Data Frame\n\nDATA |&gt;\n  # aggregate across the groups, then summarize\n  group_by(group) |&gt;\n  summarize(var2 = mean(var2, na.rm = TRUE)) \n\n# A tibble: 2 × 2\n  group  var2\n  &lt;chr&gt; &lt;dbl&gt;\n1 A      55.3\n2 B      54.7"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#plot-that-new-data-frame",
    "href": "slides/11_visualizing_data_slides.html#plot-that-new-data-frame",
    "title": "Data Visualization",
    "section": "Plot that New Data Frame",
    "text": "Plot that New Data Frame\n\nDATA |&gt;\n  # aggregate across the groups, then summarize\n  group_by(group) |&gt;\n  summarize(var2 = mean(var2, na.rm = TRUE)) |&gt;\n  \n  # then plot\n  ggplot(mapping = aes(x = group, \n                       y = var2)\n         ) +\n  geom_col()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_histogram-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_histogram-1",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_histogram()",
    "text": "Adding a Geometry: geom_histogram()\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_point-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_point-1",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_point()",
    "text": "Adding a Geometry: geom_point()\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1,\n                       y = var2\n                       )\n         ) +\n  geom_point()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_col-1",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_col()",
    "text": "Adding a Geometry: geom_col()\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2\n                       )\n         ) +\n  geom_col()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_boxplot",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_boxplot",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_boxplot()",
    "text": "Adding a Geometry: geom_boxplot()\ngeom_boxplot(\n  mapping = NULL,\n  data = NULL,\n  stat = \"boxplot\",\n  position = \"dodge2\",\n  ...\n  )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#new-data",
    "href": "slides/11_visualizing_data_slides.html#new-data",
    "title": "Data Visualization",
    "section": "New Data",
    "text": "New Data\n\nDATA &lt;- \n  data.frame(\n    var1 = rnorm(n = 100, mean = 20, sd = 2),\n    var2 = rnorm(n = 100, mean = 55, sd = 3),\n    group = rep(c(\"A\", \"B\"), 50)\n  )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_boxplot-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_boxplot-1",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_boxplot()",
    "text": "Adding a Geometry: geom_boxplot()\n\nDATA |&gt;\n  ggplot(mapping = aes(x = group, \n                       y = var2\n                       )\n         ) +\n  geom_boxplot(mapping = aes(fill = group),\n               show.legend = FALSE\n               )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_boxplot-geom_point",
    "href": "slides/11_visualizing_data_slides.html#adding-a-geometry-geom_boxplot-geom_point",
    "title": "Data Visualization",
    "section": "Adding a Geometry: geom_boxplot() + geom_point() ",
    "text": "Adding a Geometry: geom_boxplot() + geom_point() \n\nDATA |&gt;\n  ggplot(mapping = aes(x = group, \n                       y = var2\n                       )\n         ) +\n  geom_boxplot(mapping = aes(fill = group),\n               show.legend = FALSE\n               ) +\n  geom_point(position = position_jitter(width = .2))"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#change-the-data-frame-e.g.-summarize",
    "href": "slides/11_visualizing_data_slides.html#change-the-data-frame-e.g.-summarize",
    "title": "Data Visualization",
    "section": "Change the Data Frame (e.g., summarize)",
    "text": "Change the Data Frame (e.g., summarize)\n\nDATA |&gt;\n  # aggregate across the groups, then summarize\n  group_by(group) |&gt;\n  summarize(var2 = mean(var2, na.rm = TRUE)) \n\n# A tibble: 2 × 2\n  group  var2\n  &lt;chr&gt; &lt;dbl&gt;\n1 A       3.5\n2 B       5.5"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-geometries-as-plot-layers",
    "href": "slides/11_visualizing_data_slides.html#adding-geometries-as-plot-layers",
    "title": "Data Visualization",
    "section": "Adding Geometries as Plot Layers",
    "text": "Adding Geometries as Plot Layers\n\n\nadd a layer using +\nspecify the data\nmap the aesthetics"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#make-some-new-data",
    "href": "slides/11_visualizing_data_slides.html#make-some-new-data",
    "title": "Data Visualization",
    "section": "Make Some New Data",
    "text": "Make Some New Data\n\nDATA2 &lt;- \n  data.frame(\n    var1 = rnorm(n = 100, mean = 20, sd = 2),\n    var2 = rnorm(n = 100, mean = 55, sd = 3),\n    group1 = rep(c(\"A\", \"B\"), 50),\n    group2 = rep(c(\"A\", \"A\", \"B\", \"B\"), 25)\n  )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-facet-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-facet-1",
    "title": "Data Visualization",
    "section": "Adding a Facet",
    "text": "Adding a Facet\n\nDATA |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2)\n         ) +\n  geom_point() +\n  facet_wrap(facets = vars(group))"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-geometry-layers-geom_boxplot-geom_point",
    "href": "slides/11_visualizing_data_slides.html#adding-geometry-layers-geom_boxplot-geom_point",
    "title": "Data Visualization",
    "section": "Adding Geometry Layers: geom_boxplot() + geom_point() ",
    "text": "Adding Geometry Layers: geom_boxplot() + geom_point() \nDATA |&gt;\n  ggplot(mapping = aes(x = group, \n                       y = var2\n                       )\n         ) +\n  # add a boxplot layer; remove legend\n  geom_boxplot(color = \"black\",\n               fill = \"white\",\n               show.legend = FALSE,\n               notch = TRUE\n               ) +\n  # add a point layer with jittered points\n  geom_point(position = position_jitter(width = .2),\n             alpha = .7\n             )"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#small-multiples-replicating-plots-for-subgroups",
    "href": "slides/11_visualizing_data_slides.html#small-multiples-replicating-plots-for-subgroups",
    "title": "Data Visualization",
    "section": "Small Multiples: Replicating Plots for Subgroups",
    "text": "Small Multiples: Replicating Plots for Subgroups\n\n\nSometimes you need create multiple plots by another variable\nBar plots for each month; scatter plot for each city; etc."
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-geometry-layers-geom_boxplot-geom_point-1",
    "href": "slides/11_visualizing_data_slides.html#adding-geometry-layers-geom_boxplot-geom_point-1",
    "title": "Data Visualization",
    "section": "Adding Geometry Layers: geom_boxplot() + geom_point()",
    "text": "Adding Geometry Layers: geom_boxplot() + geom_point()"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-one-variable",
    "href": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-one-variable",
    "title": "Data Visualization",
    "section": "Adding a Facet Based on One Variable",
    "text": "Adding a Facet Based on One Variable\nDATA2 |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2)\n         ) +\n  geom_point() +\n  # facet by one variable\n  facet_wrap(facets = vars(group1))"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-two-variables",
    "href": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-two-variables",
    "title": "Data Visualization",
    "section": "Adding a Facet Based on Two Variables",
    "text": "Adding a Facet Based on Two Variables"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-two-variables-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-two-variables-1",
    "title": "Data Visualization",
    "section": "Adding a Facet Based on Two Variables",
    "text": "Adding a Facet Based on Two Variables"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-one-variable-1",
    "href": "slides/11_visualizing_data_slides.html#adding-a-facet-based-on-one-variable-1",
    "title": "Data Visualization",
    "section": "Adding a Facet Based on One Variable",
    "text": "Adding a Facet Based on One Variable"
  },
  {
    "objectID": "slides/11_visualizing_data_slides.html#adding-a-theme-2",
    "href": "slides/11_visualizing_data_slides.html#adding-a-theme-2",
    "title": "Data Visualization",
    "section": "Adding a Theme",
    "text": "Adding a Theme\n\nDATA2 |&gt;\n  ggplot(mapping = aes(x = var1, \n                       y = var2)\n         ) +\n  geom_point() +\n  facet_wrap(facets = vars(group1)) +\n  # change the theme\n  theme_minimal()"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#correlations",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#correlations",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Correlations",
    "text": "Correlations"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#pivot-wide",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#pivot-wide",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Pivot Wide",
    "text": "Pivot Wide\nPivot the data frame to take the levels of time to create new column variables by taking the values from the var1 and var2.\n\n(WIDE &lt;-\n  LONG |&gt;\n  tidyr::pivot_wider( \n    names_from  = time,            # the measurement time variable\n    values_from = c(var1, var2)    # two types of variables measured\n  )\n)\n\n# A tibble: 576 × 8\n   id    group var1_1 var1_2 var1_3 var2_1 var2_2 var2_3\n   &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 AQAFS A         25     NA     NA     32     NA     NA\n 2 AQAMF A          8     NA     NA     16     NA     NA\n 3 AQAMS A         19     24      9     27     33     19\n 4 AQAQQ A         28     NA     19     37     NA     22\n 5 AQAQP A         37     32     30     41     40     39\n 6 AQAYR A         28     42     28     34     42     36\n 7 AQASY A         18     18     NA     29     24     NA\n 8 AQARM A          0     NA      4      0     NA      8\n 9 AQFAF A          9     11     NA     20     16     NA\n10 AQFJA A         21      8      7     31     19     21\n# ℹ 566 more rows"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-variables-using-cor",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-variables-using-cor",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Correlating Variables using cor()",
    "text": "Correlating Variables using cor()\nOut of the box, however, cor() will require some modifications. If you specify an x and a y variable to correlate, the default method = \"person which means that Pearson’s r will be correlated.\n\ncor(x = WIDE$var1_1, \n    y = WIDE$var1_2\n    )\n\n[1] NA"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#dealing-with-nas-missing-observations",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#dealing-with-nas-missing-observations",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Dealing with NAs (Missing Observations)",
    "text": "Dealing with NAs (Missing Observations)\nBut if there are NAs, you will see that the correlation is returned as NA. This is because use = \"everything\", which means that all values will be included in the correlation computation. However, just like other functions (e.g., mean(), etc.), when there are NAs, the correlation will be NA.\nIn order to correlate only the complete cases, for which individuals have data for both x and y variables, pass use = \"complete.obs\"\n\ncor(x = WIDE$var1_1, \n    y = WIDE$var1_2,\n    use = \"complete.obs\"\n    )\n\n[1] 0.5274822"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-matrices",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-matrices",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Correlating Matrices",
    "text": "Correlating Matrices\nCorrelating more than two variables, however, is quite common. The x parameter in cor() will also take a matrix, so you can pass a data frame that contains the numeric variables you wish to correlate.\nSelecting specific variables is easy using :.\n\nWIDE |&gt;\n  select(var1_1:var2_3) |&gt;\n  cor(use = \"complete.obs\")\n\n          var1_1    var1_2    var1_3    var2_1    var2_2    var2_3\nvar1_1 1.0000000 0.5563847 0.4780208 0.9139159 0.5005610 0.4133120\nvar1_2 0.5563847 1.0000000 0.6022340 0.5683264 0.9040954 0.5892968\nvar1_3 0.4780208 0.6022340 1.0000000 0.4590756 0.5823953 0.9126153\nvar2_1 0.9139159 0.5683264 0.4590756 1.0000000 0.5369649 0.4126811\nvar2_2 0.5005610 0.9040954 0.5823953 0.5369649 1.0000000 0.6122694\nvar2_3 0.4133120 0.5892968 0.9126153 0.4126811 0.6122694 1.0000000\n\n\nBut if you wanted to correlate all numeric variables, you can select columns that are numeric by using where(). All you need to do is pass an argument for a function, for example, fn = is.numeric.\n\nWIDE |&gt;\n  select(where(fn = is.numeric)) |&gt; \n  head()\n\n# A tibble: 6 × 6\n  var1_1 var1_2 var1_3 var2_1 var2_2 var2_3\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     25     NA     NA     32     NA     NA\n2      8     NA     NA     16     NA     NA\n3     19     24      9     27     33     19\n4     28     NA     19     37     NA     22\n5     37     32     30     41     40     39\n6     28     42     28     34     42     36\n\n\nYou see that all other variables are no longer in the data frame. With only numeric variables, if the entire data frame is passed as the argument to x in cor(), all variables will be correlated with each other.\n\nWIDE |&gt;\n  select(where(fn = is.numeric)) |&gt;\n  cor()\n\n       var1_1 var1_2 var1_3 var2_1 var2_2 var2_3\nvar1_1      1     NA     NA     NA     NA     NA\nvar1_2     NA      1     NA     NA     NA     NA\nvar1_3     NA     NA      1     NA     NA     NA\nvar2_1     NA     NA     NA      1     NA     NA\nvar2_2     NA     NA     NA     NA      1     NA\nvar2_3     NA     NA     NA     NA     NA      1\n\n\nBut if there are NAs, you will need to deal with them. There are two options for this. First, you can correlate variables at the pair levels by dropping out the NA for each pair for pairwise correlations (e.g., use = \"pairwise.complete.obs\" or you can drop out all the NAs to include complete cases use = \"complete.obs\". The latter option will correlate data by including only those who have no missing data across all of the variables. Let’s try both options.\nCorrelate at the pair level. Drop out those who have not contributed for each x,y pair.\n\nWIDE |&gt;\n  select(where(fn = is.numeric)) |&gt;\n  cor(use = \"pairwise.complete.obs\")\n\n          var1_1    var1_2    var1_3    var2_1    var2_2    var2_3\nvar1_1 1.0000000 0.5274822 0.4703198 0.9089004 0.5086606 0.4230712\nvar1_2 0.5274822 1.0000000 0.6026012 0.5615591 0.9018850 0.5863472\nvar1_3 0.4703198 0.6026012 1.0000000 0.4587613 0.5802238 0.9081988\nvar2_1 0.9089004 0.5615591 0.4587613 1.0000000 0.5772950 0.4325422\nvar2_2 0.5086606 0.9018850 0.5802238 0.5772950 1.0000000 0.6067406\nvar2_3 0.4230712 0.5863472 0.9081988 0.4325422 0.6067406 1.0000000\n\n\nUse only those who have data for all measurements.\n\nWIDE |&gt;\n  select(where(fn = is.numeric)) |&gt;\n  cor(use = \"complete.obs\")\n\n          var1_1    var1_2    var1_3    var2_1    var2_2    var2_3\nvar1_1 1.0000000 0.5563847 0.4780208 0.9139159 0.5005610 0.4133120\nvar1_2 0.5563847 1.0000000 0.6022340 0.5683264 0.9040954 0.5892968\nvar1_3 0.4780208 0.6022340 1.0000000 0.4590756 0.5823953 0.9126153\nvar2_1 0.9139159 0.5683264 0.4590756 1.0000000 0.5369649 0.4126811\nvar2_2 0.5005610 0.9040954 0.5823953 0.5369649 1.0000000 0.6122694\nvar2_3 0.4133120 0.5892968 0.9126153 0.4126811 0.6122694 1.0000000"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-with-correlation",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-with-correlation",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Correlating with correlation()",
    "text": "Correlating with correlation()\nSelect the the var1 variables, var1_1:var1_3 as well as the group variable, group by group, and correlate the pairwise combinations for each group. By default, the correlation will be Pearson’s r.\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;     # select var1 variables\n  group_by(group) |&gt;\n  correlation()\n\n# Correlation Matrix (pearson-method)\n\nGroup | Parameter1 | Parameter2 |    r |       95% CI |    t |  df |         p\n------------------------------------------------------------------------------\nA     |     var1_1 |     var1_2 | 0.54 | [0.41, 0.65] | 7.59 | 139 | &lt; .001***\nA     |     var1_1 |     var1_3 | 0.52 | [0.38, 0.65] | 6.51 | 112 | &lt; .001***\nA     |     var1_2 |     var1_3 | 0.62 | [0.46, 0.74] | 6.85 |  77 | &lt; .001***\nB     |     var1_1 |     var1_2 | 0.50 | [0.33, 0.63] | 5.70 | 100 | &lt; .001***\nB     |     var1_1 |     var1_3 | 0.41 | [0.25, 0.55] | 4.75 | 111 | &lt; .001***\nB     |     var1_2 |     var1_3 | 0.56 | [0.37, 0.70] | 5.59 |  69 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 71-141\n\n\nThe correlation table print out from correlation() is organized by group, followed by the pairwise correlations for the variable pairs (e.g., parameters 1 and 2). In addition to r, a 95% confidence interval (CI), t-test, degrees of freedom (df), and p value, are also provided. Because these metrics are important for reporting, all of these are advantages of using correlation().\nYou will also notice that the degrees of freedom are not the same for all variable pairs, thus indicating that the default operation is to use complete observations in a pairwise fashion; rows with NAs for any of the variables are not dropped. The smallest sample sizes correspond to correlation between var1_2 and var1_3 as attrition rates affected data collected at time 3. Also, the p-values are adjusted by default using Holm’s methods."
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-complete-cases",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#correlating-complete-cases",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Correlating Complete Cases",
    "text": "Correlating Complete Cases\nIf you want to obtain the correlation for cases that contributed to all variables, reduce the data frame by dropping any rows with NAs using drop_na().\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;     # select var1 variables\n  drop_na() |&gt;\n  group_by(group) |&gt;\n  correlation()\n\n# Correlation Matrix (pearson-method)\n\nGroup | Parameter1 | Parameter2 |    r |       95% CI |    t | df |         p\n-----------------------------------------------------------------------------\nA     |     var1_1 |     var1_2 | 0.54 | [0.36, 0.68] | 5.61 | 75 | &lt; .001***\nA     |     var1_1 |     var1_3 | 0.48 | [0.29, 0.63] | 4.73 | 75 | &lt; .001***\nA     |     var1_2 |     var1_3 | 0.63 | [0.47, 0.75] | 7.00 | 75 | &lt; .001***\nB     |     var1_1 |     var1_2 | 0.57 | [0.39, 0.72] | 5.71 | 66 | &lt; .001***\nB     |     var1_1 |     var1_3 | 0.47 | [0.26, 0.64] | 4.36 | 66 | &lt; .001***\nB     |     var1_2 |     var1_3 | 0.54 | [0.35, 0.69] | 5.26 | 66 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 68-77\n\n\nYou will see that the data are now reduced to those who contributed to all measures."
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#calculating-partial-correlations",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#calculating-partial-correlations",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Calculating Partial Correlations`",
    "text": "Calculating Partial Correlations`\nTo calculate partial correlations, pass partial = TRUE.\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;     # select var1 variables\n  group_by(group) |&gt;\n  correlation(partial = TRUE)\n\n# Correlation Matrix (pearson-method)\n\nGroup | Parameter1 | Parameter2 |    r |        95% CI |    t | df |         p\n------------------------------------------------------------------------------\nA     |     var1_1 |     var1_2 | 0.36 | [ 0.14, 0.54] | 3.30 | 75 | 0.003**  \nA     |     var1_1 |     var1_3 | 0.21 | [-0.01, 0.41] | 1.86 | 75 | 0.067    \nA     |     var1_2 |     var1_3 | 0.50 | [ 0.31, 0.65] | 4.97 | 75 | &lt; .001***\nB     |     var1_1 |     var1_2 | 0.43 | [ 0.21, 0.60] | 3.84 | 66 | &lt; .001***\nB     |     var1_1 |     var1_3 | 0.23 | [-0.01, 0.44] | 1.92 | 66 | 0.059    \nB     |     var1_2 |     var1_3 | 0.38 | [ 0.16, 0.57] | 3.34 | 66 | 0.003**  \n\np-value adjustment method: Holm (1979)\nObservations: 68-77\n\n\nYou see that the sample size again is reduced to include rows with data for all variables. This is because the partial correlation represents the relationship between each variable pair by removing the relationship between each of those two variables and the third variable. In order to remove the relationship between var1_1 and var1_2 while controlling for the relationship between var1_1 and var1_3 and var1_2 and var1_3. In order for these relationships to be accounted for, only those contributing to all measures will be included in the partial correlation.\nAs a result, dropping NAs using drop_na() does not change the sample sizes.\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;   \n  drop_na() |&gt;\n  group_by(group) |&gt;\n  correlation(partial = TRUE)\n\n# Correlation Matrix (pearson-method)\n\nGroup | Parameter1 | Parameter2 |    r |        95% CI |    t | df |         p\n------------------------------------------------------------------------------\nA     |     var1_1 |     var1_2 | 0.36 | [ 0.14, 0.54] | 3.30 | 75 | 0.003**  \nA     |     var1_1 |     var1_3 | 0.21 | [-0.01, 0.41] | 1.86 | 75 | 0.067    \nA     |     var1_2 |     var1_3 | 0.50 | [ 0.31, 0.65] | 5.00 | 75 | &lt; .001***\nB     |     var1_1 |     var1_2 | 0.43 | [ 0.21, 0.61] | 3.86 | 66 | &lt; .001***\nB     |     var1_1 |     var1_3 | 0.23 | [ 0.00, 0.45] | 1.96 | 66 | 0.055    \nB     |     var1_2 |     var1_3 | 0.38 | [ 0.15, 0.56] | 3.30 | 66 | 0.003**  \n\np-value adjustment method: Holm (1979)\nObservations: 68-77"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#tables",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#tables",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Tables",
    "text": "Tables\nPresenting the data in tabular form is one of the easiest ways to communicate the relationships between the variables. Moreover, the data are already in a form that is ready for a table. The {gt} library provides a simple way to presents data in a table. You can find additional about using the library at the {gt} website.\n{gt} will want to work with data frames, so we need to verify that the correlation matrix is actually a data frame by piping it to is.data.frame().\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;   \n  drop_na() |&gt;\n  group_by(group) |&gt;\n  correlation(partial = TRUE) |&gt;\n  is.data.frame()\n\n[1] TRUE\n\n\nGreat, we know it is. The next step is to simply pipe the data frame to gt::gt() to create a table.\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;   \n  drop_na() |&gt;\n  group_by(group) |&gt;\n  correlation(partial = TRUE) |&gt;\n  gt::gt()\n\n\n\n\n\n  \n    \n    \n      Group\n      Parameter1\n      Parameter2\n      r\n      CI\n      CI_low\n      CI_high\n      t\n      df_error\n      p\n      Method\n      n_Obs\n    \n  \n  \n    A\nvar1_1\nvar1_2\n0.3557371\n0.95\n0.143165377\n0.5369343\n3.296405\n75\n2.996000e-03\nPearson correlation\n77\n    A\nvar1_1\nvar1_3\n0.2098622\n0.95\n-0.014812901\n0.4143640\n1.858855\n75\n6.697077e-02\nPearson correlation\n77\n    A\nvar1_2\nvar1_3\n0.4999301\n0.95\n0.310746798\n0.6510126\n4.999069\n75\n1.101353e-05\nPearson correlation\n77\n    B\nvar1_1\nvar1_2\n0.4294958\n0.95\n0.212869040\n0.6058775\n3.863759\n66\n7.717955e-04\nPearson correlation\n68\n    B\nvar1_1\nvar1_3\n0.2341086\n0.95\n-0.004571681\n0.4475525\n1.956271\n66\n5.466712e-02\nPearson correlation\n68\n    B\nvar1_2\nvar1_3\n0.3766514\n0.95\n0.151864231\n0.5643923\n3.303194\n66\n3.092850e-03\nPearson correlation\n68\n  \n  \n  \n\n\n\n\nThe table is somewhat busy, so we should clean it up a bit. We don’t need the Method variable and we can also round all of the values that are numeric in the data frame in order to improve appearance. We need to pass arguments to .cols and .fns. Using {dplyr}, we can mutate() across() columns where() the data are numeric and then pass a function that will iterate across all of those columns. Let’s just round by 3 digits. If you desire more rounding granularity, you can round specific columns if you don’t want the same rounding rule applied to all values.\n\nWIDE |&gt;\n  select(c(var1_1 : var1_3), group) |&gt;   \n  drop_na() |&gt;\n  group_by(group) |&gt;\n  correlation(partial = TRUE) |&gt;\n  select(-Method) |&gt;\n  mutate(across(.cols = where(is.numeric),  # where the columns are numeric \n                .fns = ~round(.x, 3))       # apply the rounding function\n         ) |&gt;\n  gt::gt()\n\n\n\n\n\n  \n    \n    \n      Group\n      Parameter1\n      Parameter2\n      r\n      CI\n      CI_low\n      CI_high\n      t\n      df_error\n      p\n      n_Obs\n    \n  \n  \n    A\nvar1_1\nvar1_2\n0.356\n0.95\n0.143\n0.537\n3.296\n75\n0.003\n77\n    A\nvar1_1\nvar1_3\n0.210\n0.95\n-0.015\n0.414\n1.859\n75\n0.067\n77\n    A\nvar1_2\nvar1_3\n0.500\n0.95\n0.311\n0.651\n4.999\n75\n0.000\n77\n    B\nvar1_1\nvar1_2\n0.429\n0.95\n0.213\n0.606\n3.864\n66\n0.001\n68\n    B\nvar1_1\nvar1_3\n0.234\n0.95\n-0.005\n0.448\n1.956\n66\n0.055\n68\n    B\nvar1_2\nvar1_3\n0.377\n0.95\n0.152\n0.564\n3.303\n66\n0.003\n68"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#scatterplots-using-geom_point-and-geom_smooth",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#scatterplots-using-geom_point-and-geom_smooth",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Scatterplots using geom_point() and geom_smooth()",
    "text": "Scatterplots using geom_point() and geom_smooth()\nUsing {ggplot}, a point plot can be used to visualize the relationship between two variables.\n\nWIDE |&gt;\n  #select(c(var1_1 : var1_3), group) |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\nTo plot points from subgroups in different colors, map a variable to the color aesthetic.\n\nWIDE |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point(mapping = aes(col = group)) +\n  theme_minimal()\n\n\n\n\nIf you wanted to add a fit line to the plot, add a geom_smooth() layer. Depending on how many rows of data there are, the formual for the function may differ so we will pass formula = y ~ x to geom_smoth()\n\nWIDE |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point() +\n  geom_smooth(formula = y ~ x)\n\n\n\n\nTo add a linear fit line, use method = \"lm\".\n\nWIDE |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point() +\n  geom_smooth(formula = y ~ x,\n              method = \"lm\"\n              ) +\n  theme_minimal()\n\n\n\n\nTo plot separate fits lines for subgroups map a variable to the color aesthetic.\n\nWIDE |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point(mapping = aes(col = group)) +\n  geom_smooth(formula = y ~ x,\n              method = \"lm\",\n              mapping = aes(col = group)\n              ) +\n  theme_minimal()\n\n\n\n\nTo extend fits lines, use fullrange = TRUE.\n\nWIDE |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point(mapping = aes(col = group)) +\n  geom_smooth(formula = y ~ x,\n              method = \"lm\",\n              mapping = aes(col = group),\n              fullrange = TRUE\n              ) +\n  theme_minimal()\n\n\n\n\nRather than use different colors, to create a facet plot by subgroups, use facet_wrap().\n\nWIDE |&gt;\n  ggplot(mapping = aes(\n    x = var1_1, \n    y = var1_2\n    )\n    ) +\n  geom_point() +\n  geom_smooth(formula = y ~ x,\n              method = \"lm\",\n              fullrange = TRUE\n              ) +\n  facet_wrap(facets = vars(group))"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#generalized-pairs-plot-using-ggallyggpairs",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#generalized-pairs-plot-using-ggallyggpairs",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Generalized Pairs Plot using GGally::ggpairs()",
    "text": "Generalized Pairs Plot using GGally::ggpairs()\nGeneralized pairs plots are data visualizations used to exploratory data for individual variables and for relationships across multiple variable pairs. They are often used in exploratory data analysis (EDA) to examine the relationships between multiple variables using point plots, bar plots, boxplots, density plots, histograms, etc. They are an extension of traditional pairwise scatter plots created above using geom_point() but they also allow for the visualization of relationships between more than two variables simultaneously.\nGGally::ggpairs() makes creating generalized pairs plots easy.\nggpairs(\n  data,\n  mapping = NULL,\n  columns = 1:ncol(data),\n  title = NULL,\n  upper = list(continuous = \"cor\", combo = \"box_no_facet\", discrete = \"count\", na = \"na\"),\n  lower = list(continuous = \"points\", combo = \"facethist\", discrete = \"facetbar\", na =\n    \"na\"),\n  diag = list(continuous = \"densityDiag\", discrete = \"barDiag\", na = \"naDiag\"),\n  params = NULL,\n  ...\n)\nKey Parameters/Arguments\n\ndata: a data frame\nmapping: for mapping aesthetics in ggplot objects\n\nThere are other parameters but not needed for this brief introduction.\nThe simplest usage is to pipe your data frame containing your columns of interest to ggpairs() without passing any arguments to the function. Let’s assume first that you have only numeric data and no grouping variable. The pairs plot will provide xy point plots for all variables pairs, density plots for each variable, and Pearson’s r correlations for each variable pair.\n\nWIDE |&gt; \n  select(var1_1:var1_3) |&gt;\n  GGally::ggpairs()\n\nWarning: Removed 54 rows containing non-finite values (`stat_density()`).\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 333 rows containing missing values\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 349 rows containing missing values\n\n\nWarning: Removed 333 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 287 rows containing non-finite values (`stat_density()`).\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 426 rows containing missing values\n\n\nWarning: Removed 349 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 426 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 336 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWhen you have a grouping variable, you see a bar plot for sample sizes across groups, side-by-side histograms of data for each sub group across all variables, boxplots for the distributions of data for each sub group, density plots without grouping, scatter plots, and correlations.\n\nWIDE |&gt; \n  select(group, var1_1:var1_3) |&gt;\n  GGally::ggpairs()\n\n\n\n\nThe {GGally} library is built on the backs of {ggplot2}, so the aesthetics can be mapped as you would with ggplot objects.\n\nWIDE |&gt; \n  select(group, var1_1:var1_3) |&gt;\n  GGally::ggpairs(mapping = aes(col = group,    # set color by group\n                                alpha = .3      # adjust transparency\n                                )\n                  ) \n\n\n\n\nIf you do not like the default palette, you can modify the colors manually. One easy way is to create a vector of colors (e.g., c(\"cornflowerblue\", \"firebrick\") and pass that to the values parameter of scale_fill_manual(). This tells ggplot() to manually change the colors for the fill aesthetic.\n\nnew_colors &lt;- c(\"cornflowerblue\", \"firebrick\") \n\nWIDE |&gt; \n  select(group, var1_1:var1_3) |&gt;\n  GGally::ggpairs(mapping = aes(col = group, \n                                alpha = .3\n                                )\n                  ) +\n  scale_fill_manual(values = new_colors)\n\n\n\n\nWhereas the fill color changes for bars, boxplots, and density plots, the point color did not change. We need to change the color aesthetic using scale_color_manual().\n\nWIDE |&gt; \n  select(group, var1_1:var1_3) |&gt;\n \n  GGally::ggpairs(mapping = aes(col = group, \n                                alpha = .3\n                                )\n                  ) +\n  scale_color_manual(values = new_colors) +\n  scale_fill_manual(values = new_colors)\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 333 rows containing missing values\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 349 rows containing missing values\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 426 rows containing missing values\n\n\nWarning: Removed 54 rows containing non-finite values (`stat_boxplot()`).\n\n\nWarning: Removed 287 rows containing non-finite values (`stat_boxplot()`).\n\n\nWarning: Removed 336 rows containing non-finite values (`stat_boxplot()`).\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 54 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 54 rows containing non-finite values (`stat_density()`).\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 287 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 333 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 287 rows containing non-finite values (`stat_density()`).\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 336 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 349 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 426 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 336 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nVoilà! The colors for both the fill and color aesthetics have changed.\nFinally, if you desired to add fit lines to the plot, you can modify the lower parameter. The argument lower = list(continuous = wrap(\"smooth\")) to produce the fit lines is beyond the scope of this course so there is not a lengthy discussion. If you are curious, you can review the lower parameter and the wrap() function. If you want to remove the standard error range from the plot, passing se = FALSE will remove it.\n\nWIDE |&gt; \n  select(group, var1_1:var1_3) |&gt;\n\n  GGally::ggpairs(mapping = aes(col = group, \n                                alpha = .3\n                                ),\n                  lower = list(continuous = wrap(\"smooth\", se = FALSE))\n                  ) +\n  scale_color_manual(values = new_colors) +\n  scale_fill_manual(values = new_colors)"
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#getting-a-data-frame",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#getting-a-data-frame",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Getting a Data Frame",
    "text": "Getting a Data Frame\nWe will use a long-format data file that contains repeated measures of a variable."
  },
  {
    "objectID": "modules/16_examining_relationships_in_variables_of_cognition.html#arranging-variables-as-columns",
    "href": "modules/16_examining_relationships_in_variables_of_cognition.html#arranging-variables-as-columns",
    "title": "Examining Relationships in Variables of Cognition",
    "section": "Arranging Variables as Columns",
    "text": "Arranging Variables as Columns\nWhen you want to correlate variables, you will need to have them as vectors of the same length. If those vectors are in data frames, you will want to arrange the variables you wish to correlate as column variables in in the data frame. If, for example, you want to correlate variables that are\nYou see that var1 and var2 are measured repeatedly at each time. Some individuals have data for one, two, or three time points. In order to correlate the var1 or var2 performance across the different time points, the data need to be arranged as columns in the data frame."
  }
]